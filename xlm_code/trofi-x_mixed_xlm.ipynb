{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"trofi-x_mixed_xlm.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"3cd69123336a4a51b9b582c5ba2aaaf7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4e7fe2f530af41a4b2f0e28afeee235f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1211f016e2e847af8c94a4ce157e9b40","IPY_MODEL_0c8f3b3fed9c4cc49d7c7993faec2f6b","IPY_MODEL_70031197fc8e41a3b621501a8f4aaecb"]}},"4e7fe2f530af41a4b2f0e28afeee235f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1211f016e2e847af8c94a4ce157e9b40":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bf3117bd4dc24c569155e4dbcbf7cd81","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d71a9a6ad3a448ac92b3920bbe1274b1"}},"0c8f3b3fed9c4cc49d7c7993faec2f6b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2cbe4f1bb629442c9ed15f7895e1868a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":5069051,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5069051,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_021a6f26370f42219840a25f643ddf23"}},"70031197fc8e41a3b621501a8f4aaecb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_28a7aa19cbe54b249a7673a2581b38eb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5.07M/5.07M [00:00&lt;00:00, 12.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_94f9caa7287646f0bd6b7ca96f0cdb61"}},"bf3117bd4dc24c569155e4dbcbf7cd81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d71a9a6ad3a448ac92b3920bbe1274b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2cbe4f1bb629442c9ed15f7895e1868a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"021a6f26370f42219840a25f643ddf23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"28a7aa19cbe54b249a7673a2581b38eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"94f9caa7287646f0bd6b7ca96f0cdb61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"360a5797ee3948cbb055d0fab46ab8ab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3a2aa1dd34af457b88527b31f4697d57","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6ad1ab30b86c4ce1b6208728cb3f22a2","IPY_MODEL_b45437806793456788c50cf87e73e9cb","IPY_MODEL_b9ead8098ddc4363a35c5474c59314bb"]}},"3a2aa1dd34af457b88527b31f4697d57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6ad1ab30b86c4ce1b6208728cb3f22a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_28218bfedba84fef8c65ee38708c9c0c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0331fb406c4c474f9f1b59cae552ae72"}},"b45437806793456788c50cf87e73e9cb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9d132b57f8024bd0b8c4fa8c5a8a33d1","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":512,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":512,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3cb76bf260ee4c9f8614797624fea7d2"}},"b9ead8098ddc4363a35c5474c59314bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_87ebdd5927434f4383c9e394e37894ab","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 512/512 [00:00&lt;00:00, 11.8kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_296af41e81b54144898fe6d6b01a2d36"}},"28218bfedba84fef8c65ee38708c9c0c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0331fb406c4c474f9f1b59cae552ae72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9d132b57f8024bd0b8c4fa8c5a8a33d1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3cb76bf260ee4c9f8614797624fea7d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"87ebdd5927434f4383c9e394e37894ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"296af41e81b54144898fe6d6b01a2d36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d5c58dd9b54d44d88abe3a7c7b3ac3b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1997c86ef0c74fdb8c0d93e54ede5c1b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_22caf4add36541dda07b20bef25a263a","IPY_MODEL_4d870727c15045aa8d89e2d56837530a","IPY_MODEL_4fa6f28c3df141889959797501370127"]}},"1997c86ef0c74fdb8c0d93e54ede5c1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"22caf4add36541dda07b20bef25a263a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e4a4a05144614e8dadec0cf07f272d38","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_94e5d8e1948c4b44a4ea26b98569136d"}},"4d870727c15045aa8d89e2d56837530a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_880b6c4bff9f4b5e997d6d44a36544da","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1115590446,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1115590446,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_01df3323c62240b286407e6fb2c3d735"}},"4fa6f28c3df141889959797501370127":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_013d4a7799424aa2806bd5da84ce4c53","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.12G/1.12G [00:37&lt;00:00, 26.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c698f8ac8d814870857e9b8b713a76d9"}},"e4a4a05144614e8dadec0cf07f272d38":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"94e5d8e1948c4b44a4ea26b98569136d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"880b6c4bff9f4b5e997d6d44a36544da":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"01df3323c62240b286407e6fb2c3d735":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"013d4a7799424aa2806bd5da84ce4c53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c698f8ac8d814870857e9b8b713a76d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"QbOvSBgh_K2T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636653438341,"user_tz":-60,"elapsed":32462,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"24cd8e68-4b27-4427-d038-cc112c55f1e5"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","metadata":{"id":"vzqIeh0k_MbM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636653446800,"user_tz":-60,"elapsed":8465,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"371b2156-6d42-4072-b921-50bbbd1d5a26"},"source":["import tensorflow as tf\n","\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}]},{"cell_type":"code","metadata":{"id":"1Og8o_HG_Mf4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636653487097,"user_tz":-60,"elapsed":40323,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"98eeebf6-b7f5-4737-bd14-4604f2625ac9"},"source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla K80\n"]}]},{"cell_type":"code","metadata":{"id":"8uCANj-7fD_L","executionInfo":{"status":"ok","timestamp":1636653487099,"user_tz":-60,"elapsed":25,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["import logging\n","logging.basicConfig(level=logging.ERROR)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"JI3V3_oy_Mlp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636653493390,"user_tz":-60,"elapsed":6315,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"990c4b46-aea0-4e86-e7b4-3144746607b2"},"source":["!pip install transformers==3"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==3\n","  Downloading transformers-3.0.0-py3-none-any.whl (754 kB)\n","\u001b[?25l\r\u001b[K     |▍                               | 10 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |▉                               | 20 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███                             | 71 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 81 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████                            | 92 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 235 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 245 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 256 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 266 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 276 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 286 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 296 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 307 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 317 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 327 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 337 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 348 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 358 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 368 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 378 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 389 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 399 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 409 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 419 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 430 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 440 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 450 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 460 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 471 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 481 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 491 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 501 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 512 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 522 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 532 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 542 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 552 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 563 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 573 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 583 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 593 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 604 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 614 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 624 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 634 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 645 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 655 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 665 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 675 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 686 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 696 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 706 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 716 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 727 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 737 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 747 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 754 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.3.2)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 40.6 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (21.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n","Collecting tokenizers==0.8.0-rc4\n","  Downloading tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 34.4 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.62.3)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 51.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.19.5)\n","Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (2.4.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.1.0)\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.46 sentencepiece-0.1.96 tokenizers-0.8.0rc4 transformers-3.0.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"MspPBjFecRHv"},"source":["#Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7gn-qmxXFkvG","executionInfo":{"status":"ok","timestamp":1636653493390,"user_tz":-60,"elapsed":16,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"2b7def17-eacf-4e6e-ce85-f3f7256624c6"},"source":["cd drive/My Drive/Colab Notebooks/experiments"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab Notebooks/experiments\n"]}]},{"cell_type":"code","metadata":{"id":"ekbV40xzFsDB","executionInfo":{"status":"ok","timestamp":1636653494678,"user_tz":-60,"elapsed":1297,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["# Use a subset for quick experiments\n","#data = data[:10000]\n","\n","from sklearn.model_selection import train_test_split as tts\n","import pandas as pd\n","data = pd.read_csv(\"data/trofix.csv\")\n","\n","# Split to train, val and test\n","train, test_df = tts(data[[\"sentence\", \"arg1\", \"arg2\", \"verb\", \"label\"]], random_state=42, test_size=0.1)\n","train, val = tts(train, random_state=42, test_size=test_df.shape[0])"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"sT3SnDiB_MoJ","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"ok","timestamp":1636653494894,"user_tz":-60,"elapsed":219,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"722d54c4-da16-47a9-c1fe-2926b07ec031"},"source":["import pandas as pd\n","# import pytreebank\n","\n","#cd drive/My Drive/Colab Notebooks/experiments/data\n","\n","# Load the dataset into a pandas dataframe.\n","df = pd.read_csv(\"data/trofix_mixed.csv\")\n","# Report the number of sentences.\n","print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n","df.head()"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of training sentences: 1,872\n","\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>arg1</th>\n","      <th>arg2</th>\n","      <th>verb</th>\n","      <th>sentence</th>\n","      <th>verb_stem</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>mileage</td>\n","      <td>struck</td>\n","      <td>blow</td>\n","      <td>Triple mileage has struck another blow to the ...</td>\n","      <td>strike</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>terrorist</td>\n","      <td>attack</td>\n","      <td>target</td>\n","      <td>U.S. officials said evidence suggests that a J...</td>\n","      <td>attack</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>forces</td>\n","      <td>stepped</td>\n","      <td>use</td>\n","      <td>Some police forces , for example , have steppe...</td>\n","      <td>step</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>day</td>\n","      <td>pour</td>\n","      <td>stream</td>\n","      <td>Every day his troops gather under the green , ...</td>\n","      <td>pour</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>manufacturers</td>\n","      <td>rolling</td>\n","      <td>products</td>\n","      <td>He says manufacturers are increasingly rolling...</td>\n","      <td>roll</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            arg1     arg2  ... verb_stem label\n","0        mileage   struck  ...    strike     1\n","1      terrorist   attack  ...    attack     0\n","2         forces  stepped  ...      step     0\n","3            day     pour  ...      pour     0\n","4  manufacturers  rolling  ...      roll     1\n","\n","[5 rows x 6 columns]"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"BQGRN8y2_Mq1","executionInfo":{"status":"ok","timestamp":1636653494897,"user_tz":-60,"elapsed":35,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["#if label was not numeric\n","#from sklearn.preprocessing import LabelEncoder\n","\n","#encoder = LabelEncoder()\n","#df.label = encoder.fit_transform(df.label)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jdw6bWex_MuB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636653494901,"user_tz":-60,"elapsed":38,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"8f725a07-fefb-4b6f-9847-e944aa9f9714"},"source":["# Get the lists of sentences and their labels.\n","sentences = df.sentence.values\n","labels = df.label.values\n","labels"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 0, 0, ..., 0, 0, 0])"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"Gkx8ObbNcTUZ"},"source":["#Tokenizer"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fd_lJqo3cncS","executionInfo":{"status":"ok","timestamp":1636653498033,"user_tz":-60,"elapsed":3162,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"4b91003d-8ea8-49e2-d4df-01709a37f3a5"},"source":["!pip install sentencepiece"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"]}]},{"cell_type":"code","metadata":{"id":"9uz-SE4L_MxE","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["3cd69123336a4a51b9b582c5ba2aaaf7","4e7fe2f530af41a4b2f0e28afeee235f","1211f016e2e847af8c94a4ce157e9b40","0c8f3b3fed9c4cc49d7c7993faec2f6b","70031197fc8e41a3b621501a8f4aaecb","bf3117bd4dc24c569155e4dbcbf7cd81","d71a9a6ad3a448ac92b3920bbe1274b1","2cbe4f1bb629442c9ed15f7895e1868a","021a6f26370f42219840a25f643ddf23","28a7aa19cbe54b249a7673a2581b38eb","94f9caa7287646f0bd6b7ca96f0cdb61"]},"executionInfo":{"status":"ok","timestamp":1636653499780,"user_tz":-60,"elapsed":1758,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"e6ba52c3-2395-4afe-b707-5e099a483d5a"},"source":["from transformers import XLMRobertaTokenizer\n","\n","# Load the BERT tokenizer.\n","print('Loading XLMRobertaTokenizer ...')\n","tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base', do_lower_case=True)"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading XLMRobertaTokenizer ...\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3cd69123336a4a51b9b582c5ba2aaaf7","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"Zvi2HDlx_M0k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636653499782,"user_tz":-60,"elapsed":18,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"14bf499b-27ce-439d-e4da-d609fed8b235"},"source":["# Print the original sentence.\n","print('Original: ', sentences[0])\n","\n","# Print the sentence split into tokens.\n","print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n","\n","# Print the sentence mapped to token ids.\n","print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Original:  Triple mileage has struck another blow to the coupon market .\n","Tokenized:  ['▁triple', '▁mile', 'age', '▁has', '▁s', 'truck', '▁another', '▁blow', '▁to', '▁the', '▁coup', 'on', '▁market', '▁', '.']\n","Token IDs:  [162738, 84765, 4588, 1556, 91, 173964, 15700, 102310, 47, 70, 14974, 191, 16839, 6, 5]\n"]}]},{"cell_type":"markdown","metadata":{"id":"tdH-JjAyev73"},"source":["#Tokenize Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pvQC4TbTcveP","executionInfo":{"status":"ok","timestamp":1636653500980,"user_tz":-60,"elapsed":907,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"f31d284c-c092-41c2-ac39-22ddc462c6c1"},"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in sentences:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 128,          # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', sentences[0])\n","print('Token IDs:', input_ids[0])\n","print('labels:', labels)"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Original:  Triple mileage has struck another blow to the coupon market .\n","Token IDs: tensor([     0, 162738,  84765,   4588,   1556,     91, 173964,  15700, 102310,\n","            47,     70,  14974,    191,  16839,      6,      5,      2,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1])\n","labels: tensor([1, 0, 0,  ..., 0, 0, 0])\n"]}]},{"cell_type":"markdown","metadata":{"id":"dgHZenrtf4uH"},"source":["#Train and validation split"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jfrqA7YHcviX","executionInfo":{"status":"ok","timestamp":1636653500982,"user_tz":-60,"elapsed":14,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"7b808ffc-a7cb-4e80-bd4f-9b88b92bcd3d"},"source":["from torch.utils.data import TensorDataset, random_split\n","\n","# Combine the training inputs into a TensorDataset.\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","# Create a 90-10 train-validation split.\n","\n","# Calculate the number of samples to include in each set.\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","# Divide the dataset by randomly selecting samples.\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["1,684 training samples\n","  188 validation samples\n"]}]},{"cell_type":"code","metadata":{"id":"Ew-crkiKcvmk","executionInfo":{"status":"ok","timestamp":1636653500983,"user_tz":-60,"elapsed":8,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","# The DataLoader needs to know our batch size for training, so we specify it \n","# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n","# size of 16 or 32.\n","batch_size = 32\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )\n"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"31XYmBgGgLMq"},"source":["#Train the model - XLMRobertaForSequenceClassification"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["360a5797ee3948cbb055d0fab46ab8ab","3a2aa1dd34af457b88527b31f4697d57","6ad1ab30b86c4ce1b6208728cb3f22a2","b45437806793456788c50cf87e73e9cb","b9ead8098ddc4363a35c5474c59314bb","28218bfedba84fef8c65ee38708c9c0c","0331fb406c4c474f9f1b59cae552ae72","9d132b57f8024bd0b8c4fa8c5a8a33d1","3cb76bf260ee4c9f8614797624fea7d2","87ebdd5927434f4383c9e394e37894ab","296af41e81b54144898fe6d6b01a2d36","d5c58dd9b54d44d88abe3a7c7b3ac3b8","1997c86ef0c74fdb8c0d93e54ede5c1b","22caf4add36541dda07b20bef25a263a","4d870727c15045aa8d89e2d56837530a","4fa6f28c3df141889959797501370127","e4a4a05144614e8dadec0cf07f272d38","94e5d8e1948c4b44a4ea26b98569136d","880b6c4bff9f4b5e997d6d44a36544da","01df3323c62240b286407e6fb2c3d735","013d4a7799424aa2806bd5da84ce4c53","c698f8ac8d814870857e9b8b713a76d9"]},"id":"NCwrwWq3gKVJ","executionInfo":{"status":"ok","timestamp":1636653554326,"user_tz":-60,"elapsed":53351,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"9ec83bb7-5307-4165-febc-d4cfe4ff5bec"},"source":["from transformers import XLMRobertaForSequenceClassification, AdamW, BertConfig\n","\n","# Load BertForSequenceClassification - pretrained BERT model with a single linear classification layer on top. \n","model = XLMRobertaForSequenceClassification.from_pretrained(\n","    \"xlm-roberta-base\", # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = 2, # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"execution_count":17,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"360a5797ee3948cbb055d0fab46ab8ab","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/512 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d5c58dd9b54d44d88abe3a7c7b3ac3b8","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["XLMRobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vMSwxx0gcvqh","executionInfo":{"status":"ok","timestamp":1636653554327,"user_tz":-60,"elapsed":31,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"ed234898-2f33-4164-95ab-664b42f8777c"},"source":["params = list(model.named_parameters())\n","\n","print('The XLMRoberta model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["The XLMRoberta model has 203 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","roberta.embeddings.word_embeddings.weight               (250002, 768)\n","roberta.embeddings.position_embeddings.weight             (514, 768)\n","roberta.embeddings.token_type_embeddings.weight             (1, 768)\n","roberta.embeddings.LayerNorm.weight                           (768,)\n","roberta.embeddings.LayerNorm.bias                             (768,)\n","\n","==== First Transformer ====\n","\n","roberta.encoder.layer.0.attention.self.query.weight       (768, 768)\n","roberta.encoder.layer.0.attention.self.query.bias             (768,)\n","roberta.encoder.layer.0.attention.self.key.weight         (768, 768)\n","roberta.encoder.layer.0.attention.self.key.bias               (768,)\n","roberta.encoder.layer.0.attention.self.value.weight       (768, 768)\n","roberta.encoder.layer.0.attention.self.value.bias             (768,)\n","roberta.encoder.layer.0.attention.output.dense.weight     (768, 768)\n","roberta.encoder.layer.0.attention.output.dense.bias           (768,)\n","roberta.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n","roberta.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n","roberta.encoder.layer.0.intermediate.dense.weight        (3072, 768)\n","roberta.encoder.layer.0.intermediate.dense.bias              (3072,)\n","roberta.encoder.layer.0.output.dense.weight              (768, 3072)\n","roberta.encoder.layer.0.output.dense.bias                     (768,)\n","roberta.encoder.layer.0.output.LayerNorm.weight               (768,)\n","roberta.encoder.layer.0.output.LayerNorm.bias                 (768,)\n","\n","==== Output Layer ====\n","\n","classifier.dense.weight                                   (768, 768)\n","classifier.dense.bias                                         (768,)\n","classifier.out_proj.weight                                  (2, 768)\n","classifier.out_proj.bias                                        (2,)\n"]}]},{"cell_type":"markdown","metadata":{"id":"51Pe3nq8g3wB"},"source":["#Optimizer and Learning Rate Scheduler"]},{"cell_type":"code","metadata":{"id":"xWkNQFlVcvup","executionInfo":{"status":"ok","timestamp":1636653554328,"user_tz":-60,"elapsed":25,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["# Note: AdamW is a class from the huggingface library (as opposed to pytorch) - \"W\" stands for weight decay fix\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"mtGiVJvNhALg","executionInfo":{"status":"ok","timestamp":1636653554329,"user_tz":-60,"elapsed":25,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs. The BERT authors recommend between 2 and 4. \n","# We chose to run for 4, but we'll see later that this may be over-fitting the\n","# training data.\n","epochs = 10\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K3a_KwCxhIw4"},"source":["#Train our model"]},{"cell_type":"code","metadata":{"id":"qZsMe3FshAPv","executionInfo":{"status":"ok","timestamp":1636653554330,"user_tz":-60,"elapsed":26,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"eIoz0srmhAZR","executionInfo":{"status":"ok","timestamp":1636653554331,"user_tz":-60,"elapsed":26,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uf5f0hyehAhP","executionInfo":{"status":"ok","timestamp":1636654331344,"user_tz":-60,"elapsed":777039,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"900943a7-f977-434f-b6ee-a0c91236d2ea"},"source":["import random\n","import numpy as np\n","\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# We'll store a number of quantities such as training and validation loss, \n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        print(b_input_ids.shape)\n","        print(b_input_mask.shape)\n","        print(b_labels.shape)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # The documentation for this `model` function is here: \n","        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","        # It returns different numbers of parameters depending on what arguments\n","        # arge given and what flags are set. For our useage here, it returns\n","        # the loss (because we provided labels) and the \"logits\"--the model\n","        # outputs prior to activation.\n","        loss, logits = model(b_input_ids, \n","                             token_type_ids=None, \n","                             attention_mask=b_input_mask, \n","                             labels=b_labels)\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using \n","        # the `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            # The documentation for this `model` function is here: \n","            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","            # Get the \"logits\" output by the model. The \"logits\" are the output\n","            # values prior to applying an activation function like the softmax.\n","            (loss, logits) = model(b_input_ids, \n","                                   token_type_ids=None, \n","                                   attention_mask=b_input_mask,\n","                                   labels=b_labels)\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     53.    Elapsed: 0:00:57.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([20, 128])\n","torch.Size([20, 128])\n","torch.Size([20])\n","\n","  Average training loss: 0.69\n","  Training epcoh took: 0:01:15\n","\n","Running Validation...\n","  Accuracy: 0.61\n","  Validation Loss: 0.66\n","  Validation took: 0:00:03\n","\n","======== Epoch 2 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     53.    Elapsed: 0:00:57.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([20, 128])\n","torch.Size([20, 128])\n","torch.Size([20])\n","\n","  Average training loss: 0.67\n","  Training epcoh took: 0:01:15\n","\n","Running Validation...\n","  Accuracy: 0.65\n","  Validation Loss: 0.66\n","  Validation took: 0:00:03\n","\n","======== Epoch 3 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     53.    Elapsed: 0:00:57.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([20, 128])\n","torch.Size([20, 128])\n","torch.Size([20])\n","\n","  Average training loss: 0.63\n","  Training epcoh took: 0:01:15\n","\n","Running Validation...\n","  Accuracy: 0.63\n","  Validation Loss: 0.65\n","  Validation took: 0:00:03\n","\n","======== Epoch 4 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     53.    Elapsed: 0:00:57.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([20, 128])\n","torch.Size([20, 128])\n","torch.Size([20])\n","\n","  Average training loss: 0.57\n","  Training epcoh took: 0:01:15\n","\n","Running Validation...\n","  Accuracy: 0.63\n","  Validation Loss: 0.63\n","  Validation took: 0:00:03\n","\n","======== Epoch 5 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     53.    Elapsed: 0:00:57.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([20, 128])\n","torch.Size([20, 128])\n","torch.Size([20])\n","\n","  Average training loss: 0.50\n","  Training epcoh took: 0:01:15\n","\n","Running Validation...\n","  Accuracy: 0.71\n","  Validation Loss: 0.59\n","  Validation took: 0:00:03\n","\n","======== Epoch 6 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     53.    Elapsed: 0:00:57.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([20, 128])\n","torch.Size([20, 128])\n","torch.Size([20])\n","\n","  Average training loss: 0.39\n","  Training epcoh took: 0:01:15\n","\n","Running Validation...\n","  Accuracy: 0.72\n","  Validation Loss: 0.61\n","  Validation took: 0:00:03\n","\n","======== Epoch 7 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     53.    Elapsed: 0:00:57.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([20, 128])\n","torch.Size([20, 128])\n","torch.Size([20])\n","\n","  Average training loss: 0.31\n","  Training epcoh took: 0:01:15\n","\n","Running Validation...\n","  Accuracy: 0.72\n","  Validation Loss: 0.71\n","  Validation took: 0:00:03\n","\n","======== Epoch 8 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     53.    Elapsed: 0:00:57.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([20, 128])\n","torch.Size([20, 128])\n","torch.Size([20])\n","\n","  Average training loss: 0.26\n","  Training epcoh took: 0:01:15\n","\n","Running Validation...\n","  Accuracy: 0.72\n","  Validation Loss: 0.66\n","  Validation took: 0:00:03\n","\n","======== Epoch 9 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     53.    Elapsed: 0:00:57.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([20, 128])\n","torch.Size([20, 128])\n","torch.Size([20])\n","\n","  Average training loss: 0.21\n","  Training epcoh took: 0:01:15\n","\n","Running Validation...\n","  Accuracy: 0.74\n","  Validation Loss: 0.68\n","  Validation took: 0:00:03\n","\n","======== Epoch 10 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     53.    Elapsed: 0:00:57.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([20, 128])\n","torch.Size([20, 128])\n","torch.Size([20])\n","\n","  Average training loss: 0.18\n","  Training epcoh took: 0:01:15\n","\n","Running Validation...\n","  Accuracy: 0.74\n","  Validation Loss: 0.70\n","  Validation took: 0:00:03\n","\n","Training complete!\n","Total training took 0:12:57 (h:mm:ss)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":390},"id":"LHx9Nzi9hAn_","executionInfo":{"status":"ok","timestamp":1636654331345,"user_tz":-60,"elapsed":40,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"32b8b767-4b0b-4bfd-91ce-b24feb475152"},"source":["import pandas as pd\n","\n","# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.69</td>\n","      <td>0.66</td>\n","      <td>0.61</td>\n","      <td>0:01:15</td>\n","      <td>0:00:03</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.67</td>\n","      <td>0.66</td>\n","      <td>0.65</td>\n","      <td>0:01:15</td>\n","      <td>0:00:03</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.63</td>\n","      <td>0.65</td>\n","      <td>0.63</td>\n","      <td>0:01:15</td>\n","      <td>0:00:03</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.57</td>\n","      <td>0.63</td>\n","      <td>0.63</td>\n","      <td>0:01:15</td>\n","      <td>0:00:03</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.50</td>\n","      <td>0.59</td>\n","      <td>0.71</td>\n","      <td>0:01:15</td>\n","      <td>0:00:03</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.39</td>\n","      <td>0.61</td>\n","      <td>0.72</td>\n","      <td>0:01:15</td>\n","      <td>0:00:03</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.31</td>\n","      <td>0.71</td>\n","      <td>0.72</td>\n","      <td>0:01:15</td>\n","      <td>0:00:03</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.26</td>\n","      <td>0.66</td>\n","      <td>0.72</td>\n","      <td>0:01:15</td>\n","      <td>0:00:03</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.21</td>\n","      <td>0.68</td>\n","      <td>0.74</td>\n","      <td>0:01:15</td>\n","      <td>0:00:03</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.18</td>\n","      <td>0.70</td>\n","      <td>0.74</td>\n","      <td>0:01:15</td>\n","      <td>0:00:03</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n","epoch                                                                         \n","1               0.69         0.66           0.61       0:01:15         0:00:03\n","2               0.67         0.66           0.65       0:01:15         0:00:03\n","3               0.63         0.65           0.63       0:01:15         0:00:03\n","4               0.57         0.63           0.63       0:01:15         0:00:03\n","5               0.50         0.59           0.71       0:01:15         0:00:03\n","6               0.39         0.61           0.72       0:01:15         0:00:03\n","7               0.31         0.71           0.72       0:01:15         0:00:03\n","8               0.26         0.66           0.72       0:01:15         0:00:03\n","9               0.21         0.68           0.74       0:01:15         0:00:03\n","10              0.18         0.70           0.74       0:01:15         0:00:03"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":427},"id":"d9EJhSWFhAxL","executionInfo":{"status":"ok","timestamp":1636654331954,"user_tz":-60,"elapsed":633,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"854113cb-745e-4541-fa5f-7a7e4e978633"},"source":["import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","import seaborn as sns\n","\n","# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"execution_count":25,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAuUAAAGaCAYAAACopj13AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeVhTZ94+8DuBJKxhTQDZQQFFQKDaWm3dBau1rXWbtq7d23ln3s6v02qXmWln+s47drHbtPPaalut1brWWutWt24KdQMX3BFlTdgJS9bz+wMIRkCjAifA/bkuL8xJzsnDY4Q7T77neySCIAggIiIiIiLRSMUeABERERFRb8dQTkREREQkMoZyIiIiIiKRMZQTEREREYmMoZyIiIiISGQM5UREREREImMoJ6IeKz8/H7Gxsfjggw9u+hgLFixAbGxsB46q52pvvmNjY7FgwQK7jvHBBx8gNjYW+fn5HT6+DRs2IDY2FhkZGR1+bCKiW+Us9gCIqPe4kXC7a9cuhISEdOJoup+6ujr85z//wffffw+NRgNfX1+kpqbimWeeQXR0tF3H+MMf/oDt27fjm2++Qf/+/dt8jCAIGDNmDKqrq/Hzzz/DxcWlI7+NTpWRkYHMzEzMmTMHSqVS7OG0kp+fjzFjxuDhhx/GX/7yF7GHQ0QOhKGciLrMokWLbG4fOnQIX3/9NWbMmIHU1FSb+3x9fW/5+YKDg5GdnQ0nJ6ebPsbf//53vPbaa7c8lo7wyiuvYMuWLZg0aRKGDBkCrVaL3bt3Iysry+5QPnXqVGzfvh3r16/HK6+80uZjDhw4gIKCAsyYMaNDAnl2djak0q75YDYzMxMffvghHnjggVah/L777sPEiRMhk8m6ZCxERDeCoZyIusx9991nc9tsNuPrr7/GoEGDWt13NZ1OBw8Pjxt6PolEAoVCccPjvJKjBLj6+nps27YNw4cPx9tvv23d/vvf/x4Gg8Hu4wwfPhxBQUHYvHkzXnjhBcjl8laP2bBhA4DGAN8RbvXfoKM4OTnd0hs0IqLOxJpyInI4o0ePxqxZs3Dy5Ek8+uijSE1NxeTJkwE0hvPFixdj2rRpuP322zFw4ECMGzcOb731Furr622O01aN85Xb9uzZgwcffBAJCQkYPnw4/vWvf8FkMtkco62a8uZtNTU1+Otf/4qhQ4ciISEBM2fORFZWVqvvp6KiAgsXLsTtt9+O5ORkzJ49GydPnsSsWbMwevRou+ZEIpFAIpG0+SahrWDdHqlUigceeACVlZXYvXt3q/t1Oh127NiBmJgYJCYm3tB8t6etmnKLxYL/+7//w+jRo5GQkIBJkybh22+/bXP/8+fP429/+xsmTpyI5ORkJCUlYcqUKVi7dq3N4xYsWIAPP/wQADBmzBjExsba/Pu3V1NeXl6O1157DSNGjMDAgQMxYsQIvPbaa6ioqLB5XPP++/fvx9KlSzF27FgMHDgQaWlp2Lhxo11zcSNOnTqFZ599FrfffjsSEhJwzz334JNPPoHZbLZ5XFFRERYuXIhRo0Zh4MCBGDp0KGbOnGkzJovFgs8//xz33nsvkpOTkZKSgrS0NLz00kswGo0dPnYiunFcKScih1RYWIg5c+YgPT0d48ePR11dHQCgpKQE69atw/jx4zFp0iQ4OzsjMzMTn376KXJycrB06VK7jr9v3z589dVXmDlzJh588EHs2rULy5Ytg5eXF5566im7jvHoo4/C19cXzz77LCorK/HZZ5/hiSeewK5du6yr+gaDAfPmzUNOTg6mTJmChIQEnD59GvPmzYOXl5fd8+Hi4oL7778f69evx3fffYdJkybZve/VpkyZgo8//hgbNmxAenq6zX1btmxBQ0MDHnzwQQAdN99X++c//4nly5dj8ODBmDt3LsrKyvD6668jNDS01WMzMzNx8OBBjBw5EiEhIdZPDV555RWUl5fjySefBADMmDEDOp0OO3fuxMKFC+Hj4wPg2ucy1NTU4He/+x3y8vLw4IMPYsCAAcjJycGqVatw4MABrF27ttUnNIsXL0ZDQwNmzJgBuVyOVatWYcGCBQgLC2tVhnWzjh07hlmzZsHZ2RkPP/ww/P39sWfPHrz11ls4deqU9dMSk8mEefPmoaSkBA899BAiIiKg0+lw+vRpHDx4EA888AAA4OOPP8b777+PUaNGYebMmXByckJ+fj52794Ng8HgMJ8IEfVqAhGRSNavXy/ExMQI69evt9k+atQoISYmRlizZk2rffR6vWAwGFptX7x4sRATEyNkZWVZt12+fFmIiYkR3n///VbbkpKShMuXL1u3WywWYeLEicKwYcNsjvviiy8KMTExbW7761//arP9+++/F2JiYoRVq1ZZt3355ZdCTEyM8NFHH9k8tnn7qFGjWn0vbampqREef/xxYeDAgcKAAQOELVu22LVfe2bPni30799fKCkpsdk+ffp0IT4+XigrKxME4dbnWxAEISYmRnjxxRett8+fPy/ExsYKs2fPFkwmk3X78ePHhdjYWCEmJsbm36a2trbV85vNZuGRRx4RUlJSbMb3/vvvt9q/WfPr7cCBA9Zt77zzjhATEyN8+eWXNo9t/vdZvHhxq/3vu+8+Qa/XW7cXFxcL8fHxwnPPPdfqOa/WPEevvfbaNR83Y8YMoX///kJOTo51m8ViEf7whz8IMTExwq+//ioIgiDk5OQIMTExwpIlS655vPvvv1+YMGHCdcdHROJh+QoROSRvb29MmTKl1Xa5XG5d1TOZTKiqqkJ5eTnuvPNOAGizfKQtY8aMsenuIpFIcPvtt0Or1aK2ttauY8ydO9fm9h133AEAyMvLs27bs2cPnJycMHv2bJvHTps2DZ6ennY9j8ViwR//+EecOnUKW7duxd13343nn38emzdvtnncq6++ivj4eLtqzKdOnQqz2YxvvvnGuu38+fM4evQoRo8ebT3RtqPm+0q7du2CIAiYN2+eTY13fHw8hg0b1urxbm5u1r/r9XpUVFSgsrISw4YNg06nw4ULF254DM127twJX19fzJgxw2b7jBkz4Ovrix9++KHVPg899JBNyVBAQAAiIyNx8eLFmx7HlcrKynDkyBGMHj0acXFx1u0SiQRPP/20ddwArK+hjIwMlJWVtXtMDw8PlJSU4ODBgx0yRiLqeCxfISKHFBoa2u5JeStXrsTq1atx7tw5WCwWm/uqqqrsPv7VvL29AQCVlZVwd3e/4WM0l0tUVlZat+Xn50OtVrc6nlwuR0hICKqrq6/7PLt27cLPP/+MN998EyEhIXjvvffw+9//Hi+88AJMJpO1ROH06dNISEiwq8Z8/PjxUCqV2LBhA5544gkAwPr16wHAWrrSrCPm+0qXL18GAERFRbW6Lzo6Gj///LPNttraWnz44YfYunUrioqKWu1jzxy2Jz8/HwMHDoSzs+2vQ2dnZ0RERODkyZOt9mnvtVNQUHDT47h6TADQt2/fVvdFRUVBKpVa5zA4OBhPPfUUlixZguHDh6N///644447kJ6ejsTEROt+f/rTn/Dss8/i4YcfhlqtxpAhQzBy5EikpaXd0DkJRNR5GMqJyCG5urq2uf2zzz7D//7v/2L48OGYPXs21Go1ZDIZSkpKsGDBAgiCYNfxr9WF41aPYe/+9mo+MXHw4MEAGgP9hx9+iKeffhoLFy6EyWRCXFwcsrKy8MYbb9h1TIVCgUmTJuGrr77C4cOHkZSUhG+//RaBgYG46667rI/rqPm+Ff/v//0/7N27F9OnT8fgwYPh7e0NJycn7Nu3D59//nmrNwqdravaO9rrueeew9SpU7F3714cPHgQ69atw9KlS/HYY4/hz3/+MwAgOTkZO3fuxM8//4yMjAxkZGTgu+++w8cff4yvvvrK+oaUiMTDUE5E3cqmTZsQHByMTz75xCYc/fjjjyKOqn3BwcHYv38/amtrbVbLjUYj8vPz7brATfP3WVBQgKCgIACNwfyjjz7CU089hVdffRXBwcGIiYnB/fffb/fYpk6diq+++gobNmxAVVUVtFotnnrqKZt57Yz5bl5pvnDhAsLCwmzuO3/+vM3t6upq7N27F/fddx9ef/11m/t+/fXXVseWSCQ3PJbc3FyYTCab1XKTyYSLFy+2uSre2ZrLqs6dO9fqvgsXLsBisbQaV2hoKGbNmoVZs2ZBr9fj0Ucfxaeffor58+fDz88PAODu7o60tDSkpaUBaPwE5PXXX8e6devw2GOPdfJ3RUTX41hv94mIrkMqlUIikdis0JpMJnzyyScijqp9o0ePhtlsxvLly222r1mzBjU1NXYdY8SIEQAau35cWS+uUCjwzjvvQKlUIj8/H2lpaa3KMK4lPj4e/fv3x/fff4+VK1dCIpG06k3eGfM9evRoSCQSfPbZZzbt/U6cONEqaDe/Ebh6RV6j0bRqiQi01J/bW1YzduxYlJeXtzrWmjVrUF5ejrFjx9p1nI7k5+eH5ORk7NmzB2fOnLFuFwQBS5YsAQCMGzcOQGP3mKtbGioUCmtpUPM8lJeXt3qe+Ph4m8cQkbi4Uk5E3Up6ejrefvttPP744xg3bhx0Oh2+++67GwqjXWnatGlYvXo13n33XVy6dMnaEnHbtm0IDw9v1Re9LcOGDcPUqVOxbt06TJw4Effddx8CAwNx+fJlbNq0CUBjwPr3v/+N6OhoTJgwwe7xTZ06FX//+9/x008/YciQIa1WYDtjvqOjo/Hwww/jyy+/xJw5czB+/HiUlZVh5cqViIuLs6nj9vDwwLBhw/Dtt9/CxcUFCQkJKCgowNdff42QkBCb+n0ASEpKAgC89dZbuPfee6FQKNCvXz/ExMS0OZbHHnsM27Ztw+uvv46TJ0+if//+yMnJwbp16xAZGdlpK8jHjx/HRx991Gq7s7MznnjiCbz88suYNWsWHn74YTz00ENQqVTYs2cPfv75Z0yaNAlDhw4F0Fja9Oqrr2L8+PGIjIyEu7s7jh8/jnXr1iEpKckazu+55x4MGjQIiYmJUKvV0Gq1WLNmDWQyGSZOnNgp3yMR3RjH/C1GRNSORx99FIIgYN26dXjjjTegUqkwYcIEPPjgg7jnnnvEHl4rcrkcX3zxBRYtWoRdu3Zh69atSExMxOeff46XX34ZDQ0Ndh3njTfewJAhQ7B69WosXboURqMRwcHBSE9Px/z58yGXyzFjxgz8+c9/hqenJ4YPH27Xce+9914sWrQIer2+1QmeQOfN98svvwx/f3+sWbMGixYtQkREBP7yl78gLy+v1cmVb775Jt5++23s3r0bGzduREREBJ577jk4Oztj4cKFNo9NTU3F888/j9WrV+PVV1+FyWTC73//+3ZDuaenJ1atWoX3338fu3fvxoYNG+Dn54eZM2fiv/7rv274KrL2ysrKarNzjVwuxxNPPIGEhASsXr0a77//PlatWoW6ujqEhobi+eefx/z5862Pj42Nxbhx45CZmYnNmzfDYrEgKCgITz75pM3j5s+fj3379mHFihWoqamBn58fkpKS8OSTT9p0eCEi8UiErjhLh4iIbJjNZtxxxx1ITEy86QvwEBFRz8GaciKiTtbWavjq1atRXV3dZl9uIiLqfVi+QkTUyV555RUYDAYkJydDLpfjyJEj+O677xAeHo7p06eLPTwiInIALF8hIupk33zzDVauXImLFy+irq4Ofn5+GDFiBP74xz/C399f7OEREZEDYCgnIiIiIhIZa8qJiIiIiETGUE5EREREJDKe6NmkoqIWFkvXVvL4+XmgrEzXpc/pyDgftjgfLTgXRETUE0ilEvj4uLd5H0N5E4tF6PJQ3vy81ILzYYvz0YJzQUREPRnLV4iIiIiIRMZQTkREREQkMoZyIiIiIiKRMZQTEREREYmMoZyIiIiISGQM5UREREREImMoJyIiIiISGUM5EREREZHIGMqJiIiIiETGK3oSERF1c5nFh/Ht+W2o0FfCR+GNydHpGBKYIvawiOgGMJQTERF1Y5nFh/HVqfUwWowAgAp9Jb46tR4AGMyJuhGWrxAREXVj357fZg3kzYwWI749v02kERHRzWAoJyIi6sYq9JXtbhcEoYtHQ0Q3i6GciIiomzKYjZBJZe3ev/jwx8gpO8NwTtQNiFpTbjAY8N5772HTpk2orq5GXFwcnnvuOQwdOvSa+40ePRoFBQVt3hceHo4dO3Z0xnCJiIgcRo1Bh//L/gJGixFOEieYBbP1PplUhhR1Ik5XnMOHWZ8iQhmGCRFjEO8XB4lEIuKoiag9oobyBQsWYMeOHZg9ezbCw8OxceNGPP7441ixYgWSk5Pb3e+ll15CbW2tzbbCwkK8++67GDZsWGcPm4iISFSaOi0+ylqGSn0VHhs4y1pDfnX3FaPFhANFB7Ejbw8+zv4MoZ7BmBAxBgn+AyCV8MNyIkciEUT6TCs7OxvTpk3DwoULMXfuXACAXq/HpEmToFarsXLlyhs63kcffYT33nsPq1atQkrKjZ9tXlamg8XStVOhUnlCq63p0ud0ZJwPW5yPFpwLohYXqi7iP9mfAwCeSpyHKK/w6+5jtpiRUXwY2/N2o7S+DMEeQUiPGINBqoEM50RdSCqVwM/Po837RFsp37ZtG2QyGaZNm2bdplAoMHXqVCxevBgajQZqtdru43333XcICQm5qUBORETUHRzWZOOLk6vho/DCM0nzoXZT2bWfk9QJd/YZjNsDU3Cw5Ci25+3G0uNfItA9ABPCRyMlIInhnHoFR+7pL1ooz8nJQWRkJNzd3W22JyYmQhAE5OTk2B3KT548ifPnz+Opp57qjKESERGJShAE7L78Ezae24IIZRieSpwLD7n79Xe8ipPUCbcHpWJwYDIOa7Kx9eIufHZyFbZc3In08DG4LWAQnKROnfAdEInP0Xv6ixbKtVotAgICWm1XqRrf9Ws0GruPtXnzZgDA5MmTO2ZwREREDsIiWLDu7LfYl/8rBqkSMGfATMid2u+4Yg+pRIrbAgYhRZ2ILO0JbL34A5bnfI3vc3ciLWI0hgSmwFnK6wtSz2EwG7Dx3JZ2e/r36lDe0NAAmaz1DxWFQgGgsb7cHhaLBVu2bMGAAQMQHR190+Npr76ns6lUnqI8r6PifNjifLTgXFBv1GDS4/39y3CwMBuTYsfikaQHOrzMZLz6TowdcAcOFR7D+hPfY+WpddhxaTfu65+GUZFDIbvFNwBEXcVgMqBYp0WxTouiGg2KdBoU12hQrNOivL7tfv4AUKmvdIjfMaKFchcXFxiNxlbbm8N4czi/nszMTJSUlFhPFr1ZPNFTfJwPW5yPFpwL6o2qDTX4OOszXK4pwLSY+zAyeBjKSmuvv+NNipBH4U+DnsWJslPYenEXPj20CuuOf49x4SMxLGgIwzk5BKPZCG19GbT1pdDUlUJbXwptXRk09aWo1FfZPNZD5g61mz/6eUVDHeSP3Zd/Qq2xrtUxvRXeXfY7xiFP9FSpVG2WqGi1WgCwu5588+bNkEqlmDhxYoeOrzPtP1GMDfvOo7xaD1+lAlNGRGNofKDYwyIiIgdRXFuCj7KWodqgwxMJs5Goiu+S55VIJBjo3x/xfnE4VXEWW3N/wNozm7D94m6MCxuB4cF3QO4k75KxUO9lNBtR2lB+Reguhaa+DNq6xuAtoGUR1UPmDpWrP2J8oqF29YfKzb/pqx9cnV1tjuvr4mNTUw409vSfHJ3eZd/btYgWyuPi4rBixQrU1tbanOyZlZVlvf96DAYDduzYgSFDhrRZn+6I9p8oxhdbT8FgsgAAyqr1+GLrKQBgMCciIpytOI//O7YczhInPJfyFMKVoV0+BolEgv6+MYjz6YezlRewNfcHrD/3HXbk7cWYsLtxV/BQuDjb94k2UVuMFhPK6sugrS+Dpq4Umqbwra0vQ0VDpU3wdpe5QeXqj77eUVC7+VnDt8rVH24y12s8i63munF2X7lKeno6li1bhrVr11pLTwwGAzZs2ICUlBRryC4sLER9fX2b9eL79u1DdXU17r333q4c+i3ZsO+8NZA3M5gsWP3DWQwI94GXB3/IERH1Vr8VH8GXOWvg5+qHZ5Lmw9/VV9TxSCQSxPhEI8YnGucqc7Ht4i58c/577Ly0F6ND78KIkDtbrUYSNTNZTCirL7cG7ubVbm19KcqvCt5uzq5Qufkj2isCqiB/qFz9oG5a9XaTuXXYmIYEpjhMCL+aaKE8KSkJ6enpeOutt6DVahEWFoaNGzeisLAQ//znP62Pe/HFF5GZmYnTp0+3OsbmzZshl8uRlpbWlUO/JWXVbZ/AWlNvxHMf/gI/pQKRQUpE9fFCVB8lwgM9oZCxPRURUU8mCAJ25O3Btxe2oa93JJ5ImAP3DgwiHaGvdyR+P+gx5FZdwraLP2Dzhe344dKPGBUyDKNCh3docKLuw2wxo7ShvCl0N9Z3N9d7lzdU2ARvV2dXqF39EekVjiGBqVA3rXar3fwd7vUuBlH7HS1atAjvvvsuNm3ahKqqKsTGxmLJkiVITU297r46nQ579+7FyJEj4ekp/hmz9vJTKtoM5kp3GSbcHo7compcKKzGwdONtfVSiQTBKndE9VEiKkiJyD5K9PFzh1Qq6eqhExFRJzBbzPj6zEb8UpiJ2wIG4ZH+0yFz4HaEkV5heDppPi5V52PbxV34/uIP2H35J4wMGYZRYXfBQ3bj/dPJsZktZpRZa7yvOMmyrhTl+kpYhJYKAFdnF6hc/RGhDMWQwGRr6Fa5NgZviYT5pT0SQRC6tuWIg+qq7itX15QDgNxZijkT4mxqyqtqDcgtrMaFomrkFlbhQlEN6vUmAICL3AkRgZ6I6uPVtKquhI9n9y97YYcNW5yPFpwL6qkaTA1YenwlTpafxvjwUbg3Kq3bXVmzQFeErRd34ajmGGROMowIvhNjwu6Gp1ycVsNky94rWDYG74rG0G1T412KsoYKm+Dt4qS44oTKlhMrVa7+8JC5M3hfw7W6rzCUN+nKlog3033FIggoKa/DhaagfqGwGvkaHcxNY/bxVFhX05vLXlzkjrvS0hYGL1ucjxacC+qJKvVV+DjrMxTWFmNGzP0YHnyH2EO6JUW1Jdh2cRcOlWTBWeqMu4LvwNiwEfBSKMUeWq919RUsAUAmdcbI4GHwdvW2nliprStFaUO5TfBWOMltTqhsDt9qNwbvW8FQbofu2KfcaDIjr0TXGNQLq5BbVA1tZQMAQCIBgv09ENWncUU9KkiJPv6OXfbC4GWL89GCc0E9TaGuGB9lLUOdqQ6PDnwE8X7X7zjWXZTUarA9bw9+KzkCqUSKYX2GYFzYSPi4eIs9tF7FIljw8i9voNrQ/s9OeXPwdvWzWflWufpDKfdg8O4EDOV26I6hvC3VdU1lL4XVyC1q/FPb0Fj2opA1l700rqZHBinhq3Tp0Oe/FQxetjgfLTgX1JOcKj+LT46tgMJJhqeT5iPUM1jsIXUKbV0ZduTtxoHiQ5BCgjuCbsP48FHwE7mjTE9VZ6xDbvUl5Fbl4UJVHi5WX4LebGj38f8z7BUo5Z4M3l2ModwOPSWUX00QBJRU1FuD+oWiKlwqaSl78faQWzu9RAYpERHoCVeFOGUvDF62OB8tOBfUUxwoOoiVp9Yh0E2Np5PmwdfFR+whdbqy+nLsuLQX+wt/gwABdwSmYnz4aKjc/MQeWrdlESzQ1JXiQlUecqsu4kL1JRTXlgAAJJAgxCMIkV7hOFSShVpT6ytY+ii88Y9hL3X1sAkM5XbpqaG8LUaTGZc0jWUvzWFdU1kPAJAA6KNyt55AGhWkRLDKHU7Szj/xiMHLFuejBeeCujtBEPD9xR/wfe5OxPr0xeMJs3pdf++KhkrsvLQPvxRmwCJYMDggGWnhoxDgbt8VvHuzBpMeedWXkVud1xTE81Bnavy97ebsikivcER5hSNSGY5wZaj1wk5t15TL8FDcgw7bq7unYyi3Q28K5W3R1RuttemNHV9ayl7kMikiAjytK+rN3V46+iMvR5oPR8D5aMG5oO7MZDFh1akNOFB8ELcHpuKhuAfh7MAtDztblb4aP1zah58KDsBkMSE1IAlp4aPRx4NXtQYa38CVNVTgQtVF5DYF8HxdkbXfd6B7AKKUYYj0ikCUVzjUbv7X7Nhjb/cV6hoM5Xbo7aH8aoIgQFNZ3xTUG2vTL5XUwGRunCMvd7k1oEcFKRERpLzlshdHng8xcD5acC6ou6o31eOTYytwuuIc7okch3sixrKGt0mNQYddl37EvoJfYTQbMUg1EOkRYxDi2UfsoXUpo9mISzUF1lXwC1UXUWPQAWjsgBKhDGtcBfcKR6QyjBdp6uYYyu3AUH59RpMFlzW6pgscVeFCYTVKKlrKXoL83a0XOIoKUiJEfWNlL91tPjob56MF54K6o4qGSnyUtQzFdRo8FDcVQ4NuE3tIDklnqMWeyz9hb/4vaDDrkegfjwkRYxCmDBF7aJ2iUl9lLUHJrcrDpZoCmAUzAMDf1c9ahhLlFY4+HoHdrm89XRtDuR0Yym+Ort6Ii0XVNv3TdfWNtWtyZynCAz1b6tP7KOGndGm1SnQzfdt7g57w+ugonAvqbi7XFODjrGXQm414PGEW4nz7iT0kh1dnrMOe/F+w5/LPqDfVY6BfHNIjxiLSK0zsod00s8WMfF0hcqsu4ULVRVyoykOFvhIA4Cx1RrhnCKK8IhpXwb3CoJR3nyuU081hKLcDQ3nHEAQB2qoG60p6bmE18kp0MJkbL0igdJe3rKb3UaK0sh6rD+0F+pyGRN4AweACFMZi9h1jen0w74mvj5vFuaDu5ETZKSw9/iVcnV3xTNJ8BHsEiT2kbqXeVI99+fux+9KPqDXVob9vDNIjxqCvd6TYQ7sunaHWpgwlrzrfepKlt8LLWoYS5RWOEI8+vfrcgt6KodwODOWdx2RuLHtprk2/UFiN4vLGFk1OvoWQRR6HxKnlKmKCWQp58SC8O2umWEN2CL3l9WEPzgV1F78UZGD1mY3o4x6Ip5PmwVvhJfaQuq0Gkx4/FezHD5f2QWesRYx3NCZEjkU/7yiHqMu3CBYU1ZbYlKJo6ksBAFKJFKEewTYhnBdPIoCh3C5dGcqbz4Su1FfCu5ucCW0RLDALFpgtJpgEM2ar7QIAACAASURBVMwWM0wWM8yCqemr+Yqvpta3LeaW/QQT6g1GlFbX4rfSDEicTa2eTzDI8VzKMwj3U0HuJBPhOxYfg2gLzgU5OkEQsPnCdmzP240BvrF4dODDcHF2nIuzdWcGswE/FxzAzkv7UG2oQbRXBCZEjkWcT78uDef1pnpcrLpsLUO5WH0ZDebGq2h7yNybylDCEOUVgTDPkF77u4uujaHcDl0VytvrGTq1371IVMVfI+xedfvKcCy0dbsx/LYcr52wbHO7/eNaBMs1vqtbIKDxLNFrkEEBL4US/m7e8FIo4a3wgpdC2fhHroS3Qgml3BNOUqfOGaNIGERbcC7IkRktJnyZswYHS45iWJ8hmBHzQI/7eeQIDGYjfi3KxM68vajUVyFCGYYJEWMQ7xfX4eFcEARo6lsuzpNbdQlFtSUQIEACCfp4BDaugCvDEeUVAX9XX4dYvSfHx1Buh64K5a/88j/Wkzw6iwQSOEud4CRxbvrq1PhV6gRniXPT17ZvW/e5xmNa3ZY6tzyHpK3bzce9ajwSJ7y47x+otbQOW3K4or98KC5oNahoqIZE1gCZmxEyFwMMqLP2a72Sp8zDJqw3/937itueco9ucyY7g2gLzgU5qlpjHZYc+wLnKnMxOSod48NHMZx1MqPFhANFB7Ejbw/KGyoQ5hmM9IixSPQfcNNzrzcbGi/O03SJ+tzqPNQaG8ssXZ1dEKkMt66ChytD4cpPQegmMZTboatC+bO7X2j3vhkxD1wVop2vCMLt3G4VfJ26TegEGj85+PLkOpjRUsLiBGc8MmCqtaSnokaPo2e1OHxGi1OXKmG2WODlJSA2yhWhITJ4ellQY6xBlb668Y+h8WuNQdcqvEsggVLueUVg92ozwLvL3ET/xcog2oJzQY6otL4cH2UtQ1l9GR7pPx2DA5PFHlKvYraYkVF8GNsv7kJpQzmCPYKQHjEGg1QDcbDkaLsXzBEEAeUNlU2Xp2+5OE/zJ8IBbuqmAN64Ch7gpupWv1fJsTGU20HslXIfhTf+MeylTn9+R3QjNfa1DUZknyvD4TNaHMstg8FogZvCGUl9/ZASo8LASD8o5I0fG5stZtQYdajUV7UEdn01Kg3VNgG+eTXkSs4SJyivXnG/4u/Nq/Guzq1bPHYUBtEWnAtyNHnVl/Fx1mcwCWY8mTAb/XyixR5Sr2W2mHGw5Ci25e2Cpq4UXnIldMZaa+9vAHCWOGOQaiBMghm5VRdRZWj8eSKXymwuzhPhFQYPmbtY3wr1AgzldhC7pvyhuAcd/mTPznajwUtvNONkbjkOn9Hi6LlS1DaYIHeWIj7SFykxKiT19YeH6/VPtDGajag21KDKUI1KfXWrFffmv9ebGlrtK5fK2i6ZsQnwXlA4ye3+vrrjicCdjaGcHEm29gQ+O/EVPOUeeCZpPgLdA8QeEqGxIcHhkix8kfN1u+dB+bn4WstQorzC0cc9kPX/1KUYyu3A7iviu5XgZbZYcOZSJQ6fKcXhs1pU1OghlUgQG+aNlBgVkvv5w1d5azWAerOh3cBuXYXXV8FwxRuuZi5OLq1OTm0V5uWeOKI9xjdtbWAoJ0exL/9XrD2zCaGewXg6aR4v9uKArlUm+u/Ri7pwJEStMZTbgX3KxddR8yEIAi4W1+DwmcY69KKyxvKUyCBPpMSokBKjQpBf53w8KQgCGswNTQH92gHedMVHq80kkLR5EmtvLm8C+H+FxGcRLPjm3PfYdflHJPj3x7z4h2/oEzDqOiwTJUfGUG4HhnLxddZ8FJXVWgN6blHj8YP83KwBPSLQs8tP6hQEAbWmOpta9ypDNTZf2N7uPgFuaoR4BKGPRxCCPQIR7BEEH4W36CekdgX+XyExGcxGLD+5Gke0x3B38J2YFjOZJ/45MJaJkiNjKLcDQ7n4umI+yqsbcORsKQ6f0eL0pUpYBAE+ngqk9FMhJcYfMWHecJKK98u2vRUeFycXxPpEo0BXhNKGcut2V2dXa0APdm8M7H08AnvcCh7/r5BYdIZa/N+xz3GhKg8P9J2IMaF394o3wt1dc5loW91XiMTEUG4HhnLxdfV86OqNyDrXGNCP55bDaLLA3cUZg/r6IyVGhfhIX8hlXXsCkD0rPPWmBhTVFqNAV4QCXTEKdIUo0BVBbzYAaCyBUbn62ayoB3v0ga+Ld7dd3eP/FRKDpq4UH2UtRYW+CnMGzESKOlHsIRFRN8dQbgeGcvGJOR96gxnHcxtbLWadK0Od3gS5TIqEyMZWi4l9/eDu0jWXTL6ZE4EtggXlDZVNQb0QBbpiFOqKoK0vs9aouzgp0McjEH08ghDiEYRgjyD0cQ/sFpcC5/8V6moXqvLwn+zPAABPJc5FlFeEuAMioh6BodwODOXic5T5MJktOH2psrEO/awWVToDnKQSxIV5IzlGheR+Kvh4Kjp9HB0xH3qzoXFVvaYIBbVF1tX1elO99TF+Lr5X1Ko3rq77u/o51Kq6o7w2qHc4ojmGL06ugpfCC88mzYfaTSX2kIioh2AotwNDufgccT4sgoDcwmocPqvF4TOlKClv7OQS1UdpPVE00NetU567s+ZDEARU6CutAb1QV4R8XRE0dVrrqrpcKrOWv/RpqlcP9giCm8y1w8djD0d8bVDPIwgC9lz+CRvObUGEMgxPJs6Bp7ztX55ERDeDodwODOXic/T5EAQBhWV11k4uecWNY+3j746UmMY69PCAjuvk0tXzYTAbUVxb0hjWa4saV9d1Rag1tVzx1Efh3bSa3vJH5erX6RffcPTXBnV/FsGCdWc3Y1/+LxikSsCcATMhd+qakjUi6j0Yyu3AUC6+7jYfZVUNOHxWiyNntDh9uRKCAPgpFUju17iC3i/U65Y6uTjCfAiCgCpDtc0JpYW6YhTXaaxXzJNJnRHkHoBgjz7W8pc+HkEdeqlqR5gL6rn0ZgM+O/EVjpWexOjQu/BA34kOVb5FRD0HQ7kdGMrF153no6bOgKPnSnHkTCmO55bDZLbAw1V2RScXH8icb2w12ZHnw2gxobhWg0Jdc516458ao876GC+5EsGeLaUvwR5BCHBT3dSquiPPBXVv1YYa/Cfrc1yqycfUfpMxMnSY2EMioh6ModwODOXi6ynz0WAw4fiF8sZOLudLUa83QyFzQkKUb2Mnl2h/uLk4X/c43XE+qg011oBeqCtGvq4QxbUamJuuXuoscUKge0Bj55emdo0hHn3ardu9mU40RPYqrtXgo6xlqDbUYF78Q0hSxYs9JCLq4RjK7cBQLr6eOB8mswWn8ipw+IwWR86Woqq2sZNL/3AfpMSokNzPH14ebXdy6SnzYbaYUVKntVlRL9AVocpQbX2Mp9zDZkU92CMIl3UF+Pr0N7wqH3WKsxUXsOTYF3CSOOGppLmIUIaJPSQi6gUYyu3AUC6+nj4fFkHAhYJq64mimsp6SABEB3s1dXLxh9rHDftPFGPDvvMor9bDV6nAlBHRGBofKPbwO5zOUNtyUqmuCIW6IhTWlsBkMV1zPx+FN/4x7KUuGiX1RAeLj2BFzhr4ufrimaRH4e/qK/aQiKiXYCi3A0O5+HrTfAiCgAJtrTWgX9I01mL7eMpRXWuE+YrXotxZijkT4npkML+a2WKGtr4UBboiLDvxVbuP+9sdL0Ll5teFI6OeQBAE7Mzbi00XtqKvdySeSJgDd1nntDQlImoLQ7kdGMrF15vnQ1tZjyNntFi37zxM5tavQz+lAm8+07tOQHvll/9Bhb6y3ftDPfogWZ2IZHUCL+5C12W2mPH1mW/wS2EGbgsYhEf6T4dMev1zO4iIOtK1Qjl/IhE5AJW3K8YPCcPq3efavL+sWo96vQmuit7zX3ZydDq+OrW+VU355KgJEGDBEU02vr2wDd9e2IZgjyCkqBORrE5EAAM6XaXB1IClJ1biZNlpjA8fhXuj0tjykIgcDlfKm3ClXHycD+DPH/2Csmp9m/e5Kpxwd1IfjLstFL5Kly4emTiu132loqESR7THcESTjQtVeQCAPu6B1oAe6K4Wa+jkICr1VfhP1mcoqC3GjJj7MTz4DrGHRES9GMtX7MBQLj7OB7D/RDG+2HoKBpPFuk3uLMU9Q8NRWFqLg6e0AIDB/dVIGxKKiEClWEPtUva8Nir1VTiiaQnoAgQEuQcgWZ2IFHUigtwDumi05CgKdcX4KGsZak11eGzgI4j3ixN7SETUyzGU24GhXHycj0bX6r5SWlWPHw7m48esQjQYzIgN9UbakDAk9vWDVCIReeSd50ZfG5X6KhzVHscRTTbOV16EAAGBbmqbgC7pwfNFwKnys/jk2AoonGR4KmkewjxDxB4SERFDuT0YysXH+bB1rfmoazDhx6xC/HDoMsqr9Qj0dcP4waG4c2Ag5LIbv2Kmo7uV10aVvhpZ2uM4rMnGucpcCBAQ4KZGsjoBKepE9HEPZEDvYQ4UHcTKU+sQ4KbCM0nz4eviI/aQiIgAMJTbhaFcfJwPW/bMh8lswcHTGmzPvIy84hp4uMowOiUYo1NCoHSXd9FIO19HvTaqDTU4qjmOI9pjOFtxHgIEqN38kaxqrEEP8QhiQO/GBEHA1os/YEvuTsT49MXjA2fBTeYq9rCIiKwYyu3AUC4+zoetG5kPQRBw5nIltmdextFzpXB2kuLOgQEYPzgMffzdO3mkna8zXhs1Bh2Oao/jqOYYzlSeh0WwQOXqZ22zGOoRzIDejZgsJqw6tQEHig/i9sBUPBT3IJzZ8pCIHAxDuR0YysXH+bB1s/NRVFaLnb9dxi/Hi2E0WZAY7Ye0IWGIC/PutiGzs18bNQYdsrUncER7DKcrzsEiWODv4msN6GGeId127nqy5u48FfpKOEudYbKYcE/EWNwTOY7/XkTkkBjK7cBQLj7Oh61bnY/qOgP2HC7A7sP5qKkzIizAA2lDwjA4Tg1np+7Vo7krXxs6Yy2ytSdwWJNtDeh+Lr5IVicgWZ2AcM9QBj4HkFl8uFUfeyeJEx7pP82mbSYRkSNx2FBuMBjw3nvvYdOmTaiurkZcXByee+45DB061K79N2/ejC+++ALnzp2DXC5HTEwMXnjhBSQmJt7wWBjKxcf5sNVR82EwmrH/RDF2/HYZRWV18PFUYOxtIRiR1AduLrIOGGnnE+u1UWusawzo2mycLj8Hs2CGr4sPklWNAT1CGcaA3oUMZiM0dVoU12mw6tQGNJgbWj3GR+GNfwx7SYTRERFdn8OG8j/96U/YsWMHZs+ejfDwcGzcuBHHjx/HihUrkJycfM19Fy9ejE8//RSTJ09GSkoK6urqcOrUKYwdOxZjxoy54bEwlIuP82Gro+fDIgg4dr4M2zMv4dSlSijkTrg7sQ/G3RYCf2/HPhnOEV4bdcY6ZJeexBFNNnLKz8IsmOGj8G5aQU9EhDKUV4nsIDpjLYprNSip1aC4rvFPSa0W5Q0VEHD9n9P/Hr2oC0ZJRHTjHDKUZ2dnY9q0aVi4cCHmzp0LANDr9Zg0aRLUajVWrlzZ7r6HDx/GQw89hA8++ADjxo3rkPEwlIuP82GrM+cjr7gG23+7hN9yNLAIAm6LVSNtSBii+jjmxYgc7bVRZ6zHsdKTOKLNRk7ZGZgEM7wVXk0r6ImI9ApjQL8Oi2BBRUNlU+BuCt+1WpTUaaAz1lofJ5M6Q+2mQqCbGgHuagS6qRHorsbHWZ+hQl/Z6rhcKSciR3atUC7aqenbtm2DTCbDtGnTrNsUCgWmTp2KxYsXQ6PRQK1u+xLZy5cvR0JCAsaNGweLxYL6+nq4u3f/DhNEXSU80BNP3BuPqSOi8cOhfOw7WoDfTmnQL8QLaUPCMKivP6RSlmW0x03mituDUnF7UCrqTfU4VpqDI5pj+KnwAPbk/wwvuRKDmvqgR3mF9+qAbjQboakvbVz5rtM0fdWipE5rUw/uLnNDoJsaSap4BDQF7wA3NXxdvNucv8nR6a1qymVSGSZHp3fJ90VE1NFEC+U5OTmIjIxsFaYTExMhCAJycnLaDeX79+/HxIkT8c4772DFihWoq6tDcHAw/vu//xuTJ0/uiuET9Qi+ShdMH9UX994ZgZ+yi7Dzt8v4cMMxqH1cMX5wKIYlBEHRAy9G1JFcnV0xJDAFQwJTUG9qwInSHBzWHsOvhRnYl/8LlHJPDFIlIEWdgGjvyB4b0OuMddbV7uK6EpTUNtZ+l9WXW0tOJJDA18UbAe5qxPhE26x+e8hvbGGl+WTO5u4rPgpvTI5O50meRNRtiRbKtVotAgICWm1XqVQAAI1G0+Z+VVVVqKysxJYtW+Dk5ITnn38e3t7eWLlyJf785z/D1dW1w0paiHoLV4Uzxg8OxZjUYBw6rcX2zMv4cscZbPzxAkalBGNMSgi8PBRiD9PhuTq74LbAZNwWmIwGUwOOl53CEc0x7C/6DT8W/ApPuYc1oPf1jup2Ad0iWFCpr7KudhfXljR91aDGqLM+zlnqDLWrP8I8gzE4INm66h3g5g+5U8dd1Kr5zRARUU8gWihvaGiATNa684NC0fiLX6/Xt7lfXV0dAKCyshJr1qxBUlISAGDcuHEYN24c/v3vf99UKG+vvqezqVSeojyvo+J82BJjPiYGeOGeu6JxMrcc3+w7hy3787At4zJGpoTg/hHRCA8Sp+68+702PBEapMIE3IUGYwMOF53AgcuHkVF0ED8V7IeXwhODQwZhaGgKBqj6wUnqOJ9ImMwmFOk0KKgubvxTU4KC6iIU1migN7X8bHaXuyHEMxCDQxLRRxmIEGUg+igDoXbzg1Tavd5wEBGJTbRQ7uLiAqPR2Gp7cxhvDudXa94eEhJiDeQAIJfLkZaWhuXLl6O2tvaGa8x5oqf4OB+2xJ4PtaccT0wagPvujMCO3y7jxyP5+OG3SxgY6Yu028MwINyny9oBij0XHaGfawz6xcRgevQUnCg7hSOabPyYewA/nP8JHjJ3JKnikaxORIx3dJcF9HpTPYprNSiu01pPtiyp1aC0oRwWwWJ9nI/CG4HuatwZOLip3ESFQPcAeMjcW78G6oGy+loQEVFrDnmip0qlarNERavVAkC79eTe3t6Qy+Xw9/dvdZ+/vz8EQYBOp+OJn0QdJMDXDbPSYvHA3VHYc6QAuw7l4+3VRxGi8kDakFDcPiCg212MSEwKJzlS1IlIUSfCYDbgZNlpHNZk47eSo/ilMBPuMjck+TcG9Fifvrcc0AVBQKW+ylpm0nKypQZVhpY3Ok4SJ6jd/BHsEYSUgKSmem8VAtzUUHRgyQkREbVNtFAeFxeHFStWtFrVzsrKst7fFqlUiv79+6OkpKTVfcXFxXBycoKXl1fnDJqoF/NwleHeOyOQPiQMB5ouRrR0Sw7W7zuPMakhGJkcDPducjEiRyF3kmOQOgGD1AkwmI3IKW8M6Ic12fi16De4ObsiURWPlKaAfliT3e6JjWaLGdr6UhS3Eb71ZoP1OV2dXRDopkZ/31gEujd3OVHBz8XXoUpoiIh6G9H6lGdlZWH69Ok2fcoNBgMmTZoEPz8/rFq1CgBQWFiI+vp6REdHW/ddtmwZ/vWvf2HZsmUYNmwYAECn02HcuHGIioq6Zo/z9rB8RXycD1uOPh+CIOB4bjm2Z17CyYsVUMicMDwxCOMGh0LdwRcjcvS56GhGsxE55WdwWHMMx0pPosHcAJlEBrNghgUtZSVSiRTB7kEwWIzQ1pfalJx4K7yu6u2tQoBbAJRyD16FlIhIJA558SAA+OMf/4hdu3Zhzpw5CAsLs17R84svvkBqaioAYNasWcjMzMTp06et+9XX12PKlCkoKSnB3LlzoVQqsX79euTm5trseyMYysXH+bDVnebjUkkNdvx2GRknS2ARBKTEqJA2JAx9gzvmU6vuNBcdzWgx4VT5GSw7/hUMFkOr+6USKRL9B1zR21uFADcVXJxdRBgtERFdi0PWlAPAokWL8O6772LTpk2oqqpCbGwslixZct1Q7erqiuXLl2PRokX48ssv0dDQgPj4eHz22Wc3FciJ6NaEBXjisUkD8OCIaOw6lI+9Rwpw6LQW0cFKpA0OQ0qMihcjukkyqTMS/Ae0GciBxjaFjyfM7uJRERFRRxN1pdyRcKVcfJwPW915PhoMJvycXYQdv11GaVUDVN4uGHdbKIYnBsFFfuNrAd15LjrKK7/8Dy8rT0TUzV1rpZwtE4iow7nInTH2tlD875ND8cz9A6F0l+OrH87izx/9inV7z6Oipu3rEFD7JkenQya1PZGWl5UnIuo5RC1fIaKeTSqV4LY4NW6LU+NcQRW2Z17C1ow8bM+8hNsHBCBtSBhC1eJcuKu74WXliYh6NpavNGH5ivg4H7Z66nxoKuqw82A+fs4ugt5oxoAIH6QNCcPASN92u4L01LkgIqLexWG7rzgShnLxcT5s9fT5qG0wYu+RAvxwKB9VOgOC/d0xfnAo7ogPhMzZtrKup88FERH1DgzldmAoFx/nw1ZvmQ+T2YKMkyXYnnkJ+dpaKN3lGJMSjFEpITh2oQwb9p1HebUevkoFpoyIxtD4QLGHTEREdFMYyu3AUC4+zoet3jYfgiDg5MUKbM+8hOO55XCSAAIksFzxI0ruLMWcCXEM5kRE1C2x+woROTyJRIL4SF/8acYgvP7oEDg7S20COQAYTBZs2HdepBESERF1HoZyInI4ISoP6I2WNu8rq2Y7RSIi6nkYyonIIfkpFW1ud5JKcKmk95T1EBFR78BQTkQOacqIaMiv6sLi7CSBzEmC1z8/iLV7zkFvNIs0OiIioo7FiwcRkUNqPpnz6u4rCVF+WLPnHLZmXMLB0xrMTo9DfISvyKMlIiK6Ney+0oTdV8TH+bDF+WjR1lzk5FXgi22noKmox50DAzFzTD94uMraOQIREZH42H2FiHqc/uE+eH3+EEwcGo6MkyV4ackB7D9RDK4zEBFRd8RQTkTdllzmhAdHROMvcwdD5e2KTzafxOI1WSitrBd7aERERDeEoZyIur1QtQdenpWK343th7P5VXhlaQa2ZVyC2dJ2W0UiIiJHw1BORD2CVCrBuNtC8Y/Hbkf/MB+s2XMO/1h+CHnFrMsnIiLHx1BORD2Kn5cL/jA1EU/dF4+KGj3+/sVBrGH7RCIicnBsiUhEPY5EIsGQ/gGIj/TF2j3nsC3jEg6e0mBOehziI9k+kYiIHA9Xyomox3J3kWHuhP544XfJcJJK8PbXR/HJ5pOoqTOIPTQiIiIbDOVE1OPFhfvg9UeHYNKd4cjMKcHLn2Rg/3G2TyQiIsfBUE5EvYLM2QlT7o7GX+cOhtrHFZ98dxLvrMmClu0TiYjIATCUE1GvEqL2wEuPpOLhcTE4V1CFVz9l+0QiIhIfT/Qkol5HKpVgTGoIkvv548sdZ7BmzzlknCzB3AlxCA/0FHt4RETUC3GlnIh6LV+lC/7rwQQ8ff9AVOia2ifuPge9ge0TiYioa3GlnIh6NYlEgsFxagyI8MHaPeexLfMSDp7WYHZ6LAZG+ok9PCIi6iW4Uk5EhOb2iXF48aFkODlJ8c7XWfhk8wlUs30iERF1AYZyIqIrxIb54PX5gzHpzghk5mjwyicZ+OVYEdsnEhFRp2IoJyK6SmP7xCj8dd5gBPi6YumWHLzz9VFo2D6RiIg6CUM5EVE7QlQeWNjUPvF8YTX+8mkGtmbksX0iERF1OJ7oSUR0DVKJbfvEtXvOW9snRgQqxR4eERH1EFwpJyKyQ3P7xGfuH4gqnQF//+IgVu86y/aJRETUIbhSTkRkJ4lEgtua2yfuPY8dv13G4TNazE6LxcAotk8kIqKbx5VyIqIb5OYiw5z0xvaJzk5SvLMmC0vYPpGIiG4BQzkR0U2KDfPBa/OHYPKwCPyWo8HLSw6wfSIREd0UhnIiolsgc5bi/rui8Ld5gxHk546lW3Lw9tdHoamoE3toRETUjTCUExF1gGCVBxY8koJHxsfgQmE1/rI0E1sP5MFkZvtEIiK6Pp7oSUTUQaQSCUanhGBQX3+s3HkGa/eex4Gm9omRQWyfSERE7eNKORFRB2tsn5iIZx8YiOo6A/6xvLF9YoPBJPbQiIjIQXGlnIiok6TGqtE/3AfrmtonHjqtxez0WCSwfSIREV2FK+VERJ3IzUWG2elxWPBwCuQyKRavycKSb0+gupbtE4mIqAVDORFRF4gJ9cbf5jW1TzylwcufHMDP2WyfSEREjRjKiYi6iLV94vwhCPJ3x7Lvc/DW6qMoYftEIqJeT9RQbjAY8Oabb2L48OFITEzE9OnTsX///uvu98EHHyA2NrbVn2HDhnXBqImIbk2wvzsWPJyCWWmxuFjc2D5xy/6LbJ9IRNSLiXqi54IFC7Bjxw7Mnj0b4eHh2LhxIx5//HGsWLECycnJ193/9ddfh4uLi/X2lX8nInJkUokEo5KDre0T1++7gMwcDdsnEhH1UqKF8uzsbGzZsgULFy7E3LlzAQD3338/Jk2ahLfeegsrV6687jEmTJgApZK/vIio+/LxVOD3UxJw6LQWK3eexj+WH8TY1FA8cHckXORskEVE1FuIVr6ybds2yGQyTJs2zbpNoVBg6tSpOHToEDQazXWPIQgCdDodT5Qiom4vNVaFfzx2B0YOCsbOg5fx6qcZyD5fKvawiIioi4gWynNychAZGQl3d3eb7YmJiRAEATk5Odc9xsiRI5GamorU1FQsXLgQlZWVnTVcIqJO5+bijFlpsVj4SArkMie8uzYb/9l0HFVsn0hE1OOJ9tmoVqtFQEBAq+0qlQoArrlSrlQqMWvWLCQlJUEmk+HAgQP4+uuvcfLkSaxduxZyubzTxk1E1Nn6hTS2T9x6IA/f7b+IE7nlmD66L5ykEmz88QLKqvXwUyowZUQ0hsYHij1cIiLqAKKF8oaGBshkslbbFQoFAECv17e775w5c2xup6eno1+/fnj99dfxzTffYPr06Tc8Hj8/jxvepyOoVJ6iPK+j4nzY4ny0z59cigAAIABJREFU6I1z8egDiRh/ZyQ+XHsUn31/ChIJ0FytV1atx/Jtp6H0dMHI1FBxB0pERLdMtFDu4uICo9HYantzGG8O5/b63e9+hzfffBP79++/qVBeVqaDxdK1tekqlSe02poufU5Hxvmwxflo0ZvnwkUK/Gl6Ev743k+obTDZ3Kc3mvH5dycQH+Yt0uiIiOhGSKWSdheCRaspV6lUbZaoaLVaAIBarb6h40mlUgQEBKCqqqpDxkdE5CikEkmrQN6srLr9TxWJiKj7EC2Ux8XFITc3F7W1tTbbs7KyrPffCKPRiKKiIvj4+HTYGImIHIWfsu1PD33b2U5ERN2LaKE8PT0dRqMRa9eutW4zGAzYsGEDUlJSrCeBFhYW4vz58zb7lpeXtzre0qVLodfrcdddd3XuwImIRDBlRDTkzq1/ZMucpNDVty4FJCKi7kW0mvKkpCSkp6fjrbfeglarRVhYGDZu3IjCwkL885//tD7uxRdfRGZmJk6fPm3dNmrUKNxzzz2IiYmBXC5HRkYGtm/fjtTUVEyaNEmMb4eIqFM1d1nZsO+8tfvKoL7+2JdViH9+eQjPTUuCv7eryKMkIqKbJerl4hYtWoR3330XmzZtQlVVFWJjY7FkyRKkpqZec797770Xhw8fxrZt22A0GhEcHIxnnnkGTz75JJydeQU8IuqZhsYHtmqBeFucGh+sP4Y3VhzCf09LQnhg7+tSQ0TUE0gEXg4TALuvOALOhy3ORwvOxbUVaHVYvDYLtQ0mPHv/QAyM8hN7SERE1AaH7L5CREQdI1jlgZdn3Qa1tyveW5eNn7OLxB4SERHdIIZyIqIewMdTgQUPpyA2zBvLvs/Bt7/kgh+EEhF1HwzlREQ9hKvCGf89LQlD4wPxzU+5+GLbaZgtFrGHRUREduBZkUREPYizkxSPTeoPPy8Fvvs1D5U6PZ66Lx4ucv64JyJyZB2yUm4ymbB9+3asWbPGekVOIiISh0QiwZS7ozE7LRbHLpRh0VdHUFVrEHtYRER0DTe8dLJo0SJkZGRg/fr1AABBEDBv3jwcPHgQgiDA29sba9asQVhYWIcPloiI7DcyORjeHgr8Z9NxvLH8IP40YxACfd3EHhYREbXhhlfKf/rpJ9x2223W27t378Zvv/2GRx99FG+//TYAYMmSJR03QiIiummD+vnjhYdSoDea8T8rDuFcQZXYQyIiojbccCgvLi5GeHi49faePXsQEhKC559/HhMnTsTMmTOxf//+Dh0kERHdvKg+Srw0KxVuLs54c9URHD7DMkMiIkdzw6HcaDTaXDUzIyMDd955p/V2aGgo68qJiBxMgI8bXpqVihCVB/694Rh2HcoXe0hERHSFGw7lgYGBOHLkCADg7NmzuHz5MgYPHmy9v6ysDG5urFkkov/f3n1HRXWtbQB/pjH06tCkiKigdKwI9oYtGmNJ7CkmsUWTm2LiTb6Ua5reaGLURExR401iAbFg7wUrRhTBQlEIVZAqZWDm+wMdMoIKCpwBnt9aWSuz55SXLQse9uyzN+kaU0M9vDvRDz7tWmHDvmvYdPgGVFzLnIhIJ9T5Qc/hw4dj5cqVyMnJwfXr12FsbIw+ffpo3o+NjeVDnkREOkouk2D2GE9s2Hcdu07dwp38Urw4rCNkUm5bQUQkpDqH8tdeew1paWk4cOAAjI2N8dVXX8HU1BQAUFBQgIMHD2L69On1XScREdUTiViMKYM7wMpUji1HEpBbWIo5Y7xgqC8TujQiohZLpK7HfZhVKhWKioqgr68Pmaxp/XDPzi6EStW4H+MqFCbIyipo1HvqMvaHNvZHFfZFw4m8nI6fI2Jha2WIN8f5wNJUX+iSiIiaLbFYBCsr45rfq88blZeXw8TEpMkFciKilirA0xZvjvdBdl4JFq0/j5TMQqFLIiJqkeocyo8cOYLly5drtW3YsAH+/v7w9fXFv/71LyiVynorkIiIGlanNpZYMMkfarUaX2w4j9ikHKFLIiJqceocyn/66SckJCRoXsfHx+Pzzz+HtbU1evbsiYiICGzYsKFeiyQiooblZGOCf0/tAksTfXyz8SJOxaQLXRIRUYtS51CekJAAT09PzeuIiAjI5XJs3rwZa9aswbBhw7B169Z6LZKIiBqepak+3p/sj3atzbB6+xVEnLqJenzsiIiIHqHOoTwvLw8WFhaa1ydPnkSPHj1gbFw5ab1bt25ISeGmFERETZGhvgxvTfBFt47W2Hw4Hhv2XWv0h+CJiFqiOodyCwsLpKamAgAKCwtx6dIldOnSRfN+eXk5Kioq6q9CIiJqVDKpGK8+44Hgbk44GPU3VoRdQqmSP9eJiBpSndcp9/X1xR9//IF27drh6NGjqKioQO/evTXv37x5E9bW1vVaJBERNS6xSITx/dvBwlSOP/Zfx5LfL+CNsd4wMdQTujQiomapziPlb7zxBlQqFebPn4/Q0FCMHj0a7dq1AwCo1Wrs378f/v7+9V4oERE1vkFdHDHrWU/cyizE5+vPIzO3WOiSiIiapSfaPCg3NxdRUVEwMTFB165dNe15eXnYunUrunfvDnd393ottKFx8yDhsT+0sT+qsC+Edz0lF99tjoZELMK8cT5wsTMVuiQioibnUZsH1euOnk0ZQ7nw2B/a2B9V2Be6IS27CEs3XkT+3TLMHOUJn3athC6JiKhJeVQor/Oc8vtu3bqFAwcOIDk5GQDg6OiIAQMGwMnJ6UkvSUREOszOyggLp3TGsk3RWL7lEqYM6YA+vq2FLouIqFl4opHyZcuWISQkpNoqK2KxGK+99hrmzZtXbwU2Fo6UC4/9oY39UYV9oVtKysqxcutlXE7IwciebTC6lwtEIpHQZRER6bx6HSnfvHkzfvjhB/j5+eGVV15B+/btAQDXr1/HTz/9hB9++AGOjo4YM2bM01VNREQ6SV9Pijee88a6PVex/WQScvJLMG2oO6SSOq8dQERE99R5pHzMmDGQyWTYsGEDpFLtTF9eXo5JkyZBqVQiNDS0XgttaBwpFx77Qxv7owr7Qjep1WpsO5GE8OOJ8HCxxKzRnjCQP/GsSCKiZu9RI+V1HtaIj4/HsGHDqgVyAJBKpRg2bBji4+PrXiURETUpIpEIo4Jc8OJQd8Qm3cFXG6KQW1gqdFlERE1SnUO5TCbD3bt3H/p+UVERZDLZUxVFRERNRy8fe7wx1hsZd4qxaN15pN4uErokIqImp86h3MvLC3/++Sdu375d7b3s7Gxs3LgRPj4+9VIcERE1Dd6uVnhvkh+UFSp88dt5XEvOFbokIqImpc5zys+ePYvp06fDyMgIzz33nGY3zxs3biA0NBRFRUX49ddf0aVLlwYpuKFwTrnw2B/a2B9V2BdNR1ZuMZZuvIjbeSV4dWQndHG3FrokIiKdUe+bBx08eBCfffYZ0tLStNrt7e3x0UcfoW/fvk9UqJAYyoXH/tDG/qjCvmhaCouV+G5zNOL/zsOEAe0xuKuj0CUREemEBtnRU6VS4fLly0hJSQFQuXmQh4cHNm7ciHXr1iEiIuLJKxYAQ7nw2B/a2B9V2BdNT5myAiHbr+D8tSwM7uqI8f3bQcy1zImohWuQHT3FYjG8vb3h7e2t1X7nzh0kJiY+6WWJiKgZ0JNJMHO0J/44cB17zyYjp6AUM0Z0hEwqEbo0IiKdxAVliYioQYjFIrwwsD0sTfWx8dAN5BeWYs5z3jA24ApdREQP4vZrRETUYEQiEYK7O+G1ZzyQkJaPL347j9t5xUKXRUSkcxjKiYiowXXvZIO3xvsit7AMi9adx60MPiNARPRPDOVERNQo3J0t8MFkf0gkInyxIQqXE7OFLomISGfUak75L7/8UusLRkVFPXExRETUvLVWGGPhlC5YuvEivt0UjelD3RHoZSd0WUREgqtVKP/qq6/qdFERl70iIqKHsDCRY8Ekf6wIu4SfdsYiJ78EI3q24e8OImrRahXK161b19B1EBFRC2KoL8Wb433wS0Qswo4lIqegFJMHd4BEzFmVRNQy1SqUd+vWraHrICKiFkYqEeOVEZ1gaaqPnZE3caegFDNHeUKux7XMiajlEXRIoqysDIsXL0ZQUBC8vb0xfvx4REZG1vk6M2bMgJubGxYtWtQAVRIRUUMRiUR4ro8rpgzugEsJ2fj69yjkF5UJXRYRUaMTNJQvWLAAa9euxTPPPIOFCxdCLBZjxowZuHDhQq2vcfjwYZw7d64BqyQioobWz98Bc8Z44e+sIixafw4ZOXeFLomIqFEJFsqjo6Oxc+dOvP3223j33XcxYcIErF27FnZ2dliyZEmtrlFWVoYvvvgCL7/8cgNXS0REDc2vvQLvTPRDcWkFFq0/j/i/84QuiYio0QgWynfv3g2ZTIZx48Zp2uRyOcaOHYvz588jMzPzsddYt24dSkpKGMqJiJoJV3szLJzSGYZyKRb/fgEXrmUJXRIRUaMQLJTHxsbCxcUFRkZGWu3e3t5Qq9WIjY195PlZWVlYuXIl3nzzTRgYGDRkqURE1IhsLA3xwZTOaK0wxvdhl3AwKkXokoiIGpxgoTwrKwvW1tbV2hUKBQA8dqT8m2++gYuLC0aNGtUg9RERkXBMjfTw7gt+8G5rhd/2XsOmwzegUquFLouIqMHUaknEhlBSUgKZTFatXS6XAwBKS0sfem50dDS2bt2K9evX19tmE1ZWxvVynbpSKEwEua+uYn9oY39UYV+0TJ+81hM/hF3CrsgkFJep8MYEP8ikXMuciJofwUK5vr4+lEpltfb7Yfx+OH+QWq3GokWLMHjwYHTp0qXe6snOLoRK1bijMAqFCbKyChr1nrqM/aGN/VGFfdGyjevtAiM9MbYcSUBGdhFmP+sFQ33Bfn0RET0xsVj00IFgwYYbFApFjVNUsrIqH+qpaWoLAOzbtw/R0dF44YUXkJKSovkPAAoLC5GSkoKSkpKGK5yIiBqVSCTC8IA2eGVER1xLzsWXG84jJ58/54moeRFsqMHd3R3r169HUVGR1sOeFy9e1Lxfk9TUVKhUKkybNq3ae6GhoQgNDUVISAh69+7dMIUTEZEgenrawcxIjhVhl7Bo/Xn092+Nwxf+RnZ+KaxM5RjTxxUBHrZCl0lE9EQEC+XBwcH4+eefsWnTJkyfPh1A5brjoaGh8Pf3h42NDYDKEF5cXAxXV1cAQP/+/eHg4FDterNnz0a/fv0wduxYeHh4NNrXQUREjcfDxRILJvnjq/9FYcuRBE17dn4p1u6KAwAGcyJqkgQL5T4+PggODsaSJUuQlZUFJycnhIWFITU1FV988YXmuPfeew9nzpzB1atXAQBOTk5wcnKq8ZqOjo4YOHBgo9RPRETCcLIxgVwmRXFphVZ7WbkKoUfiGcqJqEkS9EmZr7/+GsuWLUN4eDjy8vLg5uaG1atXo3PnzkKWRUREOi63sOYVurLzH75yFxGRLhOp1Vz4FeDqK7qA/aGN/VGFfUEPemfliRoDuL5Mgv/OCYSBnKuzEJHu0cnVV4iIiJ7UmD6u0HtgvXKxSIQSZQX+veY0oq5lCVQZEdGT4VACERE1OffnjYceiddafcXawgBrd8Xh+9BL8GvfCpMGdYClqb7A1RIRPR6nr9zD6SvCY39oY39UYV9QXZRXqLD3bDLCjydCIhbhuT6u6OfXGmJx/ewATUT0pDh9hYiIWgypRIxhPZzx2cvd4Gpvig37ruHz384jObNQ6NKIiB6KoZyIiJolawtDvDXBFzNGdkJWbjE+/fUsNh2+gVJlxeNPJiJqZJxTTkREzZZIJEKAhy282lph46Eb2HXqFs7FZWLqEHd4uFgKXR4RkQZHyomIqNkzNpDhpWEd8e4LfhCLxfjvn39h9fYY5BeVCV0aEREAhnIiImpB3J0t8OlLXTGyZxucjc3EwpBTOBadCq55QERCYygnIqIWRSaV4NnebfHxS91g18oIv0TEYfHvF5Cec1fo0oioBWMoJyKiFql1KyMsmOSPqcFuuJlRiI9+OoNtJxJRXqESujQiaoH4oCcREbVYYpEIfX1bw7ddK/y+/zq2HkvE6SsZmBbsjg6O5kKXR0QtCEfKiYioxTM3lmPmaE/MH+eNMqUKX26IwtrdcbhbohS6NCJqIRjKiYiI7vF2bYX/vNIdQ7o54ujFVCwMOY0zsRl8EJSIGhxDORER0T/I9SSY0L89PprWFeYmcvwQHoNvN0fjdl6x0KURUTPGUE5ERFQDZ1sT/HtqZzzfvx2u3srFv9ecxp4zt1Ch4oOgRFT/GMqJiIgeQiIWY3A3J3z2Sje4O1ngz4M38J+155GUni90aUTUzDCUExERPUYrMwPMG+uNmaM9kVtYis/WnsMfB66jpKxc6NKIqJngkohERES1IBKJ0NXdGh5tLLD5cDz2nk3G+auZmDzYDT7tWgldHhE1cRwpJyIiqgNDfRmmBrvj/cn+kOtJ8e3maKzcehm5haVCl0ZETRhDORER0RNo72COj1/simd7t8Vf129jYchpHL7wN1RcPpGIngBDORER0ROSSsQY2bMNPn25G5xtjLFuz1V8uSEKf2cVCl0aETUxDOVERERPydbSEO+84IeXhnVE2u0ifPzLWYQeTYCyvELo0oioieCDnkRERPVAJBIhyNsO3u2s8OeBG9hxMglnYzMwNdgdHZ0thC6PiHQcR8qJiIjqkamhHmaM7IR/TfCFSq3G4t8v4KedV1BYrBS6NCLSYQzlREREDcDDxRKfvtwdw3o441RMBj5YfQqRl9Oh5oOgRFQDhnIiIqIGIpdJMLavK/5velfYWBggZMcVfPPnX8i8c1fo0ohIxzCUExERNTAHa2O8P7kzJg/ugPjUfHz40xnsjExCeYVK6NKISEfwQU8iIqJGIBaL0N/fAX7tFfjfvmvYciQBp69kYFqwO1xbmwldHhEJjCPlREREjcjCRI7ZY7wwd4wXikrK8fn68/ht71UUl5YLXRoRCYgj5URERALw66CAu7MFwo4m4MD5FFy4fhsTB3ZAZzeF0KURkQA4Uk5ERCQQA7kUEwd1wMKpXWBsIMOKsEtYviUaOfklQpdGRI2MoZyIiEhgbe1N8eG0LhjX1xUxiTlYuOY09p9LhkrF5ROJWgqGciIiIh0glYgxtIczPn2lO9q3NsP/9l/HovXncSujQOjSiKgRMJQTERHpEGtzA7w53gevPtMJt/OK8emv57Dp0A2UKiuELo2IGhAf9CQiItIxIpEIPTrZwtPFCpsO3cCu07dwNi4TU4e4wbOtldDlEVED4Eg5ERGRjjI2kOHFYR3x3kQ/SCVifLPxIlZvi0F+UZnQpRFRPWMoJyIi0nFuThb45KVueCawDc7GZWJhyCkcu5gKtZoPghI1F5y+QkRE1ATIpGKM7tUW3TraYN3uOPyyKw6RMemYMsQNSekFCD0Sj+z8UliZyjGmjysCPGyFLpmI6kCk5p/ZAIDs7MJGX3pKoTBBVhafqr+P/aGN/VGFfUGkTaVW49jFVGw6FI/isnKIRSJU/ON3mJ5UjGlD3RnMiXSMWCyClZVxze81ci1ERET0lMQiEfr4tsaiGd0hk4i1AjkAlJWrEHokXqDqiOhJMJQTERE1UWbGcpSVq2p8Lzu/tJGrIaKnwVBORETUhFmZymtsl4hFOBeXyV1BiZoIQUN5WVkZFi9ejKCgIHh7e2P8+PGIjIx87Hnbtm3D1KlTERgYCE9PT/Tv3x/vv/8+/v7770aomoiISHeM6eMKPan2r3OJWARDfSlWbr2MhWtO49jFVJRX1DyiTkS6QdDVVxYsWIC9e/di6tSpcHZ2RlhYGGbMmIH169fDz8/voefFxcXBxsYGffr0gZmZGVJTU7Fx40YcPnwY27Ztg0KhaMSvgoiISDj3H+Z8cPWV7h1tcO5qJnZG3sQvu+Kw9Xgigrs5obePPeR6EoGrJqIHCbb6SnR0NMaNG4f3338f06dPBwCUlpZixIgRsLa2xoYNG+p0vZiYGIwZMwbvvvsuXn755TrXw9VXhMf+0Mb+qMK+IHpyarUalxJyEBGZhGspeTA2kGFgFwcM6OwAI32Z0OURtSiPWn1FsJHy3bt3QyaTYdy4cZo2uVyOsWPHYunSpcjMzIS1tXWtr2dvbw8AyM/Pr/daiYiImiqRSARvVyt4u1rhekoudkbexNZjidh1+hb6+bbG4G6OMDeueV46ETUewUJ5bGwsXFxcYGRkpNXu7e0NtVqN2NjYx4by3NxcVFRUIDU1FStWrAAABAQENFjNRERETVl7B3PMH2eO5MxCRJy6iT1nb2H/+WQEedkhuLsTrC0MhS6RqMUSLJRnZWXBxsamWvv9+eCZmZmPvcaQIUOQm5sLADA3N8dHH32EHj161G+hREREzYyjtTFee8YDo3u5YPfpWzh+KQ1HLqaiW0cbDOvhDEfrmj9eJ6KGI1goLykpgUxWfS6bXF75EVpp6ePXV/3+++9x9+5dJCYmYtu2bSgqKnrieh42v6ehKRQmgtxXV7E/tLE/qrAviOqfQmECzw42eDGvGOFHE7DrZCJOX8lAl442GDegPTq5WAldIlGLIVgo19fXh1KprNZ+P4zfD+eP0rVrVwBAnz59MGDAAIwcORKGhoaYPHlynevhg57CY39oY39UYV8QNbyRPZzQz8cOB8+nYP/5FLz3/XF0cDDD8J5t4OliCZFIJHSJRE3eox70FGydcoVCUeMUlaysLACo00OeAODo6AgPDw9s3769XuojIiJqaYwNZHgmyAWLZ/bE8wPaIyuvBEs3XsQnv57FmdgMbkRE1IAEC+Xu7u5ITEysNuXk4sWLmvfrqqSkBAUFHE0jIiJ6GnI9CQZ3dcRXrwfgxaHuKFWq8EN4DBaGnMLRi6lQlnMjIqL6JlgoDw4OhlKpxKZNmzRtZWVlCA0Nhb+/v+Yh0NTUVMTHx2udm5OTU+16ly9fRlxcHDw8PBq2cCIiohZCKhGjl489Fr3SHTNHe0KuJ8Gvu+Kw4MdI7DlzCyVl5UKXSNRsCDan3MfHB8HBwViyZAmysrLg5OSEsLAwpKam4osvvtAc99577+HMmTO4evWqpq1fv34YOnQoOnToAENDQ9y4cQNbtmyBkZERZs2aJcSXQ0RE1GyJxSJ0dbdGFzcFYhJzsDPyJv48eAM7TiZhYBdHDOjsAGMDbkRE9DQEC+UA8PXXX2PZsmUIDw9HXl4e3NzcsHr1anTu3PmR502cOBGRkZHYv38/SkpKoFAoEBwcjFmzZsHR0bGRqiciImpZRCIRPNtawbOtFW78nYeIyJsIP56I3advoY+vPYZ0c4KFCTciInoSIrVazac2wNVXdAH7Qxv7owr7gkh3pdzbiOh0bAYkYhF6etphaA8n2HAjIqJqHrX6iqAj5URERNS0OVgb49VnPDC6d9vKjYii03AsOhVd3a0xrIcznGy4xwBRbTCUExER0VOzNjfA1CFueCawDfadTcahC3/jTGwmvNpaYXiAMzo4mgtdIpFO4/SVezh9RXjsD23sjyrsC6Kmp6hEiYNRf2Pf2WQUFivR3sEMwwOc4dXWihsRUYvF6StERETUqIz0ZRjZsw0Gd3XE0Yup2HPmFpZtioajtTGG9XBGV3driMUM50T3caT8Ho6UC4/9oY39UYV9QdT0lVeocComAxGnbiI95y6szQ0Q3MMJgZ52kEkF2zaFqFFxpJyIiIgEJZWIEeRth56etoi6loWdp25i3e6rCD+eiCFdndDH1x4GcsYSark4Un7P40bKlcoyFBTkory8DCpVRb3cUywWQ6XiVsX3NYf+kEikMDY2h4GB0VNfi6PDVdgXRM2PWq3GlaQ72BmZhLhbuTDSl2JAZwcM7OLIjYio2XrUSDlD+T2PCuXFxUUoKLgDY2MzyOUGEIsl9fKQilQqRnl50w6h9amp94darYZSWYbc3CyYmFg8dTBnEK3CviBq3uL/zkPEqZu4cP029GRi9PVtjcFdHWFpqi90aUT1iqG8Fh4VyrOyUmFmZgk9vfr94dDUQ2h9ay79UVZWiry821AoWj/VdRhEq7AviFqGlKxC7Dp1E6evZEIkAnp62mJoD2fYWnIjImoeOKf8KVVUKCGTcdtgqh2ZTA8VFeVCl0FE1OQ4KIwxY6QHRvdqi91nbuHYxTQcj05DZ3drDO/hDGdbbkREzRdDeS1xTVWqLX6vEBE9HYW5AaYMdsMzgS73NiJKwbm4THi6WGo2IuLPWmpuGMqJiIhIJ5kZ6WFsX1cM6+FUuRHRuWR89b8LaNfaDMMCnOHjyo2IqPlgKKcGNWfOqwCA779f3ajnEhFR82GoL8OInm0wqKsjjkenYffpm/huczQcFEaVGxF1tIZEzLXOqWljKG+hgoK61Oq4TZu2wc7OvoGrISIiejy5TIIBnR3Qx9cep69UbkS0evsVhB1LQHB3ZwR52UImlSAyJh2hR+KRnV8KK1M5xvRxRYCHrdDlEz0SV1+551Grr6Sn34StrXO931PI1Ub27InQer1x4+/IyEjD3LlvabX37t0PBgYGT3wfpVIJAJDJHr/m7IP9UZdzdU19fM9wxZEq7AsiqolKrcZf129jZ2QSEtMKYGakBzcnc1y4fhvKf/w+0ZOKMW2oO4M5CY6rr1A1Q4YM03p9+PAB5OXlVmt/UElJCfT1a7805NME6qYYxomIqPGIRSL4d1DAr30rxN68g52RN3EmNrPacWXlKoQeiWcoJ53GCVj0UHPmvIrp0yfiypXLmDnzZfTvH4gNG9YCAI4dO4x33pmHUaOC0a9fAMaPH4Vff12DioqKate4PzccAKKiziEoqAuOHDmIX39dg9Gjh6J//56YN28mkpNvPfG5KSnJ1erfsmUjxo0bhf79AzFjxlRcvHih2jWJiKjpE4lE6NTGEu+84PfQY7LzSxuxIqK640i5QCJj0hF6NAHZeSU6Pd8tN/cO3n33TQweHIzg4OGwsamsMSJiBwyCKGKYAAAgAElEQVQMDDFhwiQYGhrg/PlzWLPmBxQVFWH27HmPve7atT9BLJZg4sSpKCjIx++/r8f//d+/sXr1r0907ief/BshIWs1x4SFbcbSpV/D19cfEya8gLS0NLz//tswMTGBQmH9xP1BRES6zcpUXmMAF4mAPw9eR5CXHVorap4+QCQkhnIBRMakY+2uOJTdm++WnV+KtbviAEDngvnt21lYsOBDjBgxSqv944//A7m8ahrL6NFjsXjx5wgL24QZM2ZCT0/vkdctLy/Hzz+vhVRa+S1oamqGb79dgoSEG2jbtt1TnatUKrFmzSp4eHhh2bKVmuPatWuPRYs+ZignImrGxvRx1fodCwBSiQitFcbYfy4Fe84kw8XOFEHeduje0RqG+pwqSbqBofwpnLhUudNYXcWn5qG8Qvuh0rJyFX6JiMXRv1LrfL0gbzsEetnV+bza0NfXR3Dw8Grt/wzkd+8WoaxMCR8fP4SHh+LmzSS0b9/hkdcdPvwZTVgGAB8fXwBAaurfjw3ljzs3Lu4K8vLyMGvWs1rHDRoUjO++++aR1yYioqbt/uBWTauv5BeV4VRMOo5dSsP6PVfxx4Hr6NxBgUBvO3R0toCYa56TgBjKBfBgIH9cu5AUCmutYHtfQkI8QkJWISrqLIqKirTeKyoqfOx170+Duc/ExBQAUFDw+BU2HnduenrlH0oODo5ax0mlUtjZNcwfL0REpDsCPGxr/OTZ1EgPg7s5YVBXRySlF+D4pTScjsnAqSsZsDLVR6CXLQK97KAwf/JVx4ieFEP5Uwj0erIR6ndWnqhxvpuVqRzvTfKvj9LqzT9HxO8rKCjA3LmvwtDQGC+//Dpat3aAnp4erl2Lw6pVy6FSPX6ZR7FYUmN7bVbofJpziYiIRCIRXOxM4WJniuf7t0PUtds4Hp2K7SeSsO1EEtydzNHL2x7+bgrIZTX/ziGqbwzlAqhpvpueVIwxfVwFrKr2Llw4j7y8PCxatBi+vlV/RKSl1X3qTUOwta38QyklJRk+PlVP4peXlyMtLQ2uro+eHkNERC2HTCpB90426N7JBtl5JThxOQ0nLqUhZMcVGOyToFtHGwR52aGtvSlEnN5CDYihXACa+W5NYPWVmojvbWX8z5FppVKJsLBNQpWkxd29E8zMzLBtWxiGDBmmmX6zb99uFBTkC1wdERHpKiszfTwT6IIRPdvgenIujkWnITImHUf+SoWdlSGCvO3Q08MWZsZyoUulZoihXCABHrbo5WMv2I6eT8PLyxsmJqZYtOhjjB07ASKRCHv2REBXZo/IZDK89NKrWLp0MebPn4V+/QYgLS0Nu3ZtR+vWDhzpICKiRxKLRHBzsoCbkwUmDeqAs3GZOB6dhk2H4rHlcAK8Xa0Q6GUHn3ZWkEq45QvVD4ZyqjMzM3N8/fVSfP/9MoSErIKJiSkGDx6KLl264a235ghdHgDguecmQK1W448/NmDFim/h6toeX375DZYtWwI9PY5wEBFR7RjIpejtY4/ePvZIyy7C8UtpOHk5HX/duA0TQxkCPGwR5GUHB2uufU5PR6Tm03EAgOzsQqhUNXdFevpN2No61/s9pVJxkxwpbygN3R8qlQojRgxCnz798N57/26w+wD18z2jUJggK+vxq9G0BOwLItIlFSoVLifk4PilNPx1/TYqVGq0sTVBL287dOtkAyOufU4PIRaLYGVV8x9wHCmnZqm0tBRyufaI+O7dO5Gfnwc/v84CVUVERM2BRCyGT7tW8GnXCgV3y3AqJgPHotOwfu81/H7gBvw7tEIvb/vKtc/FnDJJtcNQTs1SdPRfWLVqOfr27Q9TUzNcuxaHnTu3oW1bV/TrN1Do8oiIqJkwMdTDoK6OGNjFAbcyCnEsOhWnr2TgTGwmLE3lCPS0Q6C3Hay59jk9BkM5NUv29q3RqpUCmzf/ifz8PJiamiE4eDhef30OZDJ+rEhERPVLJBLB2dYEzrZumNC/HS5cv43j0WnYcTIJ209Wrn0e6GWHLm7WkOtx7XOqjnPK7+GccuE1p/7gnPL6xb4goqYqJ78EJy6n40R0GjJzi6GvJ0G3jtYI8raHK9c+b3E4p5yIiIhIAJam+hjZsw1GBDjjekoejkWn4tSVDBy9mAZby3trn3vawpxrn7d4DOVEREREDUwkEqGDozk6OJpj4sAOOBeXieOX0rD5cDxCjyTAs60lennbwaddK6593kIxlBMRERE1IgO5FL187NHLxx7pOXdx4lIaTlxKw4qwbBgb3Fv73NsOjlz7vEVhKCciIiISiK2lIZ7r44rRvVwQk3gHx6NTcTAqBfvOJcPZxgRB3nbo3skGxgZcpKC5YygnIiIiEphELIa3qxW8Xa1QWKzEqZh0HI9Ow4Z91/Dnwevw76BAkJcdOrWx5NrnzRRDOREREZEOMTaQYWAXRwzs4oib6QU4fikNp2LScSY2ExYmcgR62SLQyw42FoZCl0r1iKGciIiISEdVrn1ugvH92uGvG5Vrn++MvIkdJ2+ig6M5grzs0MVdAX09Rrqmjv+CRERERDpOJhWjq7s1urpb405BKU5eTsPx6DT8HBGLDfuvoau7NXp526FdazOufd5Ecc0dqhcREdsRFNQFaWmpmraxY0di0aKPa31uamrqY4+traiocwgK6oKoqHP1dk0iIiJdYGEix/CANvj81R5YMMkfXd2tcTY2E1/8FoUPQk5jZ2QS7hSUAgAiY9LxzsoTeOnLg3hn5QlExqQLWzw9FEfKW6h3330TUVFnsX37PhgYGNR4zFtvzUFMzCVs27YXcrlubmqwf/8e5ORkY/z4iUKXQkRE1Ki01z5vj3NxWTh+KQ1bjiQg9GgCHBRGSMu+i/KKyh3Ls/NLsXZXHAAgwMNWyNKpBgzlLdSgQUNw8uQxHD9+BIMGBVd7/86dHJw/fxaDBw994kD+v/9tgVjcsB/GHDiwF9evX6sWyn19/XHgwAnIZFxCioiImj99PSmCvO0Q5G2HjDuVa59HRN6ESq19XFm5CqFH4hnKdZCg01fKysqwePFiBAUFwdvbG+PHj0dkZORjz9u7dy/mz5+P/v37w8fHB8HBwfjqq69QUFDQCFU3D7169YWBgSH2799T4/sHD+5HRUUFBg+uHthrS09PD1KpMH/3icViyOXyBv+jgIiISNfYWBhiTG/XaoH8vuz8Uny3ORrbTyYhJjEHRSXKxi2QaiToSPmCBQuwd+9eTJ06Fc7OzggLC8OMGTOwfv16+Pn5PfS8Dz/8ENbW1hg1ahTs7e1x9epVrF+/HseOHcOWLVt0dqqFLtHX10evXn1w6NB+5Ofnw9TUVOv9/fv3wMrKCo6Ozliy5EucP38GGRkZ0NfXh79/F8yePQ92dvaPvMfYsSPh59cZCxd+rGlLSIjHsmWLcfnyJZiZmWHUqDFo1UpR7dxjxw5j27YwXLt2Ffn5eVAorDFs2EhMmfIiJBIJAGDOnFfx119RAICgoC4AAFtbO2zevB1RUefwxhuv47vvfoC/fxfNdQ8c2IvffvsVN28mwdDQCIGBvTBz5hswNzfXHDNnzqsoLCzERx99im+++RqxsTEwMTHFuHHPY9KkaXXraCIiIoFYmcqRnV9arV0uEyPjzl38deO2ps3G0hBt7UzgYmcKF3tTOFkbQyaVNGa5LZ5goTw6Oho7d+7E+++/j+nTpwMARo8ejREjRmDJkiXYsGHDQ8/97rvv0L17d602T09PvPfee9i5cyfGjBnTkKXXizPpUdiesBs5JbmwkJvjGddgdLP1b9QaBg0Kxt69u3D48AE888yzmvb09DRcvhyNsWOfR2xsDC5fjsbAgUOgUFgjLS0VW7duwdy5r+G33zZBX1+/1vfLzr6NN954HSqVCpMnT4O+vgG2bQur8Y+oiIgdMDAwxIQJk2BoaIDz589hzZofUFRUhNmz5wEApk17CcXFxcjISMPcuW8BAAwMHr5ma0TEdnz++Sfw8PDCzJlvIDMzA1u2/InY2BiEhKzTqiM/Pw//+tcb6NdvAAYMGIxDh/Zj1arlaNu2HQICAmv9NRMREQllTB9XrN0Vh7JylaZNTyrG1GB3BHjY4m5JOZLS85GYlo+E1HzE3cpFZEwGAEAiFsHB2hht7Uw1Qd3OyhBiruzSYAQL5bt374ZMJsO4ceM0bXK5HGPHjsXSpUuRmZkJa2vrGs99MJADwMCBAwEA8fHxDVNwPTqTHoX/xW2BUlX5cdGd0lz8L24LADRqMO/atTvMzS2wf/8erVC+f/8eqNVqDBo0BK6u7dCv30Ct8wIDe+P111/E4cMHEBw8vNb327BhLfLycrFmzXq4ubkDAIYOHYEXXni22rEff/wfyOVVgX/06LFYvPhzhIVtwowZM6Gnp4euXXsgNHQT8vJyMWTIsEfeu7y8HKtWLUe7dh2wfPmP0NPTAwC4ubnj448XYvv2MIwd+7zm+MzMDPzf//1HM99+xIhRGDt2BHbuDGcoJyKiJuH+vPHQI/HIzi+FlakcY/q4atoN9aXo1MYSndpYas65U1CKxLSqoH7qSjoOXfgbAKCvJ0EbWxO42JtqwrqFiZxLMNYTwUJ5bGwsXFxcYGRkpNXu7e0NtVqN2NjYh4bymty+XfkRjIWFRb3W+Sin084jMu1snc9LzLuFcnW5VptSpcSG2M04mXqmztcLsOuK7nad63yeVCpF//4DsXXrFty+fRutWrUCAOzfvxcODo7o1MlT6/jy8nIUFRXCwcERxsYmuHYtrk6hPDLyBLy8fDSBHKj89xo0aCjCwjZpHfvPQH73bhHKypTw8fFDeHgobt5MQvv2Her0tcbFXcGdOzmaQH9f//6DsGLFtzh58oRWKDc2NsbAgUM0r2UyGTp29EBq6t91ui8REZGQAjxs6/RQp4WJHBYmCvh3qJxaqlKrkZFzFwmp+ZqwvvdMMiruTVg3M9arGk23M4WLnQkM9bnIwpMQLJRnZWXBxsamWrtCUflNkJmZWafrhYSEQCKRYPDgwfVSX0N6MJA/rr0hDRoUjNDQTTh4cC/Gj5+IpKRE3LhxDS++OAMAUFpagvXrf0VExHZkZWVCra56aqSwsLBO98rISIeXl0+1dicn52ptCQnxCAlZhaiosygqKtJ6r6iobvcFKqfk1HQvsVgMBwdHZGSkabVbW9tU+8vfxMQU8fE36nxvIiKipkosEsHOygh2VkYI9LIDACjLVUjJKtQK6heuc3760xIslJeUlNS4XN39eb2lpdUfTHiY7du3Y/PmzXjttdfg5OT0RPVYWRk/9L3MTDGk0uqreAQ6dkWgY9c63+v9o/9BTklutXZLfXO83W1Wna/3NPz8/GBv3xr79+/BxImTceBA5WosQ4cOg1QqxldfLcHOndswYcJEeHl5w8jIGCKRCB9++D4AaPpFLK4MsBKJdl+JRCKt12KxqFpf3j/3/vUKCgowd+5rMDIywquvzkTr1g7Q05Pj6tVYrFjxHUSiqvveD84PXlMiEWvVU/W6+v0fvIZIJIJEIqnxOLVaXeP3woPEYjEUCpPHHvc49XGN5oJ9QUSkO+ztzNDNu7XmdWGxEvHJubiWfAfXbt3B1Vt3NPPTpRIR2tibVa6p7mSBDk4WaK0w1vr9TwKGcn19fSiV1ZfguR/Ga7uCyrlz57Bw4UL07dsX8+bNe+J6srMLoXrI2kEqlQrl/3hI4mmNbBusNaccAGRiGUa2Da7X+9TWgAGDsX79L0hKuol9+/bAza0j7O0dUV6uwqFD+xEcPByzZ8/XHF9aWorCwgKo1WpNvff7rqJCu6/+eYyNjS1u3bpV7WtMSkrS/H95uQpnz55FXl4uFi36Gr6+VXPsU1JSqt3j/sD9g9esqFBpHatQVH4qk5iYBC+vqpV91Go1kpNvwcXF9R/XVEOtrn7N+58S1ObfSKVSISvr6ZboVChMnvoazQX7gohI99lb6MPewg59vStH1O8UlGqNph86n4yIk0kAWu78dLFY9NCBYMFCuUKhqHGKSlZWFgDUaj55XFwcZs6cCTc3NyxdulSzVJ6uu/8wp9Crr9w3ePBQrF//C77/filSUpIxd+6bmvfE4up9umXLn6ioqKjzfQICArFp0x+4ejVOM6/8zp072Ldvl9Zx99cW/+dUGaVSWW3eOQAYGBjUahqNu3snWFhYYuvWzRg6dITmU5pDhw4gKysTkyZNrfPXQ0RERA9nYSJHZzcFOrs9wfx0e1O42Las+emChXJ3d3esX78eRUVFWg97Xrx4UfP+o9y6dQuvvPIKLC0t8eOPP8LQ8OFL4emibrb+6OnQRZCR8Qe5uLRFu3YdcPz4UYjFYgwYUPWAY8+eQdizJwJGRsZo08YFMTGXcO7cGZiZmdX5PhMnTsOePRF4663ZGDv2ecjl+ti2LQw2NnYoLLyuOc7LyxsmJqZYtOhjjB07ASKRCHv2REBdwwcZbm7u2Lt3F5Yv/wbu7p1gYGCIoKDe1Y6TSqWYOXMuPv/8E8yd+xoGDhyMzMwMbN78J9q2dcXIkdVXgCEiIqL687D56cmZhZrVXh6cn25raQgXO1O0ta8M647WxpDVYhppUyRYKA8ODsbPP/+MTZs2adYpLysrQ2hoKPz9/TUPgaampqK4uBiurq6ac7OysvDSSy9BJBLhp59+gqWlZU23oDoYPDgYN25cg59fZ80qLAAwb97bEIvF2LdvF0pLy+Dl5YNly1bgrbfm1vkerVq1wnff/YilS7/G+vW/am0e9OWXn2mOMzMzx9dfL8X33y9DSMgqmJiYYvDgoejSpRveemuO1jVHjXoO167FISJiB/7883+wtbWrMZQDwLBhI6Gnp4cNG9ZixYpvYWRkhEGDgvH663O54RQREZEAZFIx2tpXhu4B9xaSu1uiRGJ6ARLvhfQrN3MQGZMOoHL9dEdrY61pL7bNZP10kVpd0/hj45g3bx4OHDiAadOmwcnJCWFhYbh8+TLWrl2Lzp0r/2WmTJmCM2fO4OrVq5rzRo0ahbi4OLzyyivo0EF7aTwnJ6dH7gb6MI+aU56efhO2ttVXCHlaUqlYJ0bKdUVz6o/6+J7hPOoq7AsiopbtwfnpiWn5KCmrnEprIJegjW3Vsoxt7Svnp9ckMib9oeu2NwadnFMOAF9//TWWLVuG8PBw5OXlwc3NDatXr9YE8oeJi4sDAKxZs6bae88+++wThXIiIiIi0k01zU9Pz75bOe0lLR+JqfnYc+aWZn66ubGeJqC3saucn34xPltrh9Ps/FKs3VWZKRszmD+MoCPluoQj5cJrTv3BkfL6xb4gIqLHUZZX4FZmIZLSCjSj6uk5dzXvi8WiGrOelakci2c1zm7dOjtSTkRERERUH2RSCVztzeBqb1bj/PTQowk1npedX/u9cRpS83x8lYiIiIhaPEN9GTzaWGJEzzawMq15nvnD2hsbQzkRERERNXtj+rhC74HlFPWkYozp4/qQMxoXp68QERERUbN3/2FOIVdfeRSG8lpSq9XNfutXqh98dpqIiEg3BXjY6kwIfxCnr9SCRCKDUqkbDwGQ7lMqyyCR8O9dIiIiqj2G8lowNjZDbu5tFBUVoKKinCOhVCO1Wo2yslLk5mbB2Nhc6HKIiIioCeFwXi0YGBhBKpWhsDAXRUV5UKkq6uW6YrEYKlXzWJe7PjSH/pBIpDAxsYCBgZHQpRAREVETwlBeSzKZHiwsrOv1mtwQRRv7g4iIiFoqTl8hIiIiIhIYQzkRERERkcAYyomIiIiIBMZQTkREREQkMIZyIiIiIiKBcfWVe8RiYXbrFOq+uor9oY39UYV9QURETd2jfpeJ1NwJh4iIiIhIUJy+QkREREQkMIZyIiIiIiKBMZQTEREREQmMoZyIiIiISGAM5UREREREAmMoJyIiIiISGEM5EREREZHAGMqJiIiIiATGUE5EREREJDCGciIiIiIigUmFLqClyczMxLp163Dx4kVcvnwZd+/exbp169C9e3ehS2t00dHRCAsLw+nTp5Gamgpzc3P4+flh/vz5cHZ2Frq8Rnfp0iX88MMPuHLlCrKzs2FiYgJ3d3fMnj0b/v7+QpcnuJCQECxZsgTu7u4IDw8XuhwiIqJ6xVDeyBITExESEgJnZ2e4ubnhwoULQpckmDVr1iAqKgrBwcFwc3NDVlYWNmzYgNGjR2Pz5s1wdXUVusRGlZycjIqKCowbNw4KhQIFBQXYvn07Jk+ejJCQEAQGBgpdomCysrKwatUqGBoaCl0KERFRgxCp1Wq10EW0JIWFhVAqlbCwsMD+/fsxe/bsFjtSHhUVBU9PT+jp6WnakpKSMHLkSAwfPhxffvmlgNXphuLiYgwcOBCenp748ccfhS5HMAsWLEBqairUajXy8/M5Uk5ERM0O55Q3MmNjY1hYWAhdhk7w9/fXCuQA0KZNG7Rv3x7x8fECVaVbDAwMYGlpifz8fKFLEUx0dDS2bduG999/X+hSiIiIGgxDOekUtVqN27dvt+g/XAoLC5GTk4OEhAR88803uHbtGgICAoQuSxBqtRqfffYZRo8ejY4dOwpdDhERUYPhnHLSKdu2bUNGRgbefPNNoUsRzAcffIA9e/YAAGQyGZ5//nm8/vrrAlcljK1bt+LGjRtYsWKF0KUQERE1KIZy0hnx8fH49NNP0blzZ4waNUrocgQze/ZsTJgwAenp6QgPD0dZWRmUSmW1qT7NXWFhIf773//i1VdfhbW1tdDlEBERNShOXyGdkJWVhddeew1mZmb49ttvIRa33G9NNzc3BAYG4rnnnsNPP/2EmJiYFjmfetWqVZDJZHjxxReFLoWIiKjBtdzkQzqjoKAAM2bMQEFBAdasWQOFQiF0STpDJpNhwIAB2Lt3L0pKSoQup9FkZmZi7dq1mDhxIm7fvo2UlBSkpKSgtLQUSqUSKSkpyMvLE7pMIiKiesPpKySo0tJSvP7660hKSsKvv/6Ktm3bCl2SzikpKYFarUZRURH09fWFLqdRZGdnQ6lUYsmSJViyZEm19wcMGIAZM2bg7bffFqA6IiKi+sdQToKpqKjA/Pnz8ddff2HlypXw9fUVuiRB5eTkwNLSUqutsLAQe/bsgZ2dHaysrASqrPE5ODjU+HDnsmXLcPfuXXzwwQdo06ZN4xdGRETUQBjKBbBy5UoA0KzFHR4ejvPnz8PU1BSTJ08WsrRG9eWXX+LgwYPo168fcnNztTaEMTIywsCBAwWsrvHNnz8fcrkcfn5+UCgUSEtLQ2hoKNLT0/HNN98IXV6jMjExqfHff+3atZBIJC3ue4OIiJo/7ugpADc3txrbW7dujYMHDzZyNcKZMmUKzpw5U+N7La0vAGDz5s0IDw/HjRs3kJ+fDxMTE/j6+uKll15Ct27dhC5PJ0yZMoU7ehIRUbPEUE5EREREJDCuvkJEREREJDCGciIiIiIigTGUExEREREJjKGciIiIiEhgDOVERERERAJjKCciIiIiEhhDORERERGRwBjKiYhIMFOmTEH//v2FLoOISHBSoQsgIqL6dfr0aUydOvWh70skEly5cqURKyIiosdhKCciaqZGjBiB3r17V2sXi/khKRGRrmEoJyJqpjp16oRRo0YJXQYREdUCh0uIiFqolJQUuLm5Yfny5dixYwdGjhwJLy8v9O3bF8uXL0d5eXm1c+Li4jB79mx0794dXl5eGDZsGEJCQlBRUVHt2KysLPznP//BgAED4OnpiYCAALz44os4ceJEtWMzMjLw1ltvoWvXrvDx8cHLL7+MxMTEBvm6iYh0EUfKiYiaqeLiYuTk5FRr19PTg7Gxseb1wYMHkZycjEmTJqFVq1Y4ePAgvv/+e6SmpuKLL77QHHfp0iVMmTIFUqlUc+yhQ4ewZMkSxMXF4b///a/m2JSUFLzwwgvIzs7GqFGj4OnpieLiYly8eBEnT55EYGCg5ti7d+9i8uTJ8PHxwZtvvomUlBSsW7cOs2bNwo4dOyCRSBqoh4iIdAdDORFRM7V8+XIsX768Wnvfvn3x448/al7HxcVh8+bN8PDwAABMnjwZc+bMQWhoKCZMmABfX18AwKJFi1BWVoY//vgD7u7ummPnz5+PHTt2YOzYsQgICAAAfPLJJ8jMzMSaNWvQq1cvrfurVCqt13fu3MHLL7+MGTNmaNosLS2xePFinDx5str5RETNEUM5EVEzNWHCBAQHB1drt7S01Hrds2dPTSAHAJFIhFdeeQX79+/Hvn374Ovri+zsbFy4cAGDBg3SBPL7x86cORO7d+/Gvn37EBAQgNzcXBw7dgy9evWqMVA/+KCpWCyutlpMjx49AAA3b95kKCeiFoGhnIiomXJ2dkbPnj0fe5yrq2u1tnbt2gEAkpOTAVROR/ln+z+1bdsWYrFYc+ytW7egVqvRqVOnWtVpbW0NuVyu1WZubg4AyM3NrdU1iIiaOj7oSUREgnrUnHG1Wt2IlRARCYehnIiohYuPj6/WduPGDQCAo6MjAMDBwUGr/Z8SEhKgUqk0xzo5OUEkEiE2NrahSiYianYYyomIWriTJ08iJiZG81qtVmPNmjUAgIEDBwIArKys4Ofnh0OHDuHatWtax65evRoAMGjQIACVU0969+6No0eP4uTJk9Xux9FvIqLqOKeciKiZunLlCsLDw2t8737YBgB3d3dMmzYNkyZNgkKhwIEDB3Dy5EmMGjUKfn5+muMWLlyIKVOmYNKkSZg4cSIUCgUOHTqE48ePY8SIEZqVVwDgww8/xJUrVzBjxgyMHj0aHh4eKC0txcWLF9G6dWu88847DfeFExE1QQzlRETN1I4dO7Bjx44a39u7d69mLnf//v3h4uKCH3/8EYmJibCyssKsWbMwa9YsrXO8vLzwxx9/4LvvvsPvv/+Ou3fvwtHREW+//TZeeuklrWMdHR2xZcsWrFixAkePHkV4eDhMTU3h7u6OCRMmNMwXTETUhInU/ByRiKhFSklJwYABAwlEamsAAABpSURBVDBnzhzMnTtX6HKIiFo0ziknIiIiIhIYQzkRERERkcAYyomIiIiIBMY55UREREREAuNIORERERGRwBjKiYiIiIgExlBORERERCQwhnIiIiIiIoExlBMRERERCYyhnIiIiIhIYP8P6c4+zvy2V+YAAAAASUVORK5CYII=\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"IT4-LcM-iPn8"},"source":["#Performance on test set"]},{"cell_type":"code","metadata":{"id":"8VipplfqhBhS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636654332271,"user_tz":-60,"elapsed":330,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"04efdcc3-21a1-4dfd-d88b-a6957c2179b8"},"source":["import pandas as pd\n","\n","# # Load the dataset into a pandas dataframe.\n","#test_df = pd.read_csv(\"Datasets/es_lcc_new.csv\")\n","\n","# # Report the number of sentences.\n","print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n","\n","# # Create sentence and label lists\n","sentences = test_df.sentence.values.astype(str)\n","labels = test_df.label.values\n","\n","# # Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# # For every sentence...\n","for sent in sentences:\n","#     # `encode_plus` will:\n","#     #   (1) Tokenize the sentence.\n","#     #   (2) Prepend the `[CLS]` token to the start.\n","#     #   (3) Append the `[SEP]` token to the end.\n","#     #   (4) Map tokens to their IDs.\n","#     #   (5) Pad or truncate the sentence to `max_length`\n","#     #   (6) Create attention masks for [PAD] tokens.\n","     encoded_dict = tokenizer.encode_plus(\n","                         sent,                      # Sentence to encode.\n","                         add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                         max_length = 64,           # Pad & truncate all sentences.\n","                         pad_to_max_length = True,\n","                         return_attention_mask = True,   # Construct attn. masks.\n","                         return_tensors = 'pt',     # Return pytorch tensors.\n","                    )\n","    \n","#     # Add the encoded sentence to the list.    \n","     input_ids.append(encoded_dict['input_ids'])\n","    \n","#     # And its attention mask (simply differentiates padding from non-padding).\n","     attention_masks.append(encoded_dict['attention_mask'])\n","\n","# # Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# # Set the batch size.  \n","batch_size = 32  \n","\n","# # Create the DataLoader.\n","prediction_data = TensorDataset(input_ids, attention_masks, labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of test sentences: 1,872\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"HLjiQA_TiUbi"},"source":["#Evaluation on test set"]},{"cell_type":"code","metadata":{"id":"Gnv1WjdwhBrg","executionInfo":{"status":"ok","timestamp":1636654332272,"user_tz":-60,"elapsed":7,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["# # Prediction on test set\n","\n","# print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n","\n","# # Put model in evaluation mode\n","# model.eval()\n","\n","# # Tracking variables \n","# predictions , true_labels = [], []\n","\n","# # Predict \n","# for batch in prediction_dataloader:\n","#   # Add batch to GPU\n","#   batch = tuple(t.to(device) for t in batch)\n","  \n","#   # Unpack the inputs from our dataloader\n","#   b_input_ids, b_input_mask, b_labels = batch\n","  \n","#   # Telling the model not to compute or store gradients, saving memory and \n","#   # speeding up prediction\n","#   with torch.no_grad():\n","#       # Forward pass, calculate logit predictions\n","#       outputs = model(b_input_ids, token_type_ids=None, \n","#                       attention_mask=b_input_mask)\n","\n","#   logits = outputs[0]\n","\n","#   # Move logits and labels to CPU\n","#   logits = logits.detach().cpu().numpy()\n","#   label_ids = b_labels.to('cpu').numpy()\n","  \n","#   # Store predictions and true labels\n","#   predictions.append(logits)\n","#   true_labels.append(label_ids)\n","\n","\n","# print('    DONE.')\n","# print('    predictions:::',predictions)\n","# print('    true_labels:::',true_labels)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"0dmz1QpXteUp","executionInfo":{"status":"ok","timestamp":1636654333055,"user_tz":-60,"elapsed":790,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["model.eval()\n","\n","# Tracking variables \n","predictions , true_labels = [], []\n","\n","# Predict \n","for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels = batch\n","  # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n","  with torch.no_grad():\n","    # Forward pass, calculate logit predictions\n","    logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)[0]\n","\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  true_labels.append(label_ids)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"WfsjU8Upt38K","executionInfo":{"status":"ok","timestamp":1636654333059,"user_tz":-60,"elapsed":30,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["my_submission = pd.DataFrame()\n","my_submission['sentence'] = test_df['sentence']\n","my_submission['arg1'] = test_df['arg1']\n","my_submission['arg2'] = test_df['arg2']\n","my_submission[\"verb\"] = test_df['verb']\n","my_submission['correct_label'] = test_df['label']\n","#my_submission['polarity'] = test_df['polarity']\n","#my_submission['intensity'] = test_df['intensity']\n","#my_submission['source_concept'] = test_df['source_concept']\n","#my_submission['target_concept'] = test_df['target_concept']"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"VNV-BxYnuNZh","executionInfo":{"status":"ok","timestamp":1636654333064,"user_tz":-60,"elapsed":34,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["final_preds = []\n","for p in predictions:\n","    for i in p:\n","        final_preds.append(np.argmax(i))"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"JN1eyJlFuPCc","executionInfo":{"status":"ok","timestamp":1636654333066,"user_tz":-60,"elapsed":35,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["my_submission['label'] = final_preds"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"FDLPomjZuR7W","executionInfo":{"status":"ok","timestamp":1636654333068,"user_tz":-60,"elapsed":36,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["my_submission['label'] = my_submission['label'].map({0:0, 1:1})"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fqo58IR-ufCG","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1636654333069,"user_tz":-60,"elapsed":37,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"2cbe240e-34d3-4082-97d4-d0953d9dd06b"},"source":["my_submission.head()"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>arg1</th>\n","      <th>arg2</th>\n","      <th>verb</th>\n","      <th>correct_label</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>413</th>\n","      <td>When she hears that prisoners sometimes carve ...</td>\n","      <td>she</td>\n","      <td>grabs</td>\n","      <td>child</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>316</th>\n","      <td>Morty Bennett eats a scallop and shrimp entree...</td>\n","      <td>bennett</td>\n","      <td>eats</td>\n","      <td>scallop</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1034</th>\n","      <td>The latest truce in the week-old battle , whic...</td>\n","      <td>which</td>\n","      <td>killed</td>\n","      <td>188</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>All agree that the state must diversify its in...</td>\n","      <td>state</td>\n","      <td>escape</td>\n","      <td>base</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1024</th>\n","      <td>`` It floods the area instead of having hot pi...</td>\n","      <td>it</td>\n","      <td>floods</td>\n","      <td>area</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               sentence  ... label\n","413   When she hears that prisoners sometimes carve ...  ...     1\n","316   Morty Bennett eats a scallop and shrimp entree...  ...     0\n","1034  The latest truce in the week-old battle , whic...  ...     1\n","65    All agree that the state must diversify its in...  ...     1\n","1024  `` It floods the area instead of having hot pi...  ...     1\n","\n","[5 rows x 6 columns]"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"YQs-dWrUw7XN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636654333071,"user_tz":-60,"elapsed":37,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"e384deee-a2b6-453a-c0b4-254e0890d4a2"},"source":["my_submission.shape"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(145, 6)"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"KsIV4fzxxttP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636654333073,"user_tz":-60,"elapsed":35,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"8bf7b805-317c-48e5-d82d-5d25a3302647"},"source":["test_df.label.value_counts()"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    80\n","1    65\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"nTtwGl9vxOoG","executionInfo":{"status":"ok","timestamp":1636654333075,"user_tz":-60,"elapsed":34,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["final = my_submission[(my_submission['correct_label'] == my_submission['label'])]"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"6iVw1NZ2xO0C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636654333391,"user_tz":-60,"elapsed":349,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"bb521720-986f-4a23-bac6-e2f09fdb6380"},"source":["final.shape"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(141, 6)"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"1BoXX0koxO6n","executionInfo":{"status":"ok","timestamp":1636654333392,"user_tz":-60,"elapsed":18,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["final_met = my_submission[(my_submission['correct_label'] == 1) & (my_submission['label'] ==1)]"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"zQGkR9dDxeSg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636654333392,"user_tz":-60,"elapsed":17,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"20988223-a1af-416a-f526-29b82ad18b0c"},"source":["final_met.shape"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(64, 6)"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"RFTH_BCexeY1","executionInfo":{"status":"ok","timestamp":1636654333395,"user_tz":-60,"elapsed":14,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["final_lit = my_submission[(my_submission['correct_label'] == 0) & (my_submission['label'] ==0)]"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"UEwct9X5xehQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636654333396,"user_tz":-60,"elapsed":14,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"3b277ac3-6a22-492a-cf64-53645f40bf75"},"source":["final_lit.shape"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(77, 6)"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"Rs-f8IKraTz5","executionInfo":{"status":"ok","timestamp":1636654333397,"user_tz":-60,"elapsed":12,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["#print(logits)"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"g7YGsSh_uhz7","executionInfo":{"status":"ok","timestamp":1636654333642,"user_tz":-60,"elapsed":256,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["my_submission.to_csv('trofi_sub.csv', index=False)"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"9GYFtiTEk7MP","executionInfo":{"status":"ok","timestamp":1636654333643,"user_tz":-60,"elapsed":8,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["#final_met.to_csv(\"final_met.csv\", index=False)"],"execution_count":44,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Whz6mWvpidb-"},"source":["#Save and load fine-tuned model"]},{"cell_type":"code","metadata":{"id":"73UumM0PhBym","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636654341017,"user_tz":-60,"elapsed":7382,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"043a7892-2db1-4a3f-c7b4-9aa76e0e36cd"},"source":["import os\n","\n","# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n","\n","output_dir = 'stockholm/xlm_code/mixed_models/trofix'\n","# output_dir = './content/xlm-roberta_model_save/'\n","\n","# Create output directory if needed\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","print(\"Saving model to %s\" % output_dir)\n","\n","# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","# They can then be reloaded using `from_pretrained()`\n","model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","model_to_save.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)\n","\n","# Good practice: save your training arguments together with the trained model\n","# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"],"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving model to stockholm/xlm_code/mixed_models/trofix\n"]},{"output_type":"execute_result","data":{"text/plain":["('stockholm/xlm_code/mixed_models/trofix/sentencepiece.bpe.model',\n"," 'stockholm/xlm_code/mixed_models/trofix/special_tokens_map.json',\n"," 'stockholm/xlm_code/mixed_models/trofix/added_tokens.json')"]},"metadata":{},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"LmN96FOqjLKd"},"source":["#Import saved model and test"]},{"cell_type":"code","metadata":{"id":"ScJHWcE5hB4z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636654344586,"user_tz":-60,"elapsed":3590,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"70125fee-fc2e-4b9a-8e30-10b7ddf67508"},"source":["!pip install transformers\n","\n","from transformers import XLMRobertaForSequenceClassification\n","\n","output_dir = 'stockholm/xlm_code/mixed_models/trofix'\n","\n","print(output_dir)"],"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (3.0.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.96)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n","Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.0rc4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.2)\n","Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","stockholm/xlm_code/mixed_models/trofix\n"]}]},{"cell_type":"code","metadata":{"id":"SZbux55ucvy5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636654363940,"user_tz":-60,"elapsed":19362,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"c5794eb4-23a9-4082-daa8-7f092cc15c45"},"source":["from transformers import XLMRobertaTokenizer\n","import torch\n","# Load the BERT tokenizer.\n","print('Loading XLMRobertaTokenizer...')\n","tokenizer = XLMRobertaTokenizer.from_pretrained(output_dir)\n","model_loaded = XLMRobertaForSequenceClassification.from_pretrained(output_dir)"],"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading XLMRobertaTokenizer...\n"]}]},{"cell_type":"code","metadata":{"id":"lhw_GFdIuwR4","executionInfo":{"status":"ok","timestamp":1636654363941,"user_tz":-60,"elapsed":19,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":[""],"execution_count":47,"outputs":[]}]}