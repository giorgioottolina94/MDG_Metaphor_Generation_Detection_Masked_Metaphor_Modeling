{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"Copia di mohx_xlm.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"11351a3cd50b42949c584ca99b6d808f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_76e855caee5d4dfda9f0b3a5b98af1cb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_93ae668247d2445d92638585e4740c7f","IPY_MODEL_14ff54a1e86948e3a2853e9bdfd408f9","IPY_MODEL_a15ee33716be46a484ab8ac2da6e14cc"]}},"76e855caee5d4dfda9f0b3a5b98af1cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"93ae668247d2445d92638585e4740c7f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_90c38c563fd04710a252ba95a2ad541a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f8a37cc4f4834b3ea4d609579a5cd1f5"}},"14ff54a1e86948e3a2853e9bdfd408f9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_95bfdfda5db340f9b871724c30d8fa2a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":5069051,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5069051,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d1d5a0212fbe4a2d9d61709ec15e9dc6"}},"a15ee33716be46a484ab8ac2da6e14cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_598ef0829e72461580e3729c785b0796","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5.07M/5.07M [00:00&lt;00:00, 15.5MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_04d72bd0244049319aa3ee6555bfb723"}},"90c38c563fd04710a252ba95a2ad541a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f8a37cc4f4834b3ea4d609579a5cd1f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"95bfdfda5db340f9b871724c30d8fa2a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d1d5a0212fbe4a2d9d61709ec15e9dc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"598ef0829e72461580e3729c785b0796":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"04d72bd0244049319aa3ee6555bfb723":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ede03abe35b4434f8869463dea4d3acf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_81850b010c7349bfacd004abafd0f3f1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5ad903aba5c64cc29fcdcfe34f9c4f54","IPY_MODEL_95475cf1ed7940c4bb5c66f9205b852a","IPY_MODEL_41622ac1f6b34dbbb935f0af16597757"]}},"81850b010c7349bfacd004abafd0f3f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5ad903aba5c64cc29fcdcfe34f9c4f54":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_082f4db4db0541bcadb62e3803c8e9ec","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_04dd51940b7241978c08255a4bd3be6d"}},"95475cf1ed7940c4bb5c66f9205b852a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2b81105c63cc479c8a69d9d0869da22b","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":512,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":512,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2d2f549879484c4a83a098dcf28eccec"}},"41622ac1f6b34dbbb935f0af16597757":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7617f0105c9a40259a73fefb0d46d408","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 512/512 [00:00&lt;00:00, 11.2kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c18116fe7bc64f12aa4debf85e54e2b7"}},"082f4db4db0541bcadb62e3803c8e9ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"04dd51940b7241978c08255a4bd3be6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2b81105c63cc479c8a69d9d0869da22b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2d2f549879484c4a83a098dcf28eccec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7617f0105c9a40259a73fefb0d46d408":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c18116fe7bc64f12aa4debf85e54e2b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f8b37a5cf4e941abbd5996bf872d3bab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_05b08ba8dff14a67a7927321957502c7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b4fd9bc19c384d6a883b832d92cc0b74","IPY_MODEL_752f32b2c5f14bbaaab134c9a772e3f2","IPY_MODEL_dd120345d544403a9f1bf2badbaaac36"]}},"05b08ba8dff14a67a7927321957502c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b4fd9bc19c384d6a883b832d92cc0b74":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d504edbdd09f4d8196c9d01694d5c52d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a0dab196e2f14c70829c7ce3e04bce64"}},"752f32b2c5f14bbaaab134c9a772e3f2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f3d84c9727d64d03b7e030ef52cb4aa6","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1115590446,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1115590446,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_34458070d9154fc48bb4f359935c3967"}},"dd120345d544403a9f1bf2badbaaac36":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_894a908ef122454fb88582d7938578c8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.12G/1.12G [00:37&lt;00:00, 29.9MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c82bfffbbd4649549512628f9af9ab5d"}},"d504edbdd09f4d8196c9d01694d5c52d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a0dab196e2f14c70829c7ce3e04bce64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f3d84c9727d64d03b7e030ef52cb4aa6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"34458070d9154fc48bb4f359935c3967":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"894a908ef122454fb88582d7938578c8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c82bfffbbd4649549512628f9af9ab5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"QbOvSBgh_K2T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636650175969,"user_tz":-60,"elapsed":91619,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"c1c69ecc-e10a-43eb-9a20-1ef95fd84c8a"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","metadata":{"id":"vzqIeh0k_MbM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636650184435,"user_tz":-60,"elapsed":8475,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"812a498c-031d-4c07-eaca-1818d9c632cb"},"source":["import tensorflow as tf\n","\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}]},{"cell_type":"code","metadata":{"id":"1Og8o_HG_Mf4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636650223683,"user_tz":-60,"elapsed":39277,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"6082bd4a-54ee-419c-ce0c-e7296bd9ba44"},"source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla K80\n"]}]},{"cell_type":"code","metadata":{"id":"8uCANj-7fD_L","executionInfo":{"status":"ok","timestamp":1636650223684,"user_tz":-60,"elapsed":29,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["import logging\n","logging.basicConfig(level=logging.ERROR)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"JI3V3_oy_Mlp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636650229790,"user_tz":-60,"elapsed":6132,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"9d8ec3f4-4a18-44af-9c9d-669428b8597f"},"source":["!pip install transformers==3"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==3\n","  Downloading transformers-3.0.0-py3-none-any.whl (754 kB)\n","\u001b[?25l\r\u001b[K     |▍                               | 10 kB 21.4 MB/s eta 0:00:01\r\u001b[K     |▉                               | 20 kB 26.2 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 92 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 276 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 286 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 296 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 307 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 317 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 327 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 337 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 348 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 358 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 368 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 378 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 389 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 399 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 409 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 419 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 430 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 440 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 450 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 460 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 471 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 481 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 491 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 501 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 512 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 522 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 532 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 542 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 552 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 563 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 573 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 583 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 593 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 604 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 614 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 624 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 634 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 645 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 655 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 665 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 675 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 686 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 696 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 706 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 716 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 727 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 737 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 747 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 754 kB 5.4 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.3.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2019.12.20)\n","Collecting tokenizers==0.8.0-rc4\n","  Downloading tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 38.0 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.62.3)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 44.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.19.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (21.2)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 42.5 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.1.0)\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.46 sentencepiece-0.1.96 tokenizers-0.8.0rc4 transformers-3.0.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"MspPBjFecRHv"},"source":["#Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7gn-qmxXFkvG","executionInfo":{"status":"ok","timestamp":1636650229791,"user_tz":-60,"elapsed":12,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"298f7485-00e4-42e5-e099-57745045ebda"},"source":["cd drive/My Drive/Colab Notebooks/experiments"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab Notebooks/experiments\n"]}]},{"cell_type":"code","metadata":{"id":"ekbV40xzFsDB","executionInfo":{"status":"ok","timestamp":1636650230817,"user_tz":-60,"elapsed":1032,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["# Use a subset for quick experiments\n","#data = data[:10000]\n","\n","from sklearn.model_selection import train_test_split as tts\n","import pandas as pd\n","data = pd.read_csv(\"data/moh-x.csv\")\n","\n","# Split to train, val and test\n","train, test_df = tts(data[[\"sentence\", \"arg1\", \"verb\", \"label\"]], random_state=42, test_size=0.1)\n","train, val = tts(train, random_state=42, test_size=test_df.shape[0])"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"sT3SnDiB_MoJ","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"ok","timestamp":1636650231053,"user_tz":-60,"elapsed":238,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"ddd115db-c510-44af-8dc4-13bf9a4615d6"},"source":["import pandas as pd\n","# import pytreebank\n","\n","#cd drive/My Drive/Colab Notebooks/experiments/data\n","\n","# Load the dataset into a pandas dataframe.\n","df = pd.read_csv(\"data/mohx_mixed.csv\")\n","# Report the number of sentences.\n","print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n","df.head()"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of training sentences: 1,075\n","\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>arg1</th>\n","      <th>arg2</th>\n","      <th>verb</th>\n","      <th>sentence</th>\n","      <th>verb_idx</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>knowledge</td>\n","      <td>NaN</td>\n","      <td>absorb</td>\n","      <td>He absorbed the knowledge or beliefs of his tr...</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cost</td>\n","      <td>NaN</td>\n","      <td>absorb</td>\n","      <td>He absorbed the costs for the accident .</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>tax</td>\n","      <td>NaN</td>\n","      <td>absorb</td>\n","      <td>The sales tax is absorbed into the state incom...</td>\n","      <td>4.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>immigrant</td>\n","      <td>NaN</td>\n","      <td>absorb</td>\n","      <td>The immigrants were quickly absorbed into soci...</td>\n","      <td>4.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>interest</td>\n","      <td>NaN</td>\n","      <td>absorb</td>\n","      <td>Her interest in butterflies absorbs her comple...</td>\n","      <td>4.0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        arg1  arg2  ... verb_idx label\n","0  knowledge   NaN  ...      1.0     1\n","1       cost   NaN  ...      1.0     1\n","2        tax   NaN  ...      4.0     1\n","3  immigrant   NaN  ...      4.0     1\n","4   interest   NaN  ...      4.0     1\n","\n","[5 rows x 6 columns]"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"BQGRN8y2_Mq1","executionInfo":{"status":"ok","timestamp":1636650231054,"user_tz":-60,"elapsed":26,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["#if label was not numeric\n","#from sklearn.preprocessing import LabelEncoder\n","\n","#encoder = LabelEncoder()\n","#df.label = encoder.fit_transform(df.label)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jdw6bWex_MuB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636650231055,"user_tz":-60,"elapsed":26,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"c0dcd539-4bac-4ed9-8f9f-f810d3d05397"},"source":["# Get the lists of sentences and their labels.\n","sentences = df.sentence.values\n","labels = df.label.values\n","labels"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 1, 1, ..., 0, 0, 0])"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"Gkx8ObbNcTUZ"},"source":["#Tokenizer"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fd_lJqo3cncS","executionInfo":{"status":"ok","timestamp":1636650234358,"user_tz":-60,"elapsed":3325,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"11abdacb-0df8-4033-ee40-8185ec04e53e"},"source":["!pip install sentencepiece"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"]}]},{"cell_type":"code","metadata":{"id":"9uz-SE4L_MxE","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["11351a3cd50b42949c584ca99b6d808f","76e855caee5d4dfda9f0b3a5b98af1cb","93ae668247d2445d92638585e4740c7f","14ff54a1e86948e3a2853e9bdfd408f9","a15ee33716be46a484ab8ac2da6e14cc","90c38c563fd04710a252ba95a2ad541a","f8a37cc4f4834b3ea4d609579a5cd1f5","95bfdfda5db340f9b871724c30d8fa2a","d1d5a0212fbe4a2d9d61709ec15e9dc6","598ef0829e72461580e3729c785b0796","04d72bd0244049319aa3ee6555bfb723"]},"executionInfo":{"status":"ok","timestamp":1636650235931,"user_tz":-60,"elapsed":1596,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"910e9903-ffac-4e09-db66-1126eb3df975"},"source":["from transformers import XLMRobertaTokenizer\n","\n","# Load the BERT tokenizer.\n","print('Loading XLMRobertaTokenizer ...')\n","tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base', do_lower_case=True)"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading XLMRobertaTokenizer ...\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"11351a3cd50b42949c584ca99b6d808f","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"Zvi2HDlx_M0k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636650235932,"user_tz":-60,"elapsed":12,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"1e1d0ee3-20d1-47a3-8c20-ac8c769ab802"},"source":["# Print the original sentence.\n","print('Original: ', sentences[0])\n","\n","# Print the sentence split into tokens.\n","print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n","\n","# Print the sentence mapped to token ids.\n","print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Original:  He absorbed the knowledge or beliefs of his tribe .\n","Tokenized:  ['▁he', '▁absorb', 'ed', '▁the', '▁knowledge', '▁or', '▁belief', 's', '▁of', '▁his', '▁tri', 'be', '▁', '.']\n","Token IDs:  [764, 57622, 297, 70, 51359, 707, 144239, 7, 111, 1919, 1927, 372, 6, 5]\n"]}]},{"cell_type":"markdown","metadata":{"id":"tdH-JjAyev73"},"source":["#Tokenize Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pvQC4TbTcveP","executionInfo":{"status":"ok","timestamp":1636650236463,"user_tz":-60,"elapsed":538,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"7541eb39-2826-4ed0-d2db-c2530c8a3922"},"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in sentences:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 128,          # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', sentences[0])\n","print('Token IDs:', input_ids[0])\n","print('labels:', labels)"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Original:  He absorbed the knowledge or beliefs of his tribe .\n","Token IDs: tensor([     0,    764,  57622,    297,     70,  51359,    707, 144239,      7,\n","           111,   1919,   1927,    372,      6,      5,      2,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1])\n","labels: tensor([1, 1, 1,  ..., 0, 0, 0])\n"]}]},{"cell_type":"markdown","metadata":{"id":"dgHZenrtf4uH"},"source":["#Train and validation split"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jfrqA7YHcviX","executionInfo":{"status":"ok","timestamp":1636650236464,"user_tz":-60,"elapsed":16,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"dbec96d7-7f7c-4707-b6fa-5427b6112020"},"source":["from torch.utils.data import TensorDataset, random_split\n","\n","# Combine the training inputs into a TensorDataset.\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","# Create a 90-10 train-validation split.\n","\n","# Calculate the number of samples to include in each set.\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","# Divide the dataset by randomly selecting samples.\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["  967 training samples\n","  108 validation samples\n"]}]},{"cell_type":"code","metadata":{"id":"Ew-crkiKcvmk","executionInfo":{"status":"ok","timestamp":1636650236465,"user_tz":-60,"elapsed":13,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","# The DataLoader needs to know our batch size for training, so we specify it \n","# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n","# size of 16 or 32.\n","batch_size = 32\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )\n"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"31XYmBgGgLMq"},"source":["#Train the model - XLMRobertaForSequenceClassification"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["ede03abe35b4434f8869463dea4d3acf","81850b010c7349bfacd004abafd0f3f1","5ad903aba5c64cc29fcdcfe34f9c4f54","95475cf1ed7940c4bb5c66f9205b852a","41622ac1f6b34dbbb935f0af16597757","082f4db4db0541bcadb62e3803c8e9ec","04dd51940b7241978c08255a4bd3be6d","2b81105c63cc479c8a69d9d0869da22b","2d2f549879484c4a83a098dcf28eccec","7617f0105c9a40259a73fefb0d46d408","c18116fe7bc64f12aa4debf85e54e2b7","f8b37a5cf4e941abbd5996bf872d3bab","05b08ba8dff14a67a7927321957502c7","b4fd9bc19c384d6a883b832d92cc0b74","752f32b2c5f14bbaaab134c9a772e3f2","dd120345d544403a9f1bf2badbaaac36","d504edbdd09f4d8196c9d01694d5c52d","a0dab196e2f14c70829c7ce3e04bce64","f3d84c9727d64d03b7e030ef52cb4aa6","34458070d9154fc48bb4f359935c3967","894a908ef122454fb88582d7938578c8","c82bfffbbd4649549512628f9af9ab5d"]},"id":"NCwrwWq3gKVJ","executionInfo":{"status":"ok","timestamp":1636650289262,"user_tz":-60,"elapsed":52807,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"80b9bbfe-993f-4007-a08c-4a2e2e48efa8"},"source":["from transformers import XLMRobertaForSequenceClassification, AdamW, BertConfig\n","\n","# Load BertForSequenceClassification - pretrained BERT model with a single linear classification layer on top. \n","model = XLMRobertaForSequenceClassification.from_pretrained(\n","    \"xlm-roberta-base\", # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = 2, # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"execution_count":17,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ede03abe35b4434f8869463dea4d3acf","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/512 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f8b37a5cf4e941abbd5996bf872d3bab","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["XLMRobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vMSwxx0gcvqh","executionInfo":{"status":"ok","timestamp":1636650289263,"user_tz":-60,"elapsed":29,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"b7dbab54-a869-4f8c-9dee-2cb3927dc824"},"source":["params = list(model.named_parameters())\n","\n","print('The XLMRoberta model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["The XLMRoberta model has 203 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","roberta.embeddings.word_embeddings.weight               (250002, 768)\n","roberta.embeddings.position_embeddings.weight             (514, 768)\n","roberta.embeddings.token_type_embeddings.weight             (1, 768)\n","roberta.embeddings.LayerNorm.weight                           (768,)\n","roberta.embeddings.LayerNorm.bias                             (768,)\n","\n","==== First Transformer ====\n","\n","roberta.encoder.layer.0.attention.self.query.weight       (768, 768)\n","roberta.encoder.layer.0.attention.self.query.bias             (768,)\n","roberta.encoder.layer.0.attention.self.key.weight         (768, 768)\n","roberta.encoder.layer.0.attention.self.key.bias               (768,)\n","roberta.encoder.layer.0.attention.self.value.weight       (768, 768)\n","roberta.encoder.layer.0.attention.self.value.bias             (768,)\n","roberta.encoder.layer.0.attention.output.dense.weight     (768, 768)\n","roberta.encoder.layer.0.attention.output.dense.bias           (768,)\n","roberta.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n","roberta.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n","roberta.encoder.layer.0.intermediate.dense.weight        (3072, 768)\n","roberta.encoder.layer.0.intermediate.dense.bias              (3072,)\n","roberta.encoder.layer.0.output.dense.weight              (768, 3072)\n","roberta.encoder.layer.0.output.dense.bias                     (768,)\n","roberta.encoder.layer.0.output.LayerNorm.weight               (768,)\n","roberta.encoder.layer.0.output.LayerNorm.bias                 (768,)\n","\n","==== Output Layer ====\n","\n","classifier.dense.weight                                   (768, 768)\n","classifier.dense.bias                                         (768,)\n","classifier.out_proj.weight                                  (2, 768)\n","classifier.out_proj.bias                                        (2,)\n"]}]},{"cell_type":"markdown","metadata":{"id":"51Pe3nq8g3wB"},"source":["#Optimizer and Learning Rate Scheduler"]},{"cell_type":"code","metadata":{"id":"xWkNQFlVcvup","executionInfo":{"status":"ok","timestamp":1636650289264,"user_tz":-60,"elapsed":25,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["# Note: AdamW is a class from the huggingface library (as opposed to pytorch) - \"W\" stands for weight decay fix\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"mtGiVJvNhALg","executionInfo":{"status":"ok","timestamp":1636650289264,"user_tz":-60,"elapsed":25,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs. The BERT authors recommend between 2 and 4. \n","# We chose to run for 4, but we'll see later that this may be over-fitting the\n","# training data.\n","epochs = 10\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K3a_KwCxhIw4"},"source":["#Train our model"]},{"cell_type":"code","metadata":{"id":"qZsMe3FshAPv","executionInfo":{"status":"ok","timestamp":1636650289265,"user_tz":-60,"elapsed":25,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"eIoz0srmhAZR","executionInfo":{"status":"ok","timestamp":1636650289267,"user_tz":-60,"elapsed":27,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uf5f0hyehAhP","executionInfo":{"status":"ok","timestamp":1636650718151,"user_tz":-60,"elapsed":428910,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"437163ab-9598-4909-810d-d1cc9ed3d851"},"source":["import random\n","import numpy as np\n","\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# We'll store a number of quantities such as training and validation loss, \n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        print(b_input_ids.shape)\n","        print(b_input_mask.shape)\n","        print(b_labels.shape)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # The documentation for this `model` function is here: \n","        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","        # It returns different numbers of parameters depending on what arguments\n","        # arge given and what flags are set. For our useage here, it returns\n","        # the loss (because we provided labels) and the \"logits\"--the model\n","        # outputs prior to activation.\n","        loss, logits = model(b_input_ids, \n","                             token_type_ids=None, \n","                             attention_mask=b_input_mask, \n","                             labels=b_labels)\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using \n","        # the `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            # The documentation for this `model` function is here: \n","            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","            # Get the \"logits\" output by the model. The \"logits\" are the output\n","            # values prior to applying an activation function like the softmax.\n","            (loss, logits) = model(b_input_ids, \n","                                   token_type_ids=None, \n","                                   attention_mask=b_input_mask,\n","                                   labels=b_labels)\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([7, 128])\n","torch.Size([7, 128])\n","torch.Size([7])\n","\n","  Average training loss: 0.70\n","  Training epcoh took: 0:00:40\n","\n","Running Validation...\n","  Accuracy: 0.47\n","  Validation Loss: 0.69\n","  Validation took: 0:00:02\n","\n","======== Epoch 2 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([7, 128])\n","torch.Size([7, 128])\n","torch.Size([7])\n","\n","  Average training loss: 0.68\n","  Training epcoh took: 0:00:41\n","\n","Running Validation...\n","  Accuracy: 0.52\n","  Validation Loss: 0.69\n","  Validation took: 0:00:02\n","\n","======== Epoch 3 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([7, 128])\n","torch.Size([7, 128])\n","torch.Size([7])\n","\n","  Average training loss: 0.66\n","  Training epcoh took: 0:00:41\n","\n","Running Validation...\n","  Accuracy: 0.60\n","  Validation Loss: 0.70\n","  Validation took: 0:00:02\n","\n","======== Epoch 4 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([7, 128])\n","torch.Size([7, 128])\n","torch.Size([7])\n","\n","  Average training loss: 0.62\n","  Training epcoh took: 0:00:41\n","\n","Running Validation...\n","  Accuracy: 0.58\n","  Validation Loss: 0.70\n","  Validation took: 0:00:02\n","\n","======== Epoch 5 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([7, 128])\n","torch.Size([7, 128])\n","torch.Size([7])\n","\n","  Average training loss: 0.57\n","  Training epcoh took: 0:00:41\n","\n","Running Validation...\n","  Accuracy: 0.64\n","  Validation Loss: 0.67\n","  Validation took: 0:00:02\n","\n","======== Epoch 6 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([7, 128])\n","torch.Size([7, 128])\n","torch.Size([7])\n","\n","  Average training loss: 0.51\n","  Training epcoh took: 0:00:42\n","\n","Running Validation...\n","  Accuracy: 0.66\n","  Validation Loss: 0.64\n","  Validation took: 0:00:02\n","\n","======== Epoch 7 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([7, 128])\n","torch.Size([7, 128])\n","torch.Size([7])\n","\n","  Average training loss: 0.46\n","  Training epcoh took: 0:00:42\n","\n","Running Validation...\n","  Accuracy: 0.67\n","  Validation Loss: 0.64\n","  Validation took: 0:00:02\n","\n","======== Epoch 8 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([7, 128])\n","torch.Size([7, 128])\n","torch.Size([7])\n","\n","  Average training loss: 0.43\n","  Training epcoh took: 0:00:41\n","\n","Running Validation...\n","  Accuracy: 0.70\n","  Validation Loss: 0.69\n","  Validation took: 0:00:02\n","\n","======== Epoch 9 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([7, 128])\n","torch.Size([7, 128])\n","torch.Size([7])\n","\n","  Average training loss: 0.41\n","  Training epcoh took: 0:00:42\n","\n","Running Validation...\n","  Accuracy: 0.72\n","  Validation Loss: 0.67\n","  Validation took: 0:00:02\n","\n","======== Epoch 10 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([7, 128])\n","torch.Size([7, 128])\n","torch.Size([7])\n","\n","  Average training loss: 0.36\n","  Training epcoh took: 0:00:41\n","\n","Running Validation...\n","  Accuracy: 0.70\n","  Validation Loss: 0.68\n","  Validation took: 0:00:02\n","\n","Training complete!\n","Total training took 0:07:09 (h:mm:ss)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":390},"id":"LHx9Nzi9hAn_","executionInfo":{"status":"ok","timestamp":1636650718152,"user_tz":-60,"elapsed":48,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"1ed35370-57f1-4510-8aef-99d8a74656e2"},"source":["import pandas as pd\n","\n","# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.70</td>\n","      <td>0.69</td>\n","      <td>0.47</td>\n","      <td>0:00:40</td>\n","      <td>0:00:02</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.68</td>\n","      <td>0.69</td>\n","      <td>0.52</td>\n","      <td>0:00:41</td>\n","      <td>0:00:02</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.66</td>\n","      <td>0.70</td>\n","      <td>0.60</td>\n","      <td>0:00:41</td>\n","      <td>0:00:02</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.62</td>\n","      <td>0.70</td>\n","      <td>0.58</td>\n","      <td>0:00:41</td>\n","      <td>0:00:02</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.57</td>\n","      <td>0.67</td>\n","      <td>0.64</td>\n","      <td>0:00:41</td>\n","      <td>0:00:02</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.51</td>\n","      <td>0.64</td>\n","      <td>0.66</td>\n","      <td>0:00:42</td>\n","      <td>0:00:02</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.46</td>\n","      <td>0.64</td>\n","      <td>0.67</td>\n","      <td>0:00:42</td>\n","      <td>0:00:02</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.43</td>\n","      <td>0.69</td>\n","      <td>0.70</td>\n","      <td>0:00:41</td>\n","      <td>0:00:02</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.41</td>\n","      <td>0.67</td>\n","      <td>0.72</td>\n","      <td>0:00:42</td>\n","      <td>0:00:02</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.36</td>\n","      <td>0.68</td>\n","      <td>0.70</td>\n","      <td>0:00:41</td>\n","      <td>0:00:02</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n","epoch                                                                         \n","1               0.70         0.69           0.47       0:00:40         0:00:02\n","2               0.68         0.69           0.52       0:00:41         0:00:02\n","3               0.66         0.70           0.60       0:00:41         0:00:02\n","4               0.62         0.70           0.58       0:00:41         0:00:02\n","5               0.57         0.67           0.64       0:00:41         0:00:02\n","6               0.51         0.64           0.66       0:00:42         0:00:02\n","7               0.46         0.64           0.67       0:00:42         0:00:02\n","8               0.43         0.69           0.70       0:00:41         0:00:02\n","9               0.41         0.67           0.72       0:00:42         0:00:02\n","10              0.36         0.68           0.70       0:00:41         0:00:02"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":427},"id":"d9EJhSWFhAxL","executionInfo":{"status":"ok","timestamp":1636650718796,"user_tz":-60,"elapsed":675,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"2e0a6421-acd4-45e8-dfaa-cbc61471b32e"},"source":["import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","import seaborn as sns\n","\n","# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"execution_count":25,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"IT4-LcM-iPn8"},"source":["#Performance on test set"]},{"cell_type":"code","metadata":{"id":"8VipplfqhBhS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636650719299,"user_tz":-60,"elapsed":510,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"a4b600ae-f3ac-4603-ffa4-d14f9fc8bb70"},"source":["import pandas as pd\n","\n","# # Load the dataset into a pandas dataframe.\n","#test_df = pd.read_csv(\"Datasets/es_lcc_new.csv\")\n","\n","# # Report the number of sentences.\n","print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n","\n","# # Create sentence and label lists\n","sentences = test_df.sentence.values.astype(str)\n","labels = test_df.label.values\n","\n","# # Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# # For every sentence...\n","for sent in sentences:\n","#     # `encode_plus` will:\n","#     #   (1) Tokenize the sentence.\n","#     #   (2) Prepend the `[CLS]` token to the start.\n","#     #   (3) Append the `[SEP]` token to the end.\n","#     #   (4) Map tokens to their IDs.\n","#     #   (5) Pad or truncate the sentence to `max_length`\n","#     #   (6) Create attention masks for [PAD] tokens.\n","     encoded_dict = tokenizer.encode_plus(\n","                         sent,                      # Sentence to encode.\n","                         add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                         max_length = 64,           # Pad & truncate all sentences.\n","                         pad_to_max_length = True,\n","                         return_attention_mask = True,   # Construct attn. masks.\n","                         return_tensors = 'pt',     # Return pytorch tensors.\n","                    )\n","    \n","#     # Add the encoded sentence to the list.    \n","     input_ids.append(encoded_dict['input_ids'])\n","    \n","#     # And its attention mask (simply differentiates padding from non-padding).\n","     attention_masks.append(encoded_dict['attention_mask'])\n","\n","# # Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# # Set the batch size.  \n","batch_size = 32  \n","\n","# # Create the DataLoader.\n","prediction_data = TensorDataset(input_ids, attention_masks, labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of test sentences: 1,075\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"HLjiQA_TiUbi"},"source":["#Evaluation on test set"]},{"cell_type":"code","metadata":{"id":"Gnv1WjdwhBrg","executionInfo":{"status":"ok","timestamp":1636650719300,"user_tz":-60,"elapsed":14,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["# # Prediction on test set\n","\n","# print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n","\n","# # Put model in evaluation mode\n","# model.eval()\n","\n","# # Tracking variables \n","# predictions , true_labels = [], []\n","\n","# # Predict \n","# for batch in prediction_dataloader:\n","#   # Add batch to GPU\n","#   batch = tuple(t.to(device) for t in batch)\n","  \n","#   # Unpack the inputs from our dataloader\n","#   b_input_ids, b_input_mask, b_labels = batch\n","  \n","#   # Telling the model not to compute or store gradients, saving memory and \n","#   # speeding up prediction\n","#   with torch.no_grad():\n","#       # Forward pass, calculate logit predictions\n","#       outputs = model(b_input_ids, token_type_ids=None, \n","#                       attention_mask=b_input_mask)\n","\n","#   logits = outputs[0]\n","\n","#   # Move logits and labels to CPU\n","#   logits = logits.detach().cpu().numpy()\n","#   label_ids = b_labels.to('cpu').numpy()\n","  \n","#   # Store predictions and true labels\n","#   predictions.append(logits)\n","#   true_labels.append(label_ids)\n","\n","\n","# print('    DONE.')\n","# print('    predictions:::',predictions)\n","# print('    true_labels:::',true_labels)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qmj7fm818zxM","executionInfo":{"status":"ok","timestamp":1636650719302,"user_tz":-60,"elapsed":16,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["model.eval()\n","\n","# Tracking variables \n","predictions , true_labels = [], []\n","\n","# Predict \n","for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels = batch\n","  # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n","  with torch.no_grad():\n","    # Forward pass, calculate logit predictions\n","    logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)[0]\n","\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  true_labels.append(label_ids)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"WfsjU8Upt38K","executionInfo":{"status":"ok","timestamp":1636650719303,"user_tz":-60,"elapsed":16,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["my_submission = pd.DataFrame()\n","my_submission['sentence'] = test_df['sentence']\n","my_submission['arg1'] = test_df['arg1']\n","my_submission['verb'] = test_df['verb']\n","my_submission['correct_label'] = test_df['label']\n","#my_submission['polarity'] = test_df['polarity']\n","#my_submission['intensity'] = test_df['intensity']\n","#my_submission['source_concept'] = test_df['source_concept']\n","#my_submission['target_concept'] = test_df['target_concept']"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"VNV-BxYnuNZh","executionInfo":{"status":"ok","timestamp":1636650719303,"user_tz":-60,"elapsed":16,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["final_preds = []\n","for p in predictions:\n","    for i in p:\n","        final_preds.append(np.argmax(i))"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"JN1eyJlFuPCc","executionInfo":{"status":"ok","timestamp":1636650719304,"user_tz":-60,"elapsed":16,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["my_submission['label'] = final_preds"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"FDLPomjZuR7W","executionInfo":{"status":"ok","timestamp":1636650719305,"user_tz":-60,"elapsed":16,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["my_submission['label'] = my_submission['label'].map({0:0, 1:1})"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fqo58IR-ufCG","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1636650719656,"user_tz":-60,"elapsed":35,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"8abfb666-19e1-4e61-975e-9bf6b7c24392"},"source":["my_submission.head()"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>arg1</th>\n","      <th>verb</th>\n","      <th>correct_label</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>634</th>\n","      <td>He marched into the classroom and announced t...</td>\n","      <td>man</td>\n","      <td>march</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>220</th>\n","      <td>The stars gravitate towards each other .</td>\n","      <td>star</td>\n","      <td>gravitate</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>426</th>\n","      <td>A hot soup will revive me .</td>\n","      <td>soup</td>\n","      <td>revive</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>428</th>\n","      <td>He revived this style of opera .</td>\n","      <td>style</td>\n","      <td>revive</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>72</th>\n","      <td>They clawed their way to the top of the mount...</td>\n","      <td>way</td>\n","      <td>claw</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              sentence  ... label\n","634   He marched into the classroom and announced t...  ...     1\n","220           The stars gravitate towards each other .  ...     0\n","426                        A hot soup will revive me .  ...     1\n","428                   He revived this style of opera .  ...     1\n","72    They clawed their way to the top of the mount...  ...     0\n","\n","[5 rows x 5 columns]"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"YQs-dWrUw7XN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636650719659,"user_tz":-60,"elapsed":36,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"eaf5ba54-7d77-4e9d-c894-24fcb8033b66"},"source":["my_submission.shape"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(65, 5)"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"KsIV4fzxxttP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636650719660,"user_tz":-60,"elapsed":34,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"d28386b1-d321-4da4-8faf-b88f6e022179"},"source":["test_df.label.value_counts()"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    36\n","0    29\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"nTtwGl9vxOoG","executionInfo":{"status":"ok","timestamp":1636650719662,"user_tz":-60,"elapsed":33,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["final = my_submission[(my_submission['correct_label'] == my_submission['label'])]"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"6iVw1NZ2xO0C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636650719668,"user_tz":-60,"elapsed":38,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"391def38-2f34-439d-e600-16cbe1a692eb"},"source":["final.shape"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(55, 5)"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"1BoXX0koxO6n","executionInfo":{"status":"ok","timestamp":1636650719670,"user_tz":-60,"elapsed":36,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["final_met = my_submission[(my_submission['correct_label'] == 1) & (my_submission['label'] ==1)]"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"zQGkR9dDxeSg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636650719673,"user_tz":-60,"elapsed":39,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"94dfd042-eaa8-4ba4-e78a-889236d48a28"},"source":["final_met.shape"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(30, 5)"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"RFTH_BCexeY1","executionInfo":{"status":"ok","timestamp":1636650719677,"user_tz":-60,"elapsed":40,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["final_lit = my_submission[(my_submission['correct_label'] == 0) & (my_submission['label'] ==0)]"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"UEwct9X5xehQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636650719678,"user_tz":-60,"elapsed":40,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"fb01ecee-3e48-49b7-b026-54f371407486"},"source":["final_lit.shape"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(25, 5)"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"Rs-f8IKraTz5","executionInfo":{"status":"ok","timestamp":1636650719680,"user_tz":-60,"elapsed":39,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["#print(logits)"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"g7YGsSh_uhz7","executionInfo":{"status":"ok","timestamp":1636650719926,"user_tz":-60,"elapsed":285,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["my_submission.to_csv('mohx_sub.csv', index=False)"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"9GYFtiTEk7MP","executionInfo":{"status":"ok","timestamp":1636650719928,"user_tz":-60,"elapsed":12,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["#final_met.to_csv(\"final_met.csv\", index=False)"],"execution_count":44,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Whz6mWvpidb-"},"source":["#Save and load fine-tuned model"]},{"cell_type":"code","metadata":{"id":"73UumM0PhBym","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636650875134,"user_tz":-60,"elapsed":7634,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"188ca7b2-3e84-4e22-de97-52bcc678368d"},"source":["import os\n","\n","# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n","\n","output_dir = 'stockholm/xlm_code/mixed_models/mohx'\n","# output_dir = './content/xlm-roberta_model_save/'\n","\n","# Create output directory if needed\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","print(\"Saving model to %s\" % output_dir)\n","\n","# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","# They can then be reloaded using `from_pretrained()`\n","model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","model_to_save.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)\n","\n","# Good practice: save your training arguments together with the trained model\n","# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"],"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving model to stockholm/xlm_code/mixed_models/mohx\n"]},{"output_type":"execute_result","data":{"text/plain":["('stockholm/xlm_code/mixed_models/mohx/sentencepiece.bpe.model',\n"," 'stockholm/xlm_code/mixed_models/mohx/special_tokens_map.json',\n"," 'stockholm/xlm_code/mixed_models/mohx/added_tokens.json')"]},"metadata":{},"execution_count":48}]},{"cell_type":"markdown","metadata":{"id":"LmN96FOqjLKd"},"source":["#Import saved model and test"]},{"cell_type":"code","metadata":{"id":"ScJHWcE5hB4z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636650946509,"user_tz":-60,"elapsed":3853,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"4c6c7155-4209-490e-83f6-7291a75efaf1"},"source":["!pip install transformers\n","\n","from transformers import XLMRobertaForSequenceClassification\n","\n","output_dir = 'stockholm/xlm_code/mixed_models/mohx'\n","\n","print(output_dir)"],"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (3.0.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.96)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.0rc4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","stockholm/xlm_code/mixed_models/mohx\n"]}]},{"cell_type":"code","metadata":{"id":"SZbux55ucvy5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636650964003,"user_tz":-60,"elapsed":16016,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"085f3a11-3cd1-4c74-e253-68235fa1edf7"},"source":["from transformers import XLMRobertaTokenizer\n","import torch\n","# Load the BERT tokenizer.\n","print('Loading XLMRobertaTokenizer...')\n","tokenizer = XLMRobertaTokenizer.from_pretrained(output_dir)\n","model_loaded = XLMRobertaForSequenceClassification.from_pretrained(output_dir)"],"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading XLMRobertaTokenizer...\n"]}]}]}