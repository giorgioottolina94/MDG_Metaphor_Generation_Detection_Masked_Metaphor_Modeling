{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"trofi-x_mixed_xlm_2.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"02e364c6c40d4c11863bd912c2bb59ec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_001ca80faee346cebe82da69991d209f","IPY_MODEL_a8dbb0d90e1d4fde9ee8c089cbd285d6","IPY_MODEL_7cffa3b5971d4b14b314f8555dae6201"],"layout":"IPY_MODEL_6bf413a4f8154dc19873d49a2f025aa9"}},"001ca80faee346cebe82da69991d209f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7dba5f89611b4bebbcb56d2f349ae4ab","placeholder":"​","style":"IPY_MODEL_b6a33505a9454ce8940fb42f233197dd","value":"Downloading: 100%"}},"a8dbb0d90e1d4fde9ee8c089cbd285d6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_709914b675e343419afac6c177eb237f","max":5069051,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1b17f442ee3b4f2091ca10ebfdcb4155","value":5069051}},"7cffa3b5971d4b14b314f8555dae6201":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bdef24984d02483d88c2eec2df2ee484","placeholder":"​","style":"IPY_MODEL_3793153e779c4d199c0b5ddfae9b6684","value":" 5.07M/5.07M [00:01&lt;00:00, 5.44MB/s]"}},"6bf413a4f8154dc19873d49a2f025aa9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7dba5f89611b4bebbcb56d2f349ae4ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6a33505a9454ce8940fb42f233197dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"709914b675e343419afac6c177eb237f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b17f442ee3b4f2091ca10ebfdcb4155":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bdef24984d02483d88c2eec2df2ee484":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3793153e779c4d199c0b5ddfae9b6684":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"41f20cd194b242c0a8ccf5a1326f4c6b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_037068842c4749c9862d66e7a67c2297","IPY_MODEL_b6f9e08dcb3b4eefa60acb53205b1877","IPY_MODEL_88385bc3f179444680a62a4088c1712c"],"layout":"IPY_MODEL_280dc11fb2f14aaab90c59afb28b4297"}},"037068842c4749c9862d66e7a67c2297":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb312728eb924aed8b2a33a2c7ffda0d","placeholder":"​","style":"IPY_MODEL_bd321690fca84fe69223ecc0b80da657","value":"Downloading: 100%"}},"b6f9e08dcb3b4eefa60acb53205b1877":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7768bd95d0214fac93ffb29f89afc15d","max":512,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1aee6c0c2a534fcab3c1834aba3ad2ef","value":512}},"88385bc3f179444680a62a4088c1712c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1991649bc1e430a86a414122c615fa2","placeholder":"​","style":"IPY_MODEL_eff691522d384dccb4da4bc50406126c","value":" 512/512 [00:00&lt;00:00, 16.4kB/s]"}},"280dc11fb2f14aaab90c59afb28b4297":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb312728eb924aed8b2a33a2c7ffda0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd321690fca84fe69223ecc0b80da657":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7768bd95d0214fac93ffb29f89afc15d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1aee6c0c2a534fcab3c1834aba3ad2ef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e1991649bc1e430a86a414122c615fa2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eff691522d384dccb4da4bc50406126c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95bbf3a548ba4993b3000f6a718d4fa4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f142bc265f5140afb9ea4e6aeafc82bc","IPY_MODEL_2035ec9722b643e39ef1744c753e834d","IPY_MODEL_2add4c68cb8d4e909f8caafac852c838"],"layout":"IPY_MODEL_7de84b8535474bcc8792b13238458b0e"}},"f142bc265f5140afb9ea4e6aeafc82bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6765d3deebd4ae9a9f7dd113b870180","placeholder":"​","style":"IPY_MODEL_67f6c1a52be145b9bcaa8a9317f4927d","value":"Downloading: 100%"}},"2035ec9722b643e39ef1744c753e834d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ac9fb044889405497c849b0fbee0ce4","max":1115590446,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4653f1e92dd24e9d908ac55d6ed6fd56","value":1115590446}},"2add4c68cb8d4e909f8caafac852c838":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_777c65795e404d9695a120e94c5ba730","placeholder":"​","style":"IPY_MODEL_de76e0e523a34194b57ee4e0ed92c7ef","value":" 1.12G/1.12G [00:33&lt;00:00, 53.6MB/s]"}},"7de84b8535474bcc8792b13238458b0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6765d3deebd4ae9a9f7dd113b870180":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67f6c1a52be145b9bcaa8a9317f4927d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4ac9fb044889405497c849b0fbee0ce4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4653f1e92dd24e9d908ac55d6ed6fd56":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"777c65795e404d9695a120e94c5ba730":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de76e0e523a34194b57ee4e0ed92c7ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","metadata":{"id":"QbOvSBgh_K2T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655974309048,"user_tz":-120,"elapsed":3478,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}},"outputId":"87d2e8b2-a584-4147-931e-a4697988e842"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"vzqIeh0k_MbM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655974312215,"user_tz":-120,"elapsed":3174,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}},"outputId":"4fc3dce3-793a-4fae-f86f-b7596a28c7f9"},"source":["import tensorflow as tf\n","\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}]},{"cell_type":"code","metadata":{"id":"1Og8o_HG_Mf4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655974319097,"user_tz":-120,"elapsed":6887,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}},"outputId":"f8368417-2d87-4796-b1eb-45af653ef4e0"},"source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"]}]},{"cell_type":"code","metadata":{"id":"8uCANj-7fD_L","executionInfo":{"status":"ok","timestamp":1655974319098,"user_tz":-120,"elapsed":11,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}}},"source":["import logging\n","logging.basicConfig(level=logging.ERROR)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"JI3V3_oy_Mlp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655974324415,"user_tz":-120,"elapsed":5326,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}},"outputId":"396965f9-7bea-449b-d0e0-4252a31d22ea"},"source":["!pip install transformers==3"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers==3 in /usr/local/lib/python3.7/dist-packages (3.0.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.1.96)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.64.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.0.53)\n","Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.8.0rc4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2022.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.7.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (7.1.2)\n"]}]},{"cell_type":"markdown","metadata":{"id":"MspPBjFecRHv"},"source":["#Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7gn-qmxXFkvG","executionInfo":{"status":"ok","timestamp":1655974324416,"user_tz":-120,"elapsed":14,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}},"outputId":"fcd5b53f-46bf-4f80-cd4b-d2e9dd634a23"},"source":["cd drive/My Drive/Colab Notebooks/experiments"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab Notebooks/experiments\n"]}]},{"cell_type":"code","metadata":{"id":"ekbV40xzFsDB","executionInfo":{"status":"ok","timestamp":1655974324417,"user_tz":-120,"elapsed":10,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}}},"source":["# Use a subset for quick experiments\n","#data = data[:10000]\n","\n","from sklearn.model_selection import train_test_split as tts\n","import pandas as pd\n","data = pd.read_csv(\"data/trofix.csv\")\n","\n","# Split to train, val and test\n","train, test_df = tts(data[[\"sentence\", \"arg1\", \"arg2\", \"verb\", \"label\"]], random_state=42, test_size=0.1)\n","train, val = tts(train, random_state=42, test_size=test_df.shape[0])"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"sT3SnDiB_MoJ","colab":{"base_uri":"https://localhost:8080/","height":241},"executionInfo":{"status":"ok","timestamp":1655974326787,"user_tz":-120,"elapsed":2379,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}},"outputId":"513ed1bc-eaca-4c4d-b009-1286e865095a"},"source":["import pandas as pd\n","# import pytreebank\n","\n","#cd drive/My Drive/Colab Notebooks/experiments/data\n","\n","# Load the dataset into a pandas dataframe.\n","df = pd.read_csv(\"data/trofix_mixed_2.csv\")\n","# Report the number of sentences.\n","print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n","df.head()"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of training sentences: 2,260\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["            arg1     arg2      verb  \\\n","0        mileage   struck      blow   \n","1      terrorist   attack    target   \n","2         forces  stepped       use   \n","3            day     pour    stream   \n","4  manufacturers  rolling  products   \n","\n","                                            sentence verb_stem  label  \n","0  Triple mileage has struck another blow to the ...    strike      1  \n","1  U.S. officials said evidence suggests that a J...    attack      0  \n","2  Some police forces , for example , have steppe...      step      0  \n","3  Every day his troops gather under the green , ...      pour      0  \n","4  He says manufacturers are increasingly rolling...      roll      1  "],"text/html":["\n","  <div id=\"df-6c59403b-01af-404f-aabe-fd73eb283d77\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>arg1</th>\n","      <th>arg2</th>\n","      <th>verb</th>\n","      <th>sentence</th>\n","      <th>verb_stem</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>mileage</td>\n","      <td>struck</td>\n","      <td>blow</td>\n","      <td>Triple mileage has struck another blow to the ...</td>\n","      <td>strike</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>terrorist</td>\n","      <td>attack</td>\n","      <td>target</td>\n","      <td>U.S. officials said evidence suggests that a J...</td>\n","      <td>attack</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>forces</td>\n","      <td>stepped</td>\n","      <td>use</td>\n","      <td>Some police forces , for example , have steppe...</td>\n","      <td>step</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>day</td>\n","      <td>pour</td>\n","      <td>stream</td>\n","      <td>Every day his troops gather under the green , ...</td>\n","      <td>pour</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>manufacturers</td>\n","      <td>rolling</td>\n","      <td>products</td>\n","      <td>He says manufacturers are increasingly rolling...</td>\n","      <td>roll</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c59403b-01af-404f-aabe-fd73eb283d77')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6c59403b-01af-404f-aabe-fd73eb283d77 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6c59403b-01af-404f-aabe-fd73eb283d77');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"BQGRN8y2_Mq1","executionInfo":{"status":"ok","timestamp":1655974326788,"user_tz":-120,"elapsed":26,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}}},"source":["#if label was not numeric\n","#from sklearn.preprocessing import LabelEncoder\n","\n","#encoder = LabelEncoder()\n","#df.label = encoder.fit_transform(df.label)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jdw6bWex_MuB","executionInfo":{"status":"ok","timestamp":1655974326788,"user_tz":-120,"elapsed":24,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8d7feeb7-418b-4d79-8469-928e4c61cbc5"},"source":["# Get the lists of sentences and their labels.\n","sentences = df.sentence.values\n","labels = df.label.values\n","labels"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 0, 0, ..., 0, 0, 0])"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"Gkx8ObbNcTUZ"},"source":["#Tokenizer"]},{"cell_type":"code","metadata":{"id":"fd_lJqo3cncS","executionInfo":{"status":"ok","timestamp":1655974329328,"user_tz":-120,"elapsed":2561,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"de27e5f7-4ff3-434c-a253-909a9a135606"},"source":["!pip install sentencepiece"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"]}]},{"cell_type":"code","metadata":{"id":"9uz-SE4L_MxE","executionInfo":{"status":"ok","timestamp":1655974333326,"user_tz":-120,"elapsed":4008,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}},"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["02e364c6c40d4c11863bd912c2bb59ec","001ca80faee346cebe82da69991d209f","a8dbb0d90e1d4fde9ee8c089cbd285d6","7cffa3b5971d4b14b314f8555dae6201","6bf413a4f8154dc19873d49a2f025aa9","7dba5f89611b4bebbcb56d2f349ae4ab","b6a33505a9454ce8940fb42f233197dd","709914b675e343419afac6c177eb237f","1b17f442ee3b4f2091ca10ebfdcb4155","bdef24984d02483d88c2eec2df2ee484","3793153e779c4d199c0b5ddfae9b6684"]},"outputId":"46c7c2f2-e855-43f9-815c-21b518e1aa7e"},"source":["from transformers import XLMRobertaTokenizer\n","\n","# Load the BERT tokenizer.\n","print('Loading XLMRobertaTokenizer ...')\n","tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base', do_lower_case=True)"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading XLMRobertaTokenizer ...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02e364c6c40d4c11863bd912c2bb59ec"}},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"Zvi2HDlx_M0k","executionInfo":{"status":"ok","timestamp":1655974333328,"user_tz":-120,"elapsed":25,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5bc5d949-5bf8-413e-c888-24ca46253330"},"source":["# Print the original sentence.\n","print('Original: ', sentences[0])\n","\n","# Print the sentence split into tokens.\n","print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n","\n","# Print the sentence mapped to token ids.\n","print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Original:  Triple mileage has struck another blow to the coupon market .\n","Tokenized:  ['▁triple', '▁mile', 'age', '▁has', '▁s', 'truck', '▁another', '▁blow', '▁to', '▁the', '▁coup', 'on', '▁market', '▁', '.']\n","Token IDs:  [162738, 84765, 4588, 1556, 91, 173964, 15700, 102310, 47, 70, 14974, 191, 16839, 6, 5]\n"]}]},{"cell_type":"markdown","metadata":{"id":"tdH-JjAyev73"},"source":["#Tokenize Dataset"]},{"cell_type":"code","metadata":{"id":"pvQC4TbTcveP","executionInfo":{"status":"ok","timestamp":1655974333328,"user_tz":-120,"elapsed":21,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"15048758-c0cd-479c-f4fd-9c0d85636290"},"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in sentences:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 128,          # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', sentences[0])\n","print('Token IDs:', input_ids[0])\n","print('labels:', labels)"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Original:  Triple mileage has struck another blow to the coupon market .\n","Token IDs: tensor([     0, 162738,  84765,   4588,   1556,     91, 173964,  15700, 102310,\n","            47,     70,  14974,    191,  16839,      6,      5,      2,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1])\n","labels: tensor([1, 0, 0,  ..., 0, 0, 0])\n"]}]},{"cell_type":"markdown","metadata":{"id":"dgHZenrtf4uH"},"source":["#Train and validation split"]},{"cell_type":"code","metadata":{"id":"jfrqA7YHcviX","executionInfo":{"status":"ok","timestamp":1655974333329,"user_tz":-120,"elapsed":16,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4e10a9fd-2e32-4aba-a5ae-dfab5eb35b90"},"source":["from torch.utils.data import TensorDataset, random_split\n","\n","# Combine the training inputs into a TensorDataset.\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","# Create a 90-10 train-validation split.\n","\n","# Calculate the number of samples to include in each set.\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","# Divide the dataset by randomly selecting samples.\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["2,034 training samples\n","  226 validation samples\n"]}]},{"cell_type":"code","metadata":{"id":"Ew-crkiKcvmk","executionInfo":{"status":"ok","timestamp":1655974333330,"user_tz":-120,"elapsed":13,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}}},"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","# The DataLoader needs to know our batch size for training, so we specify it \n","# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n","# size of 16 or 32.\n","batch_size = 32\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )\n"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"31XYmBgGgLMq"},"source":["#Train the model - XLMRobertaForSequenceClassification"]},{"cell_type":"code","metadata":{"id":"NCwrwWq3gKVJ","executionInfo":{"status":"ok","timestamp":1655974381261,"user_tz":-120,"elapsed":47944,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["41f20cd194b242c0a8ccf5a1326f4c6b","037068842c4749c9862d66e7a67c2297","b6f9e08dcb3b4eefa60acb53205b1877","88385bc3f179444680a62a4088c1712c","280dc11fb2f14aaab90c59afb28b4297","fb312728eb924aed8b2a33a2c7ffda0d","bd321690fca84fe69223ecc0b80da657","7768bd95d0214fac93ffb29f89afc15d","1aee6c0c2a534fcab3c1834aba3ad2ef","e1991649bc1e430a86a414122c615fa2","eff691522d384dccb4da4bc50406126c","95bbf3a548ba4993b3000f6a718d4fa4","f142bc265f5140afb9ea4e6aeafc82bc","2035ec9722b643e39ef1744c753e834d","2add4c68cb8d4e909f8caafac852c838","7de84b8535474bcc8792b13238458b0e","e6765d3deebd4ae9a9f7dd113b870180","67f6c1a52be145b9bcaa8a9317f4927d","4ac9fb044889405497c849b0fbee0ce4","4653f1e92dd24e9d908ac55d6ed6fd56","777c65795e404d9695a120e94c5ba730","de76e0e523a34194b57ee4e0ed92c7ef"]},"outputId":"37943c72-63bf-46f8-d09a-265aba4f5d37"},"source":["from transformers import XLMRobertaForSequenceClassification, AdamW, BertConfig\n","\n","# Load BertForSequenceClassification - pretrained BERT model with a single linear classification layer on top. \n","model = XLMRobertaForSequenceClassification.from_pretrained(\n","    \"xlm-roberta-base\", # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = 2, # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/512 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41f20cd194b242c0a8ccf5a1326f4c6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95bbf3a548ba4993b3000f6a718d4fa4"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["XLMRobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"vMSwxx0gcvqh","executionInfo":{"status":"ok","timestamp":1655974381262,"user_tz":-120,"elapsed":35,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"01c45fb3-d909-41d4-e05a-869c3c06769b"},"source":["params = list(model.named_parameters())\n","\n","print('The XLMRoberta model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["The XLMRoberta model has 203 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","roberta.embeddings.word_embeddings.weight               (250002, 768)\n","roberta.embeddings.position_embeddings.weight             (514, 768)\n","roberta.embeddings.token_type_embeddings.weight             (1, 768)\n","roberta.embeddings.LayerNorm.weight                           (768,)\n","roberta.embeddings.LayerNorm.bias                             (768,)\n","\n","==== First Transformer ====\n","\n","roberta.encoder.layer.0.attention.self.query.weight       (768, 768)\n","roberta.encoder.layer.0.attention.self.query.bias             (768,)\n","roberta.encoder.layer.0.attention.self.key.weight         (768, 768)\n","roberta.encoder.layer.0.attention.self.key.bias               (768,)\n","roberta.encoder.layer.0.attention.self.value.weight       (768, 768)\n","roberta.encoder.layer.0.attention.self.value.bias             (768,)\n","roberta.encoder.layer.0.attention.output.dense.weight     (768, 768)\n","roberta.encoder.layer.0.attention.output.dense.bias           (768,)\n","roberta.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n","roberta.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n","roberta.encoder.layer.0.intermediate.dense.weight        (3072, 768)\n","roberta.encoder.layer.0.intermediate.dense.bias              (3072,)\n","roberta.encoder.layer.0.output.dense.weight              (768, 3072)\n","roberta.encoder.layer.0.output.dense.bias                     (768,)\n","roberta.encoder.layer.0.output.LayerNorm.weight               (768,)\n","roberta.encoder.layer.0.output.LayerNorm.bias                 (768,)\n","\n","==== Output Layer ====\n","\n","classifier.dense.weight                                   (768, 768)\n","classifier.dense.bias                                         (768,)\n","classifier.out_proj.weight                                  (2, 768)\n","classifier.out_proj.bias                                        (2,)\n"]}]},{"cell_type":"markdown","metadata":{"id":"51Pe3nq8g3wB"},"source":["#Optimizer and Learning Rate Scheduler"]},{"cell_type":"code","metadata":{"id":"xWkNQFlVcvup","executionInfo":{"status":"ok","timestamp":1655974381263,"user_tz":-120,"elapsed":31,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}}},"source":["# Note: AdamW is a class from the huggingface library (as opposed to pytorch) - \"W\" stands for weight decay fix\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"mtGiVJvNhALg","executionInfo":{"status":"ok","timestamp":1655974381264,"user_tz":-120,"elapsed":32,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}}},"source":["from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs. The BERT authors recommend between 2 and 4. \n","# We chose to run for 4, but we'll see later that this may be over-fitting the\n","# training data.\n","epochs = 10\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K3a_KwCxhIw4"},"source":["#Train our model"]},{"cell_type":"code","metadata":{"id":"qZsMe3FshAPv","executionInfo":{"status":"ok","timestamp":1655974381265,"user_tz":-120,"elapsed":32,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}}},"source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"eIoz0srmhAZR","executionInfo":{"status":"ok","timestamp":1655974381266,"user_tz":-120,"elapsed":33,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}}},"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uf5f0hyehAhP","executionInfo":{"status":"ok","timestamp":1655974885791,"user_tz":-120,"elapsed":504557,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1bb6b98e-1883-40dd-b788-7a7b5baf600e"},"source":["import random\n","import numpy as np\n","\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# We'll store a number of quantities such as training and validation loss, \n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        print(b_input_ids.shape)\n","        print(b_input_mask.shape)\n","        print(b_labels.shape)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # The documentation for this `model` function is here: \n","        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","        # It returns different numbers of parameters depending on what arguments\n","        # arge given and what flags are set. For our useage here, it returns\n","        # the loss (because we provided labels) and the \"logits\"--the model\n","        # outputs prior to activation.\n","        loss, logits = model(b_input_ids, \n","                             token_type_ids=None, \n","                             attention_mask=b_input_mask, \n","                             labels=b_labels)\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using \n","        # the `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            # The documentation for this `model` function is here: \n","            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","            # Get the \"logits\" output by the model. The \"logits\" are the output\n","            # values prior to applying an activation function like the softmax.\n","            (loss, logits) = model(b_input_ids, \n","                                   token_type_ids=None, \n","                                   attention_mask=b_input_mask,\n","                                   labels=b_labels)\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     64.    Elapsed: 0:00:29.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([18, 128])\n","torch.Size([18, 128])\n","torch.Size([18])\n","\n","  Average training loss: 0.66\n","  Training epcoh took: 0:00:46\n","\n","Running Validation...\n","  Accuracy: 0.67\n","  Validation Loss: 0.63\n","  Validation took: 0:00:02\n","\n","======== Epoch 2 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     64.    Elapsed: 0:00:30.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([18, 128])\n","torch.Size([18, 128])\n","torch.Size([18])\n","\n","  Average training loss: 0.64\n","  Training epcoh took: 0:00:47\n","\n","Running Validation...\n","  Accuracy: 0.68\n","  Validation Loss: 0.63\n","  Validation took: 0:00:02\n","\n","======== Epoch 3 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     64.    Elapsed: 0:00:31.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([18, 128])\n","torch.Size([18, 128])\n","torch.Size([18])\n","\n","  Average training loss: 0.60\n","  Training epcoh took: 0:00:50\n","\n","Running Validation...\n","  Accuracy: 0.55\n","  Validation Loss: 0.70\n","  Validation took: 0:00:02\n","\n","======== Epoch 4 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     64.    Elapsed: 0:00:31.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([18, 128])\n","torch.Size([18, 128])\n","torch.Size([18])\n","\n","  Average training loss: 0.52\n","  Training epcoh took: 0:00:49\n","\n","Running Validation...\n","  Accuracy: 0.66\n","  Validation Loss: 0.70\n","  Validation took: 0:00:02\n","\n","======== Epoch 5 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     64.    Elapsed: 0:00:31.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([18, 128])\n","torch.Size([18, 128])\n","torch.Size([18])\n","\n","  Average training loss: 0.42\n","  Training epcoh took: 0:00:50\n","\n","Running Validation...\n","  Accuracy: 0.75\n","  Validation Loss: 0.70\n","  Validation took: 0:00:02\n","\n","======== Epoch 6 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     64.    Elapsed: 0:00:31.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([18, 128])\n","torch.Size([18, 128])\n","torch.Size([18])\n","\n","  Average training loss: 0.30\n","  Training epcoh took: 0:00:49\n","\n","Running Validation...\n","  Accuracy: 0.70\n","  Validation Loss: 0.90\n","  Validation took: 0:00:02\n","\n","======== Epoch 7 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     64.    Elapsed: 0:00:31.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([18, 128])\n","torch.Size([18, 128])\n","torch.Size([18])\n","\n","  Average training loss: 0.21\n","  Training epcoh took: 0:00:49\n","\n","Running Validation...\n","  Accuracy: 0.70\n","  Validation Loss: 1.04\n","  Validation took: 0:00:02\n","\n","======== Epoch 8 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     64.    Elapsed: 0:00:31.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([18, 128])\n","torch.Size([18, 128])\n","torch.Size([18])\n","\n","  Average training loss: 0.16\n","  Training epcoh took: 0:00:49\n","\n","Running Validation...\n","  Accuracy: 0.70\n","  Validation Loss: 1.18\n","  Validation took: 0:00:02\n","\n","======== Epoch 9 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     64.    Elapsed: 0:00:31.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([18, 128])\n","torch.Size([18, 128])\n","torch.Size([18])\n","\n","  Average training loss: 0.14\n","  Training epcoh took: 0:00:49\n","\n","Running Validation...\n","  Accuracy: 0.71\n","  Validation Loss: 1.10\n","  Validation took: 0:00:02\n","\n","======== Epoch 10 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     64.    Elapsed: 0:00:31.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([18, 128])\n","torch.Size([18, 128])\n","torch.Size([18])\n","\n","  Average training loss: 0.11\n","  Training epcoh took: 0:00:49\n","\n","Running Validation...\n","  Accuracy: 0.70\n","  Validation Loss: 1.28\n","  Validation took: 0:00:02\n","\n","Training complete!\n","Total training took 0:08:24 (h:mm:ss)\n"]}]},{"cell_type":"code","metadata":{"id":"LHx9Nzi9hAn_","executionInfo":{"status":"ok","timestamp":1655974885792,"user_tz":-120,"elapsed":29,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}},"colab":{"base_uri":"https://localhost:8080/","height":394},"outputId":"5beff813-cd97-49d8-ccfb-030b8a62241f"},"source":["import pandas as pd\n","\n","# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n","epoch                                                                         \n","1               0.66         0.63           0.67       0:00:46         0:00:02\n","2               0.64         0.63           0.68       0:00:47         0:00:02\n","3               0.60         0.70           0.55       0:00:50         0:00:02\n","4               0.52         0.70           0.66       0:00:49         0:00:02\n","5               0.42         0.70           0.75       0:00:50         0:00:02\n","6               0.30         0.90           0.70       0:00:49         0:00:02\n","7               0.21         1.04           0.70       0:00:49         0:00:02\n","8               0.16         1.18           0.70       0:00:49         0:00:02\n","9               0.14         1.10           0.71       0:00:49         0:00:02\n","10              0.11         1.28           0.70       0:00:49         0:00:02"],"text/html":["\n","  <div id=\"df-c96dad3e-5f1d-43fc-bc8f-aa7bd5e9f8e8\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.66</td>\n","      <td>0.63</td>\n","      <td>0.67</td>\n","      <td>0:00:46</td>\n","      <td>0:00:02</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.64</td>\n","      <td>0.63</td>\n","      <td>0.68</td>\n","      <td>0:00:47</td>\n","      <td>0:00:02</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.60</td>\n","      <td>0.70</td>\n","      <td>0.55</td>\n","      <td>0:00:50</td>\n","      <td>0:00:02</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.52</td>\n","      <td>0.70</td>\n","      <td>0.66</td>\n","      <td>0:00:49</td>\n","      <td>0:00:02</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.42</td>\n","      <td>0.70</td>\n","      <td>0.75</td>\n","      <td>0:00:50</td>\n","      <td>0:00:02</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.30</td>\n","      <td>0.90</td>\n","      <td>0.70</td>\n","      <td>0:00:49</td>\n","      <td>0:00:02</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.21</td>\n","      <td>1.04</td>\n","      <td>0.70</td>\n","      <td>0:00:49</td>\n","      <td>0:00:02</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.16</td>\n","      <td>1.18</td>\n","      <td>0.70</td>\n","      <td>0:00:49</td>\n","      <td>0:00:02</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.14</td>\n","      <td>1.10</td>\n","      <td>0.71</td>\n","      <td>0:00:49</td>\n","      <td>0:00:02</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.11</td>\n","      <td>1.28</td>\n","      <td>0.70</td>\n","      <td>0:00:49</td>\n","      <td>0:00:02</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c96dad3e-5f1d-43fc-bc8f-aa7bd5e9f8e8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c96dad3e-5f1d-43fc-bc8f-aa7bd5e9f8e8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c96dad3e-5f1d-43fc-bc8f-aa7bd5e9f8e8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"d9EJhSWFhAxL","executionInfo":{"status":"ok","timestamp":1655974886761,"user_tz":-120,"elapsed":986,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}},"colab":{"base_uri":"https://localhost:8080/","height":427},"outputId":"debca621-d737-4bc5-94f7-467894ea1965"},"source":["import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","import seaborn as sns\n","\n","# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 864x432 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"IT4-LcM-iPn8"},"source":["#Performance on test set"]},{"cell_type":"code","metadata":{"id":"8VipplfqhBhS","executionInfo":{"status":"ok","timestamp":1655974886762,"user_tz":-120,"elapsed":15,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4f39a891-f455-48bc-9b1f-9a51125402f7"},"source":["import pandas as pd\n","\n","# # Load the dataset into a pandas dataframe.\n","#test_df = pd.read_csv(\"Datasets/es_lcc_new.csv\")\n","\n","# # Report the number of sentences.\n","print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n","\n","# # Create sentence and label lists\n","sentences = test_df.sentence.values.astype(str)\n","labels = test_df.label.values\n","\n","# # Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# # For every sentence...\n","for sent in sentences:\n","#     # `encode_plus` will:\n","#     #   (1) Tokenize the sentence.\n","#     #   (2) Prepend the `[CLS]` token to the start.\n","#     #   (3) Append the `[SEP]` token to the end.\n","#     #   (4) Map tokens to their IDs.\n","#     #   (5) Pad or truncate the sentence to `max_length`\n","#     #   (6) Create attention masks for [PAD] tokens.\n","     encoded_dict = tokenizer.encode_plus(\n","                         sent,                      # Sentence to encode.\n","                         add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                         max_length = 64,           # Pad & truncate all sentences.\n","                         pad_to_max_length = True,\n","                         return_attention_mask = True,   # Construct attn. masks.\n","                         return_tensors = 'pt',     # Return pytorch tensors.\n","                    )\n","    \n","#     # Add the encoded sentence to the list.    \n","     input_ids.append(encoded_dict['input_ids'])\n","    \n","#     # And its attention mask (simply differentiates padding from non-padding).\n","     attention_masks.append(encoded_dict['attention_mask'])\n","\n","# # Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# # Set the batch size.  \n","batch_size = 32  \n","\n","# # Create the DataLoader.\n","prediction_data = TensorDataset(input_ids, attention_masks, labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of test sentences: 2,260\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"HLjiQA_TiUbi"},"source":["#Evaluation on test set"]},{"cell_type":"code","metadata":{"id":"Gnv1WjdwhBrg","executionInfo":{"status":"ok","timestamp":1655974886764,"user_tz":-120,"elapsed":13,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}}},"source":["# # Prediction on test set\n","\n","# print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n","\n","# # Put model in evaluation mode\n","# model.eval()\n","\n","# # Tracking variables \n","# predictions , true_labels = [], []\n","\n","# # Predict \n","# for batch in prediction_dataloader:\n","#   # Add batch to GPU\n","#   batch = tuple(t.to(device) for t in batch)\n","  \n","#   # Unpack the inputs from our dataloader\n","#   b_input_ids, b_input_mask, b_labels = batch\n","  \n","#   # Telling the model not to compute or store gradients, saving memory and \n","#   # speeding up prediction\n","#   with torch.no_grad():\n","#       # Forward pass, calculate logit predictions\n","#       outputs = model(b_input_ids, token_type_ids=None, \n","#                       attention_mask=b_input_mask)\n","\n","#   logits = outputs[0]\n","\n","#   # Move logits and labels to CPU\n","#   logits = logits.detach().cpu().numpy()\n","#   label_ids = b_labels.to('cpu').numpy()\n","  \n","#   # Store predictions and true labels\n","#   predictions.append(logits)\n","#   true_labels.append(label_ids)\n","\n","\n","# print('    DONE.')\n","# print('    predictions:::',predictions)\n","# print('    true_labels:::',true_labels)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"0dmz1QpXteUp","executionInfo":{"status":"ok","timestamp":1655974888539,"user_tz":-120,"elapsed":1787,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}}},"source":["model.eval()\n","\n","# Tracking variables \n","predictions , true_labels = [], []\n","\n","# Predict \n","for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels = batch\n","  # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n","  with torch.no_grad():\n","    # Forward pass, calculate logit predictions\n","    logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)[0]\n","\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  true_labels.append(label_ids)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"WfsjU8Upt38K","executionInfo":{"status":"ok","timestamp":1655974888541,"user_tz":-120,"elapsed":40,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}}},"source":["my_submission = pd.DataFrame()\n","my_submission['sentence'] = test_df['sentence']\n","my_submission['arg1'] = test_df['arg1']\n","my_submission['arg2'] = test_df['arg2']\n","my_submission[\"verb\"] = test_df['verb']\n","my_submission['correct_label'] = test_df['label']\n","#my_submission['polarity'] = test_df['polarity']\n","#my_submission['intensity'] = test_df['intensity']\n","#my_submission['source_concept'] = test_df['source_concept']\n","#my_submission['target_concept'] = test_df['target_concept']"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"VNV-BxYnuNZh","executionInfo":{"status":"ok","timestamp":1655974888542,"user_tz":-120,"elapsed":40,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}}},"source":["final_preds = []\n","for p in predictions:\n","    for i in p:\n","        final_preds.append(np.argmax(i))"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"JN1eyJlFuPCc","executionInfo":{"status":"ok","timestamp":1655974888543,"user_tz":-120,"elapsed":40,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}}},"source":["my_submission['label'] = final_preds"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"FDLPomjZuR7W","executionInfo":{"status":"ok","timestamp":1655974888544,"user_tz":-120,"elapsed":41,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}}},"source":["my_submission['label'] = my_submission['label'].map({0:0, 1:1})"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fqo58IR-ufCG","executionInfo":{"status":"ok","timestamp":1655974888544,"user_tz":-120,"elapsed":40,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}},"colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"346ed136-e6c4-4c64-c4fd-6f09089464d6"},"source":["my_submission.head()"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                               sentence     arg1    arg2  \\\n","413   When she hears that prisoners sometimes carve ...      she   grabs   \n","316   Morty Bennett eats a scallop and shrimp entree...  bennett    eats   \n","1034  The latest truce in the week-old battle , whic...    which  killed   \n","65    All agree that the state must diversify its in...    state  escape   \n","1024  `` It floods the area instead of having hot pi...       it  floods   \n","\n","         verb  correct_label  label  \n","413     child              1      1  \n","316   scallop              0      0  \n","1034      188              1      1  \n","65       base              1      1  \n","1024     area              1      1  "],"text/html":["\n","  <div id=\"df-e1d7b0fa-4d9b-408e-99d3-55f7baa467d4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>arg1</th>\n","      <th>arg2</th>\n","      <th>verb</th>\n","      <th>correct_label</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>413</th>\n","      <td>When she hears that prisoners sometimes carve ...</td>\n","      <td>she</td>\n","      <td>grabs</td>\n","      <td>child</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>316</th>\n","      <td>Morty Bennett eats a scallop and shrimp entree...</td>\n","      <td>bennett</td>\n","      <td>eats</td>\n","      <td>scallop</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1034</th>\n","      <td>The latest truce in the week-old battle , whic...</td>\n","      <td>which</td>\n","      <td>killed</td>\n","      <td>188</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>All agree that the state must diversify its in...</td>\n","      <td>state</td>\n","      <td>escape</td>\n","      <td>base</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1024</th>\n","      <td>`` It floods the area instead of having hot pi...</td>\n","      <td>it</td>\n","      <td>floods</td>\n","      <td>area</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1d7b0fa-4d9b-408e-99d3-55f7baa467d4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e1d7b0fa-4d9b-408e-99d3-55f7baa467d4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e1d7b0fa-4d9b-408e-99d3-55f7baa467d4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"YQs-dWrUw7XN","executionInfo":{"status":"ok","timestamp":1655974888545,"user_tz":-120,"elapsed":37,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a05fcd41-7559-470a-b7b3-6ad4d4404403"},"source":["my_submission.shape"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(145, 6)"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"KsIV4fzxxttP","executionInfo":{"status":"ok","timestamp":1655974888546,"user_tz":-120,"elapsed":34,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ae56743a-5410-4952-c7b8-a961113c79c6"},"source":["test_df.label.value_counts()"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    80\n","1    65\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"nTtwGl9vxOoG","executionInfo":{"status":"ok","timestamp":1655974888546,"user_tz":-120,"elapsed":31,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}}},"source":["final = my_submission[(my_submission['correct_label'] == my_submission['label'])]"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"6iVw1NZ2xO0C","executionInfo":{"status":"ok","timestamp":1655974888547,"user_tz":-120,"elapsed":32,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5b0fe030-feb9-4ad1-dcd7-dd38692e721b"},"source":["final.shape"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(137, 6)"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"1BoXX0koxO6n","executionInfo":{"status":"ok","timestamp":1655974888548,"user_tz":-120,"elapsed":30,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}}},"source":["final_met = my_submission[(my_submission['correct_label'] == 1) & (my_submission['label'] ==1)]"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"zQGkR9dDxeSg","executionInfo":{"status":"ok","timestamp":1655974888549,"user_tz":-120,"elapsed":31,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"87047331-efb9-4e5f-e417-8eab183a8d2b"},"source":["final_met.shape"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60, 6)"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"RFTH_BCexeY1","executionInfo":{"status":"ok","timestamp":1655974888549,"user_tz":-120,"elapsed":28,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}}},"source":["final_lit = my_submission[(my_submission['correct_label'] == 0) & (my_submission['label'] ==0)]"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"UEwct9X5xehQ","executionInfo":{"status":"ok","timestamp":1655974888550,"user_tz":-120,"elapsed":28,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6d88cc50-a885-4f08-d782-de89effecd36"},"source":["final_lit.shape"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(77, 6)"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"Rs-f8IKraTz5","executionInfo":{"status":"ok","timestamp":1655974888550,"user_tz":-120,"elapsed":24,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}}},"source":["#print(logits)"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"g7YGsSh_uhz7","executionInfo":{"status":"ok","timestamp":1655974888550,"user_tz":-120,"elapsed":23,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}}},"source":["my_submission.to_csv('trofix_mixed_sub.csv', index=False)"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"9GYFtiTEk7MP","executionInfo":{"status":"ok","timestamp":1655974888551,"user_tz":-120,"elapsed":24,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}}},"source":["#final_met.to_csv(\"final_met.csv\", index=False)"],"execution_count":44,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Whz6mWvpidb-"},"source":["#Save and load fine-tuned model"]},{"cell_type":"code","metadata":{"id":"73UumM0PhBym","executionInfo":{"status":"ok","timestamp":1655974896018,"user_tz":-120,"elapsed":7491,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d9bc7b2b-ce13-4949-e2fd-622dd5a20425"},"source":["import os\n","\n","# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n","\n","output_dir = 'stockholm/xlm_code/mixed_models/trofix_mixed'\n","# output_dir = './content/xlm-roberta_model_save/'\n","\n","# Create output directory if needed\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","print(\"Saving model to %s\" % output_dir)\n","\n","# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","# They can then be reloaded using `from_pretrained()`\n","model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","model_to_save.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)\n","\n","# Good practice: save your training arguments together with the trained model\n","# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"],"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving model to stockholm/xlm_code/mixed_models/trofix_mixed\n"]},{"output_type":"execute_result","data":{"text/plain":["('stockholm/xlm_code/mixed_models/trofix_mixed/sentencepiece.bpe.model',\n"," 'stockholm/xlm_code/mixed_models/trofix_mixed/special_tokens_map.json',\n"," 'stockholm/xlm_code/mixed_models/trofix_mixed/added_tokens.json')"]},"metadata":{},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"LmN96FOqjLKd"},"source":["#Import saved model and test"]},{"cell_type":"code","metadata":{"id":"ScJHWcE5hB4z","executionInfo":{"status":"ok","timestamp":1655974898228,"user_tz":-120,"elapsed":2242,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"15dc038b-584d-449e-a8aa-af53994a95ca"},"source":["!pip install transformers\n","\n","from transformers import XLMRobertaForSequenceClassification\n","\n","output_dir = 'stockholm/xlm_code/mixed_models/trofix_mixed'\n","\n","print(output_dir)"],"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (3.0.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.0rc4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.53)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.96)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","stockholm/xlm_code/mixed_models/trofix_mixed\n"]}]},{"cell_type":"code","metadata":{"id":"SZbux55ucvy5","executionInfo":{"status":"ok","timestamp":1655974918442,"user_tz":-120,"elapsed":20226,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d9bdb3a1-61f6-4446-9e36-06e8406a78a3"},"source":["from transformers import XLMRobertaTokenizer\n","import torch\n","# Load the BERT tokenizer.\n","print('Loading XLMRobertaTokenizer...')\n","tokenizer = XLMRobertaTokenizer.from_pretrained(output_dir)\n","model_loaded = XLMRobertaForSequenceClassification.from_pretrained(output_dir)"],"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading XLMRobertaTokenizer...\n"]}]},{"cell_type":"code","metadata":{"id":"lhw_GFdIuwR4","executionInfo":{"status":"ok","timestamp":1655974918444,"user_tz":-120,"elapsed":32,"user":{"displayName":"Giorgio Ottolina","userId":"08747627632687137907"}}},"source":[""],"execution_count":47,"outputs":[]}]}